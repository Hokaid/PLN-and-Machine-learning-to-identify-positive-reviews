{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Examen Final ML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nCpsJUfbx_HR",
        "_eUlGw7Vk9R3",
        "vI8-nNmhWSQ7",
        "bJCrGqUmP87M",
        "vkXijatIiBxP",
        "WbHpD8-5GwnH",
        "gHYL0Dga2chR",
        "sbS2nuOXKjxW",
        "Ky8FxAdyKt36",
        "opVZuGYBcmvY",
        "iHu68thjgI8S"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hokaid/PLN-and-Machine-learning-to-identify-positive-reviews/blob/master/Examen_Final_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8V19r5_kL67",
        "colab_type": "text"
      },
      "source": [
        "#***Enlace Online***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gfXOvfEjGTb",
        "colab_type": "text"
      },
      "source": [
        "**[Link de Acceso](https://colab.research.google.com/drive/1DXnNVgUVeP6DV8FLYqRjnvfysSX8VSQw?usp=sharing)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCpsJUfbx_HR",
        "colab_type": "text"
      },
      "source": [
        "#***Alumnos***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POG9ej_2yMLn",
        "colab_type": "text"
      },
      "source": [
        "- ***Geral Esteen Castillo Arredondo U201716913***\n",
        "\n",
        "- ***Javier Arturo Rozas Acurio U201711814***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enMcf6BPDU9M",
        "colab_type": "text"
      },
      "source": [
        "#***Videos***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoAZ3qykDY_u",
        "colab_type": "text"
      },
      "source": [
        "***Video de Javier:*** **[Video en Loom](https://www.loom.com/share/d481822e30fc4dd9a85f81db37c1f19c)**\n",
        "\n",
        "***Video de Geral:*** **[Video en Loom](https://www.loom.com/share/63bf3107d76b417d8d4d39743f75a1fc)**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eUlGw7Vk9R3",
        "colab_type": "text"
      },
      "source": [
        "#***I. Procesamiento de Corpus***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm6Dfe98leBl",
        "colab_type": "text"
      },
      "source": [
        "##***1. Lectura de datos***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ayleNTalj_l",
        "colab_type": "text"
      },
      "source": [
        "En esta parte, se procede a realizar la lectura respectiva de los datos correspondiente a los textos a utilizar en el presente trabajo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySjOBoP2eu-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Leer un CSV \n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials \n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4L8epUZl2db",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, es factible observar la lectura del archivo de texto ***rgdata.txt***. Este archivo contiene los textos que seran descritos y procesados posteriormente. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgvXPRXhM4dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import data_table\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "\n",
        "link_google_drive = 'https://drive.google.com/open?id=1Bl2iiO5WIRnSjnbqEA1v6TcuOXKYOTWB'\n",
        "flu, id = link_google_drive.split('=')\n",
        "dataset = drive.CreateFile({'id':id})\n",
        "dataset.GetContentFile('rgdata.txt')\n",
        "f = open('rgdata.txt', 'r')\n",
        "soup = BeautifulSoup(f,'html5lib')\n",
        "texto = soup.get_text(strip=True)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw7paCN5mSMN",
        "colab_type": "text"
      },
      "source": [
        "##***2. Descripción de los datos***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rGqD6YSmfbI",
        "colab_type": "text"
      },
      "source": [
        "***Contexto de los datos:*** Para obtener los datos anteriormente leidos, se realizo un proceso de extracción de textos. Estos textos son correspondientes a reseñas de videojuegos. Se ingreso a una pagina en la que tanto criticos profesionales como fanaticos pueden realizar reseñas a sus videojuegos favoritos. Por lo tanto, dichas reseñas fueron extraidas y ***etiquetadas*** como ***Positivo*** o ***Negativo*** dependiendo si la reseña extraida era positiva o negativa. El archivo leido anteriormenete contiene más de ***150*** textos de reseñas etiquetadas apropiadamente.  \n",
        "\n",
        "Ahora bien, se procedera a definir las caracteristicas y clase o etiqueta respectiva a los datos recolectados:\n",
        "\n",
        "***Caracteristicas***\n",
        "\n",
        "* ***Texto de reseña:*** Se compone de un texto, el cual contiene información respecto a la reseña de un videojuego. La reseña puede ser ***positiva*** o ***negativa***. \n",
        "\n",
        "***Atributo clase o objetivo***\n",
        "\n",
        "* ***Tipo de reseña:*** En este caso, respecto al texto descrito anteriormente, esta etiqueta define si se trata de una reseña ***negativa*** o ***positiva***. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAe4ewZkpuZY",
        "colab_type": "text"
      },
      "source": [
        "##***3. Análisis exploratorio del texto***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOThMo_twH75",
        "colab_type": "text"
      },
      "source": [
        "###***A. Impresión y visualización del texto***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbjEjXQ_tYGF",
        "colab_type": "text"
      },
      "source": [
        "A continuación, se procede a importar y descargar una libreria muy util para el ***Procesamiento de Lenguaje Natural (PLN)***. Esta libreria se llama ***nltk***. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v6sZ-oIZorG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d95df07-fd47-4c79-d403-3a8bb129e0c3"
      },
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "Hit Enter to continue: \n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "Hit Enter to continue: \n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] punkt............... Punkt Tokenizer Models\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "Hit Enter to continue: \n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] stopwords........... Stopwords Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet............. WordNet\n",
            "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
            "  [ ] words............... Word Lists\n",
            "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
            "                           English Prose\n",
            "\n",
            "Collections:\n",
            "  [ ] all-corpora......... All the corpora\n",
            "  [ ] all-nltk............ All packages available on nltk_data gh-pages\n",
            "                           branch\n",
            "  [ ] all................. All packages\n",
            "  [ ] book................ Everything used in the NLTK Book\n",
            "  [ ] popular............. Popular packages\n",
            "Hit Enter to continue: \n",
            "  [ ] tests............... Packages for running tests\n",
            "  [ ] third-party......... Third-party data packages\n",
            "\n",
            "([*] marks installed packages)\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "Hit Enter to continue: \n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "Hit Enter to continue: \n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] punkt............... Punkt Tokenizer Models\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "Hit Enter to continue: \n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] stopwords........... Stopwords Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet............. WordNet\n",
            "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
            "  [ ] words............... Word Lists\n",
            "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
            "                           English Prose\n",
            "\n",
            "Collections:\n",
            "  [ ] all-corpora......... All the corpora\n",
            "  [ ] all-nltk............ All packages available on nltk_data gh-pages\n",
            "                           branch\n",
            "  [ ] all................. All packages\n",
            "  [ ] book................ Everything used in the NLTK Book\n",
            "  [ ] popular............. Popular packages\n",
            "Hit Enter to continue: \n",
            "  [ ] tests............... Packages for running tests\n",
            "  [ ] third-party......... Third-party data packages\n",
            "\n",
            "([*] marks installed packages)\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> \n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z2bRzqwwbNq",
        "colab_type": "text"
      },
      "source": [
        "Ahora bien, en esta parte, se procede a imprimir el texto y la clase o etiqueta respectiva, con el objetivo de conocer las propiedades de los datos. En el siguiente codigo, se define la función ***imprimir_texto***, la cual posee la capacidad de imprimir los textos junto a su clase respectiva."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6Ta4zH8Ob_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imprimir_texto(texto,num_char=10):\n",
        "  i = 1\n",
        "  for x in texto.split('\\n'):\n",
        "    cadena, clase = x.split('----->')\n",
        "    print('{}\\t{}\\t{}'.format(i, cadena[:num_char], clase))\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EhleEoNOmJ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0339fabe-0daf-469b-c459-8d9c8e086d6a"
      },
      "source": [
        "imprimir_texto(texto, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\tEste juego tiene todo lo que puedes pedir en un juego Iron Man VR\tPositivo\n",
            "2\tEste es uno de los mejores juegos de PSVR que he jugado\tPositivo\n",
            "3\tMuy buena experiencia de juego y diversión te está esperando\tPositivo\n",
            "4\tIncreíble juego, me encanta la historia y el personaje\tPositivo\n",
            "5\tIncreíble no solo para los amantes occidentales\tPositivo\n",
            "6\tCon su increíble historia de mundo abierto, bien escrita y personajes profundos, Red Dead Redemption\tPositivo\n",
            "7\tEste juego es una obra maestra de la narración de cuentos, recomiendo a cualquiera con Ps4 que juegu\tPositivo\n",
            "8\tEl nuevo comienzo de Kratos está lleno de corazón, cargado de acción y es fácilmente uno de los mejo\tPositivo\n",
            "9\tUna expansión excepcionalmente buena que agrega una montaña de contenido nuevo que aborda específica\tPositivo\n",
            "10\tLa naturaleza del nuevo Hitman está bien establecida, las tareas siempre están bien hechas y son muy\tPositivo\n",
            "11\tLos episodios más recientes continúan con la mejora constante de la calidad de Hitman. Marrakech ofr\tPositivo\n",
            "12\tPersona 5 ya era un líder fuerte por ser el mejor JRPG jamás creado, y Royal realmente me hace pregu\tPositivo\n",
            "13\tBellamente mejorado y, en su esencia, una mezcla tremendamente fascinante de la rutina diaria de la \tPositivo\n",
            "14\tLa cantidad de cambio aportado al título es significativa, y todo parece una mejora notable. Para un\tPositivo\n",
            "15\tLiteralmente acaba de hacer el juego original, que fue uno de los mejores JRPG de todos los tiempos,\tPositivo\n",
            "16\tUtilizando disparos rápidos en primera persona como marco, cada secuela ha mejorado enormemente el d\tPositivo\n",
            "17\tUn juego fantástico, que toma todos los elementos que hicieron de DOOM 2016 un reinicio tan sorprend\tPositivo\n",
            "18\tDOOM Eternal superó las expectativas, tanto en lo que respecta a la dificultad como al disfrute, y a\tPositivo\n",
            "19\tUn juego hermoso, difícil de entender sin conocer la historia del creador pero tan inmersivo ... La \tPositivo\n",
            "20\tPuyo Puyo Champions ofrece un juego de rompecabezas competitivo familiar y divertido con una gran se\tPositivo\n",
            "21\tEn general, Blazblu Chronophantasma Extend es imprescindible para cualquiera que esté interesado en \tPositivo\n",
            "22\tTodo sobre este juego es genial. Tiene diversidad no solo en sus personajes, sino también en las emo\tPositivo\n",
            "23\tEn pocas palabras, uno de los mejores juegos de lucha en 2D para PS4, Xbox One, PS3 e incluso consol\tPositivo\n",
            "24\tDe lo contrario, BlazBlue sigue siendo el juego de lucha elegante, rápido, competitivo y vibrante qu\tPositivo\n",
            "25\tUno de los mejores juegos que he jugado en mi vida. No es mentira que sea lo mismo con los otros 2 j\tPositivo\n",
            "26\tPara un modo de historia de estilo de novela visual y un juego de lucha, no podría pedir mucho más, \tPositivo\n",
            "27\tBlood and Truth deja las viejas demostraciones tecnológicas glorificadas en el polvo y se da cuenta \tPositivo\n",
            "28\tDesde la historia convincente y bien actuada hasta su combate atractivo, SIE London Studios ha brind\tPositivo\n",
            "29\tSimplemente un juego increíble con toda la emoción y la emoción que todos esperaban de la exageració\tPositivo\n",
            "30\tA riesgo de sonar demasiado enamorado, no puedo comenzar a entender cómo demonios Torchlight II ha e\tPositivo\n",
            "31\tSiete años después de su lanzamiento inicial, Torchlight 2 finalmente adorna la generación de la con\tPositivo\n",
            "32\tUna de las mejores sorpresas que tuve con un juego de rol de acción. Probablemente el que se siente \tPositivo\n",
            "33\tBUENO: Excelente jugabilidad, toneladas de botines individuales, muchas misiones, niveles aleatorios\tPositivo\n",
            "34\tTras alejar la acción de los oscuros túneles subterráneos de Moscú en un tren, ir a lo desconocido y\tPositivo\n",
            "35\tAsí que siéntese y disfrute de la experiencia única, las maravillas visuales y los secretos más oscu\tPositivo\n",
            "36\tApocalypse es una expansión completa que redefine la guerra estelar para todos los jugadores con una\tPositivo\n",
            "37\tssetto Corsa Competizione es un extraordinario juego de simulación de carreras que permite a los jug\tPositivo\n",
            "38\tSumérgete en un juego de disparos en primera persona impulsado por la acción, ambientado en un futur\tPositivo\n",
            "39\tUno de los mejores videojuegos que he jugado. Este juego siempre te mantendrá alerta cuando juegues \tPositivo\n",
            "40\tEste es uno de los mejores JRPG que he jugado y créanme que he jugado mucho. Este juego tiene todo e\tPositivo\n",
            "41\tModern Warfare 2 vuelve con un buen trabajo de remasterización, pero que echa demasiado en falta su \tPositivo\n",
            "42\tBeyond Blue lleva a los jugadores al futuro cercano, donde tendrán la oportunidad de explorar los mi\tPositivo\n",
            "43\tBienvenido a Warzone: una nueva experiencia de combate en la que hasta 150 jugadores toman el papel \tPositivo\n",
            "44\tModern Warfare 2 vuelve con un buen trabajo de remasterización, pero que echa demasiado en falta su \tPositivo\n",
            "45\t¡¡¡MUY DIVERTIDO!!! Este juego es muy divertido ¡Definitivamente es una compra obligada! Este juego \tPositivo\n",
            "46\tUn gran juego de acción en 2D protagonizado por mechas: espectacular, variado y muy completo\tPositivo\n",
            "47\tBreeder Homegrown es un juego de terror corto sobre una familia que trata con una criatura extraña d\tPositivo\n",
            "48\tLa separación es una aventura en primera persona en su forma más ambiental y atmosférica\tPositivo\n",
            "49\tHolfraine es un juego de disparos de héroes en tercera persona con diferentes personajes para elegir\tPositivo\n",
            "50\tStab Stab Stab es un juego de apuñalamiento de arena basado en la física para jugadores múltiples pa\tPositivo\n",
            "51\tEl juego es una dicha para jugar, mirar y escuchar. Los momentos de OG te llenarán de nostalgia, mie\tPositivo\n",
            "52\tTempest es un juego de rol de acción pirata de mundo abierto que ofrece una capacidad máxima para re\tPositivo\n",
            "53\t¡El juego de golf para personas que odian el golf! Una tonta parodia de golf basada en la física don\tPositivo\n",
            "54\tUna guerra de fantasía sin fin Gran estrategia de simulación. Conquista el continente en este gran j\tPositivo\n",
            "55\tEn el año 2091, los avances generalizados en tecnología e informática no han cambiado la naturaleza \tPositivo\n",
            "56\tEs un juego genial. Aunque igual creo que las partes no tan importantes las hicieron bastante largas\tPositivo\n",
            "57\tSaints & Sinners es un juego diferente a cualquier otro en el universo de The Walking Dead. USTED im\tPositivo\n",
            "58\tJuego increíblemente divertido, ya jugué varios partidos, hasta el nivel 10. Predator me asusta cuan\tPositivo\n",
            "59\tCreo que es maravillosamente emocionante. Si obtiene apoyo y continúa creciendo, puede obtener el éx\tPositivo\n",
            "60\tDaymare: 1998 es un juego de terror y supervivencia en tercera persona con cámara sobre el hombro, d\tPositivo\n",
            "61\tExperimente el paquete completo, remasterizado. Steelport, la ciudad original del pecado, nunca se h\tPositivo\n",
            "62\tUn juego de suspenso de investigación con narración no lineal, Telling Lies gira en torno a un caché\tPositivo\n",
            "63\tAdemás de presentar NPC totalmente expresados ​​al mundo de Fallout 76, Wastelanders trae una nueva \tPositivo\n",
            "64\tBeyond Blue lleva a los jugadores al futuro cercano, donde tendrán la oportunidad de explorar los mi\tPositivo\n",
            "65\tSube el puntaje en una pelea relajada o supera los límites de tus reflejos en este refinado simulado\tPositivo\n",
            "66\tA través del juego, los jugadores pueden experimentar el miedo provocado por un terremoto y pueden a\tPositivo\n",
            "67\tJohn Wick Hex es un juego de estrategia rápido y orientado a la acción que te hace pensar y golpear \tPositivo\n",
            "68\tEllie se embarca en un viaje implacable para llevar a cabo la justicia y encontrar el cierre. Mientr\tPositivo\n",
            "69\tCommand & Conquer y Red Alert son remasterizados en 4K por los antiguos miembros del equipo de Westw\tPositivo\n",
            "70\t'Summer in Mara' es una aventura de verano con elementos fáciles de juegos de rol y mecánicas de cul\tPositivo\n",
            "71\tMonster Train es un juego de construcción de mazos roguelike estratégico con un toque diferente. Ubi\tPositivo\n",
            "72\tEl juego está destinado a sumergirte en la mente de John, a medida que avanzas cada paso hacia el re\tPositivo\n",
            "73\tProbablemente el mejor juego que jugué en los últimos 10 años. Nuevos gráficos realistas, mecánica, \tPositivo\n",
            "74\tSony San Diego evitó desarrollar viñetas llamativas en la parte posterior de la caja a favor de refi\tPositivo\n",
            "75\tMLB 15: The Show es el mejor juego de béisbol jamás creado. Pero lo hemos dicho antes sobre sus pred\tPositivo\n",
            "76\tOye, como siempre digo, si no está roto, no lo arregles. Más de lo mismo, pero sigue siendo el mejor\tPositivo\n",
            "77\tLos gráficos son lentos, inconsistentes, con ralentizaciones extremas, desgarros y saltos de fotogra\tNegativo\n",
            "78\tFps muy bajos en Ps4 Pro, por lo que el juego no se puede jugar y Graphic es horrible\tNegativo\n",
            "79\teste juego es realmente malo, baja fps, retraso, mala física y más\tNegativo\n",
            "80\tLa gente quiere jugar este juego para la historia, pero la historia es muy mala\tNegativo\n",
            "81\tDespués de más de una docena de horas, puedo decir que el juego está dolorosamente sobrevalorado\tNegativo\n",
            "82\tUno de los peores juegos que jugué últimamente\tNegativo\n",
            "83\tEste es uno de esos grandes juegos bellamente aburridos que tiene 1 fuente de logro, el realismo, y \tNegativo\n",
            "84\tfue un juego muy horrible, no entiendo por qué xcom2 ha producido una acción muy mala y muy mala cua\tNegativo\n",
            "85\tEn pocas palabras, ni siquiera sé cómo llegó al mercado. terrible juego, pistolas y mapas\tNegativo\n",
            "86\tEl lanzamiento de Out of Ammo suena interesante en el papel, pero la ejecución es probablemente el p\tNegativo\n",
            "87\tEl juego es literalmente terrible. El juego tiene gráficos muy pobres y se siente muy insensible\tNegativo\n",
            "88\tEl juego es horrible. Shooter en primera persona que corre como mi nan\tNegativo\n",
            "89\tJuego muy malo y aburrido. Casi me quedo dormido jugando este maldito juego. Simplemente no lo compr\tNegativo\n",
            "90\tUna experiencia mediocre que es menos horror psicológico que tortura. Hay mejores experiencias de te\tNegativo\n",
            "91\tDavid Lynch no tiene miedo de hacer arte impenetrable, difícil de interpretar. Eso es parte de su ge\tNegativo\n",
            "92\tEl juego es una degradación de Doom 1 en muchos aspectos. ¿Más atroz? Cuando el juego se bloquea, co\tNegativo\n",
            "93\tSuper Soccer Blast es un juego de deportes de estilo arcade. No es realista Como un juego de fútbol \tNegativo\n",
            "94\t1971 Project Heliosis es un juego de estrategia por turnos que combina tácticas militares de guerra \tNegativo\n",
            "95\tJuego muy malo y aburrido. Casi me quedo dormido jugando este maldito juego. Simplemente no lo compr\tNegativo\n",
            "96\tIon Fury canaliza sin esfuerzo el espíritu de los tiradores de la vieja escuela como Duke Nukem 3D, \tNegativo\n",
            "97\tGráficos horribles, tiempos de carga extremadamente largos y frecuentes, juego repetitivo, actuación\tNegativo\n",
            "98\tHorrible sistema de guardado en el que si tu personaje muere, te lleva de vuelta al juego, salvo en \tNegativo\n",
            "99\tLo último para terminarlo me pareció frustrantemente incómodo, casi imposible. En un hilo de Steam, \tNegativo\n",
            "100\tEste no es un buen juego! Si se tratara de un juego f2p con algunos cosméticos y potenciadores de XP\tNegativo\n",
            "101\tjuego horrible con mala calidad, ¡no era lo que esperaba! ¡No malgastes tu dinero en un juego así!\tNegativo\n",
            "102\tAdemás de horribles emparejamientos y una gran cantidad de fallas técnicas, Predator: Hunting Ground\tNegativo\n",
            "103\tWow este juego es malo! ¡Y ya están llegando las 10 falsas 10 reseñas! 10 de 10 es? el mejor juego d\tNegativo\n",
            "104\tDios mío, este juego es una desgracia, no puedo en serio, lo intento, pero Nop, si quieres malgastar\tNegativo\n",
            "105\tjuego horrible con mala calidad, ¡no era lo que esperaba! ¡No malgastes tu dinero en un juego así\tNegativo\n",
            "106\tEste juego es bastante pobre, lo compré porque se ve decente en los videos de YouTube (pero eso se v\tNegativo\n",
            "107\tSoy un gran fanático de Predator, pero qué puedo decir ... Predator Hunting grounds es uno de los ju\tNegativo\n",
            "108\tEste juego no vale su precio actual. Recomendaría comprarlo cuando esté a la venta. No valía la pena\tNegativo\n",
            "109\tMuchos problemas: colisión, equilibrio, saltos, retrasos, trampas de colisión, emparejamiento infini\tNegativo\n",
            "110\tProbablemente sea uno de los peores remasterizadores de todos los tiempos, con una tasa de fotograma\tNegativo\n",
            "111\tUgh Las imágenes son lo único que ofrece este juego. Los escritores de la historia deben haber llama\tNegativo\n",
            "112\tEste juego es una pena, siete años esperando una gran secuela y crean una historia ridícula como esa\tNegativo\n",
            "113\tEste es honestamente uno de los peores juegos que he jugado\tNegativo\n",
            "114\tNo sé qué juegan las personas que califican esto como 10, aparte de la creación del personaje, este \tNegativo\n",
            "115\tNo lo disfruté, las peleas no fueron divertidas y no me gustó mucho la historia. Sin embargo, estoy \tNegativo\n",
            "116\tEl diseño de niveles es tan malo, como un corredor de laberintos con enemigos en cada esquina. Sin p\tNegativo\n",
            "117\tFue muy malo El combate y los gráficos no parecen pertenecer a esta generación\tNegativo\n",
            "118\tEste juego tiene un diseño de ubicación deficiente, diseño de arma pobre, falta de equilibrio en un \tNegativo\n",
            "119\tEs patético que alguien mencione el surge 2 y las almas oscuras en la misma oración, The Surge 2 es \tNegativo\n",
            "120\tHorrible. ¿Cómo logró ser PEOR que el primer juego, que fue malo, pero no tan malo! Extremadamente a\tNegativo\n",
            "121\tEsperaba mas de este juego pero la verdad no me gustó es todo lo que tengo que decir\tNegativo\n",
            "122\tLa escritura es terriblemente aburrida ... Para empeorar las cosas, la mecánica de combate es la peo\tNegativo\n",
            "123\tMuy, muy mal juego y fluidez del juego. La suavidad del juego es horrible. IU de los años 90\tNegativo\n",
            "124\tHonestamente, estoy realmente decepcionado, especialmente porque este juego cuesta $ 75 en total. Ha\tNegativo\n",
            "125\tMecánica torpe y una historia ridículamente aburrida. Los personajes eran finos como el papel y comp\tNegativo\n",
            "126\tLa historia es irrelevante. El juego no es divertido en absoluto. Puedes matar el tiempo jugando Cha\tNegativo\n",
            "127\tLa jugabilidad es tan repetitiva y lo ha visto todo antes y, para empeorar las cosas, tiene problema\tNegativo\n",
            "128\tEl juego arruina mucho de lo que se puede amar de MK. La lucha es decente, pero todo lo demás, desde\tNegativo\n",
            "129\tromesas incumplidas y muchas mentiras. El peor juego de toda la franquicia\tNegativo\n",
            "130\tEsto es una vergüenza para un juego de Mortal Kombat, siempre un infierno de micro transacciones en \tNegativo\n",
            "131\tThe War Machine es una vez más otro pobre esfuerzo para inyectar vida en un juego rancio, sin inspir\tNegativo\n",
            "132\tEl peor juego del mundo para jugarlo es cómo golpear tu cabeza contra una pared. No sé a qué nivel d\tNegativo\n",
            "133\tMuy flojo. el modo zombie no es rejugable aburre en cuanto haces el huevo de pascua\tNegativo\n",
            "134\tAl final, Rise of Iron es, literalmente, más Destino. No aborda ninguno de los problemas que podría \tNegativo\n",
            "135\tSTAY no puede ser criticado por sus aspiraciones y el intento de hacer un personaje creíble en Quinn\tNegativo\n",
            "136\tImagina el nuevo Doom en VR y completamente imposible de jugar\tNegativo\n",
            "137\tSi bien DOOM: VFR puede ser un juego divertido, la falta de ultraviolencia y el corto tiempo de jueg\tNegativo\n",
            "138\tInacabado, rediseños pobres del elenco principal, y cambió un montón de efectos de sonido del arma\tNegativo\n",
            "139\tCon este segundo episodio, The Legacy of the First Blade arma todo el juego de roles que Ubisoft pas\tNegativo\n",
            "140\tMutant Football League es un juego deportivo arcade barato y mal ejecutado. Creo que los desarrollad\tNegativo\n",
            "141\tSi bien Fantastic Contraption lo alienta a ser creativo, inmediatamente lo encajona al mismo tiempo \tNegativo\n",
            "142\tGráficamente seguro como está, casi todos los demás elementos de la serie de 15 años han sido recort\tNegativo\n",
            "143\tDesafortunadamente, los mejores atributos de Island Time VR, las imágenes y la actuación de voz, se \tNegativo\n",
            "144\tSi no estás discutiendo con tus amigos sobre si Naruto vencería a Goku y no estás rezando por la cua\tNegativo\n",
            "145\tLa Iglesia en la Oscuridad quiere ser un juego de sigilo que te ponga en medio de un culto del fin d\tNegativo\n",
            "146\tEl componente interactivo real de The Grand Tour Game es realmente bastante pobre, con un manejo hor\tNegativo\n",
            "147\tDe alguna manera, este juego es peor que el primero. El combate es malo, los gráficos apestan, la hi\tNegativo\n",
            "148\tTiene muchos errores, modo historia no completado y bajo nivel de contenido. No recomiendo comprarlo\tNegativo\n",
            "149\tAquí vamos de nuevo, otro episodio completamente decepcionante de una franquicia tan (solía ser). Me\tNegativo\n",
            "150\tEn retrospectiva, no debería haber dado cero al primer episodio porque este episodio es incluso peor\tNegativo\n",
            "151\tEl problema con el juego es que tiene muchos errores como: estaba luchando contra un jefe, y no tení\tNegativo\n",
            "152\tUna buena formación de canciones pero problemas serios. No puedo creer que no hayan mejorado el sopo\tNegativo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV7U2P1Qxl3i",
        "colab_type": "text"
      },
      "source": [
        "###***B. Separación de Texto y Etiqueta***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-yIzRNTzu5v",
        "colab_type": "text"
      },
      "source": [
        "A continuación se procede a instalar la libreria ***spicy***, la cual presenta herramientas muy interesantes para el ***Procesamiento de Lenguaje Natural (PLN)***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGCtFuLSUVoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e1aa9e22-00b4-4c80-c3af-044499bdee43"
      },
      "source": [
        "!pip install spicy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spicy in /usr/local/lib/python3.6/dist-packages (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from spicy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->spicy) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb70b6xQUbfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9270551a-2d34-4820-c57b-320c8db8946f"
      },
      "source": [
        "import spacy\n",
        "spacy.cli.download('es_core_news_md')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDe1oINkUvJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('es_core_news_md')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nt6mcM2Y0M70",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se define la función ***extraer_texto***, la cual sirve para separar los textos de su etiqueta respectiva. La división se realiza por medio del siguiente conjunto de caracteres: ***----->***. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts17bmk8VuS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extraer_texto(texto):\n",
        "  X_cadenas = []\n",
        "  Y_cadena = []\n",
        "  textoSalida = ''\n",
        "  for x in texto.split('\\n'):\n",
        "    cadena, clase = x.split('----->')\n",
        "    textoSalida += cadena + \" \"\n",
        "    Y_cadena.append(clase)\n",
        "    X_cadenas.append(cadena)\n",
        "  return textoSalida, X_cadenas, Y_cadena"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8RbCUI3WOXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texto, X_cadenas, Y_cadena = extraer_texto(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pWQBJv900Ec",
        "colab_type": "text"
      },
      "source": [
        "Ahora bien, una vez separados el texto de la etiqueta asociada, se procede a imprimir el arreglo con todas las etiquetas respectivamente almacenadas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfw67Ha9Ws7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "81415c0f-f21f-43c2-b7af-d2a2bed68325"
      },
      "source": [
        "print(Y_cadena)\n",
        "print(len(Y_cadena))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Positivo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo', 'Negativo']\n",
            "152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nErRBzyD1IH3",
        "colab_type": "text"
      },
      "source": [
        "En ese sentido, tambien se procede a imprimir el arreglo con todas los textos respectivamente almacenados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuEhonuVXnqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c4bad1b5-1056-45e6-8382-6e8eb324e7ea"
      },
      "source": [
        "print(X_cadenas)\n",
        "print(len(X_cadenas))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Este juego tiene todo lo que puedes pedir en un juego Iron Man VR', 'Este es uno de los mejores juegos de PSVR que he jugado', 'Muy buena experiencia de juego y diversión te está esperando', 'Increíble juego, me encanta la historia y el personaje', 'Increíble no solo para los amantes occidentales', 'Con su increíble historia de mundo abierto, bien escrita y personajes profundos, Red Dead Redemption II es una montaña rusa llena de emociones', 'Este juego es una obra maestra de la narración de cuentos, recomiendo a cualquiera con Ps4 que juegue este juego', 'El nuevo comienzo de Kratos está lleno de corazón, cargado de acción y es fácilmente uno de los mejores juegos de esta generación', 'Una expansión excepcionalmente buena que agrega una montaña de contenido nuevo que aborda específicamente los pocos defectos que había con el original', 'La naturaleza del nuevo Hitman está bien establecida, las tareas siempre están bien hechas y son muy divertidas de jugar', 'Los episodios más recientes continúan con la mejora constante de la calidad de Hitman. Marrakech ofrece un área de juegos aún más grande e impresionante con mucha más libertad de acción, al tiempo que presenta un desafío mayor', 'Persona 5 ya era un líder fuerte por ser el mejor JRPG jamás creado, y Royal realmente me hace preguntarme qué más podría incluso competir', 'Bellamente mejorado y, en su esencia, una mezcla tremendamente fascinante de la rutina diaria de la escuela secundaria y el extraño thriller de misterio', 'La cantidad de cambio aportado al título es significativa, y todo parece una mejora notable. Para un juego que ya era uno de los mejores JRPG de los últimos años, Persona 5 Royal es una continuación que se consolida como una experiencia que vale la pena repetir en lugar de una secuela de Persona adecuada', 'Literalmente acaba de hacer el juego original, que fue uno de los mejores JRPG de todos los tiempos, mejor', 'Utilizando disparos rápidos en primera persona como marco, cada secuela ha mejorado enormemente el diseño de niveles, una selección más amplia de demonios para masacrar y un arsenal más grande que se une para refinar su identidad central de la manera más inteligente y respetuosa posible', 'Un juego fantástico, que toma todos los elementos que hicieron de DOOM 2016 un reinicio tan sorprendente de la franquicia e implementó docenas de nuevos conceptos de una manera que hace que toda la experiencia se sienta fresca nuevamente', 'DOOM Eternal superó las expectativas, tanto en lo que respecta a la dificultad como al disfrute, y aunque no sin sus fallas, se siente como un juego imprescindible para los jugadores de FPS', 'Un juego hermoso, difícil de entender sin conocer la historia del creador pero tan inmersivo ... La música es fantástica y es un placer vivirla de principio a fin', 'Puyo Puyo Champions ofrece un juego de rompecabezas competitivo familiar y divertido con una gran selección de personajes encantadores', 'En general, Blazblu Chronophantasma Extend es imprescindible para cualquiera que esté interesado en sus juegos de lucha y esto está a la altura de cualquier cosa en la PS4', 'Todo sobre este juego es genial. Tiene diversidad no solo en sus personajes, sino también en las emociones que te hace sentir por su historia', 'En pocas palabras, uno de los mejores juegos de lucha en 2D para PS4, Xbox One, PS3 e incluso consolas PS Vita', 'De lo contrario, BlazBlue sigue siendo el juego de lucha elegante, rápido, competitivo y vibrante que vimos en versiones anteriores', 'Uno de los mejores juegos que he jugado en mi vida. No es mentira que sea lo mismo con los otros 2 juegos de blazblue, pero eso no importa en absoluto', 'Para un modo de historia de estilo de novela visual y un juego de lucha, no podría pedir mucho más, es competitivo y desafiante en este último aspecto', 'Blood and Truth deja las viejas demostraciones tecnológicas glorificadas en el polvo y se da cuenta de todo el potencial de la realidad virtual con una increíble campaña de éxito que también es una carta de amor a la ciudad en la que está hecha', 'Desde la historia convincente y bien actuada hasta su combate atractivo, SIE London Studios ha brindado una de las mejores experiencias de realidad virtual en la plataforma de Sony', 'Simplemente un juego increíble con toda la emoción y la emoción que todos esperaban de la exageración de London Heist', 'A riesgo de sonar demasiado enamorado, no puedo comenzar a entender cómo demonios Torchlight II ha envejecido tan bien', 'Siete años después de su lanzamiento inicial, Torchlight 2 finalmente adorna la generación de la consola y demuestra que no tiene que tener Diablo en su título para tener un impacto', 'Una de las mejores sorpresas que tuve con un juego de rol de acción. Probablemente el que se siente más cercano también a diablo 2 en términos de todo, además del tema y las instrucciones de arte', 'BUENO: Excelente jugabilidad, toneladas de botines individuales, muchas misiones, niveles aleatorios, multijugador cooperativo, la capacidad de reproducción es excelente, mucho contenido por lo que cuesta', 'Tras alejar la acción de los oscuros túneles subterráneos de Moscú en un tren, ir a lo desconocido y obligarse a hacer paradas durante todo el viaje, los autores de Metro Exodus crearon una aventura interactiva memorable que consiste en la felicidad de descubrir el amor y el dolor por la pérdida irremplazable, esperanza de un futuro mejor y desesperación por entender la verdad', 'Así que siéntese y disfrute de la experiencia única, las maravillas visuales y los secretos más oscuros del querido universo Metro', 'Apocalypse es una expansión completa que redefine la guerra estelar para todos los jugadores con una serie de nuevas opciones ofensivas y defensivas', 'ssetto Corsa Competizione es un extraordinario juego de simulación de carreras que permite a los jugadores experimentar la atmósfera real de campeonatos', 'Sumérgete en un juego de disparos en primera persona impulsado por la acción, ambientado en un futuro universo de ciencia ficción creado por V1 Interactive', 'Uno de los mejores videojuegos que he jugado. Este juego siempre te mantendrá alerta cuando juegues a predator y fireteam. Como fanático personal de Predator, realmente disfruto de todas las referencias a las películas', 'Este es uno de los mejores JRPG que he jugado y créanme que he jugado mucho. Este juego tiene todo en una historia, momentos divertidos, capítulos embrujados que dan escalofríos, lo tiene todo, incluso los minijuegos se sienten bien. Toda mi familia está haciendo el minijuego de ejercicios en el gimnasio para superar mi puntaje más alto', 'Modern Warfare 2 vuelve con un buen trabajo de remasterización, pero que echa demasiado en falta su modo multijugador', 'Beyond Blue lleva a los jugadores al futuro cercano, donde tendrán la oportunidad de explorar los misterios de nuestro océano a través de los ojos de Mirai, un explorador y científico de las profundidades del mar', 'Bienvenido a Warzone: una nueva experiencia de combate en la que hasta 150 jugadores toman el papel de un veterano operador de nivel 1 y entran en el denso y extenso mundo de Verdansk', 'Modern Warfare 2 vuelve con un buen trabajo de remasterización, pero que echa demasiado en falta su modo multijugador', '¡¡¡MUY DIVERTIDO!!! Este juego es muy divertido ¡Definitivamente es una compra obligada! Este juego es divertido de jugar como Predator y el equipo de bomberos', 'Un gran juego de acción en 2D protagonizado por mechas: espectacular, variado y muy completo', 'Breeder Homegrown es un juego de terror corto sobre una familia que trata con una criatura extraña durante varias generaciones. Encontrarás algunos acertijos, pero el juego se basa principalmente en la atmósfera, la música y buenos diálogos', 'La separación es una aventura en primera persona en su forma más ambiental y atmosférica', 'Holfraine es un juego de disparos de héroes en tercera persona con diferentes personajes para elegir. Juega con tus compañeros de equipo y derrota al equipo contrario a través de partidos llenos de elementos dinámicos', 'Stab Stab Stab es un juego de apuñalamiento de arena basado en la física para jugadores múltiples para hasta cuatro jugadores. Juega como aves de carne explosivas con picos afilados', 'El juego es una dicha para jugar, mirar y escuchar. Los momentos de OG te llenarán de nostalgia, mientras que las partes nuevas y reimaginadas despertarán tu curiosidad por lo que está por venir. Square Enix enfrentó botas del tamaño de un océano, las llenó por completo y corrió a correr con ellas', 'Tempest es un juego de rol de acción pirata de mundo abierto que ofrece una capacidad máxima para recorrer libremente tres vastos mundos llenos de docenas de colonias y fortalezas, cientos de misiones e innumerables barcos para saquear. Intercambia, lucha, explora por tu cuenta o llama a tus amigos para que hagan lo mismo juntos', '¡El juego de golf para personas que odian el golf! Una tonta parodia de golf basada en la física donde cada campo de golf es un nuevo tipo sorprendente de golf, algunos brillantes o divertidos', 'Una guerra de fantasía sin fin Gran estrategia de simulación. Conquista el continente en este gran juego de simulación de estrategia. El continente de Runersia es el hogar de seis potencias principales con más de 40 bases, 100 caballeros y 50 tipos de monstruos', 'En el año 2091, los avances generalizados en tecnología e informática no han cambiado la naturaleza humana. Jugar con la vida de las personas nunca ha sido más divertido', 'Es un juego genial. Aunque igual creo que las partes no tan importantes las hicieron bastante largas pudiendo enfocarse en cubrir más historia. También entrando que sería difícil incluir en esta primera parte un mundo abierto al salir de midgar por lo que tal vez lo hicieron así y cortaron allí exactamente. Excelente Remake, espero la segunda parte con emoción y ojalá sea mundo abierto', 'Saints & Sinners es un juego diferente a cualquier otro en el universo de The Walking Dead. USTED impulsa cada desafío que enfrenta y la decisión que toma. Lucha contra los muertos vivientes, recorre las ruinas inundadas de Nueva Orleans y enfréntate a opciones desgarradoras para ti y los demás sobrevivientes', 'Juego increíblemente divertido, ya jugué varios partidos, hasta el nivel 10. Predator me asusta cuando me persigue, corro lo más rápido que puedo. ¡La animación de recolección de trofeos después de que te mate es INCREÍBLE! ¡Jugaré este juego por un tiempo!', 'Creo que es maravillosamente emocionante. Si obtiene apoyo y continúa creciendo, puede obtener el éxito que merece la fórmula', 'Daymare: 1998 es un juego de terror y supervivencia en tercera persona con cámara sobre el hombro, desarrollado en Unreal Engine 4 para PC con Windows. El juego presenta gráficos de alta gama, banda sonora original, atmósfera inmersiva, mecánica de supervivencia hardcore y muchas conexiones con los adorados juegos de terror de supervivencia de la vieja escuela', 'Experimente el paquete completo, remasterizado. Steelport, la ciudad original del pecado, nunca se había visto tan bien, ya que se ahoga en sexo, drogas y armas. Los Third Street Saints están a la altura del poder y los tuyos pueden controlar', 'Un juego de suspenso de investigación con narración no lineal, Telling Lies gira en torno a un caché de conversaciones de video grabadas en secreto', 'Además de presentar NPC totalmente expresados \\u200b\\u200bal mundo de Fallout 76, Wastelanders trae una nueva línea de búsqueda principal, nuevas ubicaciones, nuevos enemigos, nuevas armas, un nuevo sistema de reputación y mucho más', 'Beyond Blue lleva a los jugadores al futuro cercano, donde tendrán la oportunidad de explorar los misterios de nuestro océano a través de los ojos de Mirai, un explorador y científico de las profundidades del mar', 'Sube el puntaje en una pelea relajada o supera los límites de tus reflejos en este refinado simulador de béisbol. La tercera entrada de la serie presenta un modo de franquicia completamente nuevo, importantes mejoras gráficas y adiciones en el campo, incluidos los pickoffs y los rasgos situacionales del jugador', 'A través del juego, los jugadores pueden experimentar el miedo provocado por un terremoto y pueden aprender que la sabiduría, la valentía y el vínculo de las personas a través de la asistencia mutua son necesarias para la supervivencia', 'John Wick Hex es un juego de estrategia rápido y orientado a la acción que te hace pensar y golpear como John Wick, el asesino profesional de la franquicia cinematográfica aclamada por la crítica', 'Ellie se embarca en un viaje implacable para llevar a cabo la justicia y encontrar el cierre. Mientras caza a los responsables uno por uno, se enfrenta a las devastadoras repercusiones físicas y emocionales de sus acciones', 'Command & Conquer y Red Alert son remasterizados en 4K por los antiguos miembros del equipo de Westwood Studios. Incluye las 3 expansiones, multijugador reconstruido, una interfaz de usuario modernizada, Editor de mapas, galería de imágenes adicionales y más de 7 horas de música remasterizada', \"'Summer in Mara' es una aventura de verano con elementos fáciles de juegos de rol y mecánicas de cultivo, artesanía y exploración en un archipiélago tropical. 'Summer in Mara' es una experiencia para un jugador en un ambiente tranquilo y relajante, con un aspecto artesanal y una narrativa interesante. Serás Koa, una pequeña aventurera que quiere explorar el mundo que la rodea\", 'Monster Train es un juego de construcción de mazos roguelike estratégico con un toque diferente. Ubicado en un tren al infierno, usarás la toma de decisiones tácticas para defender múltiples campos de batalla verticales. Con el modo multijugador competitivo en tiempo real y la repetibilidad infinita, Monster Train siempre llega a tiempo', 'El juego está destinado a sumergirte en la mente de John, a medida que avanzas cada paso hacia el retorcido misterio de lo que sucedió', 'Probablemente el mejor juego que jugué en los últimos 10 años. Nuevos gráficos realistas, mecánica, el juego es simplemente increíble. 12/10', 'Sony San Diego evitó desarrollar viñetas llamativas en la parte posterior de la caja a favor de refinar un juego ya excelente, exhibiendo una confianza que en sí misma es notablemente notable, al igual que la consistencia de esta serie', 'MLB 15: The Show es el mejor juego de béisbol jamás creado. Pero lo hemos dicho antes sobre sus predecesores', 'Oye, como siempre digo, si no está roto, no lo arregles. Más de lo mismo, pero sigue siendo el mejor juego de deportes en este momento', 'Los gráficos son lentos, inconsistentes, con ralentizaciones extremas, desgarros y saltos de fotogramas', 'Fps muy bajos en Ps4 Pro, por lo que el juego no se puede jugar y Graphic es horrible', 'este juego es realmente malo, baja fps, retraso, mala física y más', 'La gente quiere jugar este juego para la historia, pero la historia es muy mala', 'Después de más de una docena de horas, puedo decir que el juego está dolorosamente sobrevalorado', 'Uno de los peores juegos que jugué últimamente', 'Este es uno de esos grandes juegos bellamente aburridos que tiene 1 fuente de logro, el realismo, y no es divertido', 'fue un juego muy horrible, no entiendo por qué xcom2 ha producido una acción muy mala y muy mala cuando jugué este juego, me río, fue muy horrible', 'En pocas palabras, ni siquiera sé cómo llegó al mercado. terrible juego, pistolas y mapas', 'El lanzamiento de Out of Ammo suena interesante en el papel, pero la ejecución es probablemente el peor juego de PSVR que he jugado', 'El juego es literalmente terrible. El juego tiene gráficos muy pobres y se siente muy insensible', 'El juego es horrible. Shooter en primera persona que corre como mi nan', 'Juego muy malo y aburrido. Casi me quedo dormido jugando este maldito juego. Simplemente no lo compres', 'Una experiencia mediocre que es menos horror psicológico que tortura. Hay mejores experiencias de terror por ahí', 'David Lynch no tiene miedo de hacer arte impenetrable, difícil de interpretar. Eso es parte de su genio: lo absurdo del horror, la belleza natural de lo misterios', 'El juego es una degradación de Doom 1 en muchos aspectos. ¿Más atroz? Cuando el juego se bloquea, comienza de nuevo al INICIO DEL NIVEL', 'Super Soccer Blast es un juego de deportes de estilo arcade. No es realista Como un juego de fútbol que se apoya fuertemente en una actitud arcade, en lugar de una simulación directa', '1971 Project Heliosis es un juego de estrategia por turnos que combina tácticas militares de guerra moderna y combate cuerpo a cuerpo. Las armas de fuego y los vehículos son escasos, los conflictos y las hostilidades no tienen fin, y el terrible frío helado aniquila a sus amigos y enemigos a su paso', 'Juego muy malo y aburrido. Casi me quedo dormido jugando este maldito juego. Simplemente no lo compres', 'Ion Fury canaliza sin esfuerzo el espíritu de los tiradores de la vieja escuela como Duke Nukem 3D, pero la acción se ralentiza por el retroceso aburrido y los acertijos ambientales', 'Gráficos horribles, tiempos de carga extremadamente largos y frecuentes, juego repetitivo, actuación de voz de nivel C y una historia sin inspiración hacen que sea un paquete extremadamente difícil de justificar', 'Horrible sistema de guardado en el que si tu personaje muere, te lleva de vuelta al juego, salvo en mi caso, estuve a 3/4 de un rompecabezas y dos choques, mi personaje muere y la salvación me llevó todo el camino de regreso para guardar el juego y tuve que comenzar el rompecabezas desde cero nuevamente', 'Lo último para terminarlo me pareció frustrantemente incómodo, casi imposible. En un hilo de Steam, los desarrolladores dijeron que había un parche para este problema, tal vez quieras intentar parchar la versión de PS4 eh lads. Arruinar un juego perfectamente bueno le habría dado un respetable 4, menos 3 por un jodky de mala calidad', 'Este no es un buen juego! Si se tratara de un juego f2p con algunos cosméticos y potenciadores de XP, este juego sería para 8, incluso 9, ¡pero no lo es! Yo pago esta mierda 45 euros! ¡Después de cinco rondas de esto, obtienes todo literalmente todo!', 'juego horrible con mala calidad, ¡no era lo que esperaba! ¡No malgastes tu dinero en un juego así!', 'Además de horribles emparejamientos y una gran cantidad de fallas técnicas, Predator: Hunting Grounds está terriblemente desequilibrado, se ve francamente feo, carece de variedad y es simplemente desagradable de jugar', 'Wow este juego es malo! ¡Y ya están llegando las 10 falsas 10 reseñas! 10 de 10 es? el mejor juego de todos, ¿sí? ridículo. Malos gráficos, espantosos enemigos con esponjas de bala AI y algunos diseños de juegos realmente malos en general', 'Dios mío, este juego es una desgracia, no puedo en serio, lo intento, pero Nop, si quieres malgastar tu dinero Ok, es tu propia elección', 'juego horrible con mala calidad, ¡no era lo que esperaba! ¡No malgastes tu dinero en un juego así', 'Este juego es bastante pobre, lo compré porque se ve decente en los videos de YouTube (pero eso se veía en una pantalla muy pequeña), pero al jugar en una pantalla grande notarás que los gráficos son realmente algo de la era de la ps3, así que son las mecánicas de juego', 'Soy un gran fanático de Predator, pero qué puedo decir ... Predator Hunting grounds es uno de los juegos más basura que he jugado. Error, errores y más errores. ¿Por qué lanzaron este juego realmente? Uno de los peores, si no los peores juegos que he tenido la desgracia de jugar', 'Este juego no vale su precio actual. Recomendaría comprarlo cuando esté a la venta. No valía la pena hacer un pedido por adelantado y muestra que otro estudio envía un mal producto que ni siquiera se siente completo', 'Muchos problemas: colisión, equilibrio, saltos, retrasos, trampas de colisión, emparejamiento infinito. El juego es demasiado crudo en el lanzamiento', 'Probablemente sea uno de los peores remasterizadores de todos los tiempos, con una tasa de fotogramas horrible de retraso malo y se bloquea a menudo, los edificios y estructuras que apenas se cargan en Hanger 13 no deberían haberse molestado con un remaster porque el juego anterior funciona mucho mejor que el remaster', 'Ugh Las imágenes son lo único que ofrece este juego. Los escritores de la historia deben haber llamado por teléfono en este juego, o haber sido reemplazados, ya que termina siendo una secuela menos divertida de un gran juego y más un comercial de 10 horas de duración para cualquier agenda que quieran impulsar', 'Este juego es una pena, siete años esperando una gran secuela y crean una historia ridícula como esa, la prioridad no eran los fanáticos sino poner todas las agendas posibles en un juego. Incluso un niño de cinco años habría hecho una mejor historia', 'Este es honestamente uno de los peores juegos que he jugado', 'No sé qué juegan las personas que califican esto como 10, aparte de la creación del personaje, este juego es súper promedio. La historia es mediocre, el combate es torpe y este juego no tiene nada de especial. Una calificación tan alta solo le dice a Bandai que pueden seguir haciendo juegos mediocres siempre que tengan una buena personalización', 'No lo disfruté, las peleas no fueron divertidas y no me gustó mucho la historia. Sin embargo, estoy feliz de que la gente lo haya disfrutado', 'El diseño de niveles es tan malo, como un corredor de laberintos con enemigos en cada esquina. Sin peso en el impacto. Estuve esperando este juego por más de 2 años, omg tal decepcionante. Ni siquiera podía esperar el final, lo vendí y quiero olvidarlo', 'Fue muy malo El combate y los gráficos no parecen pertenecer a esta generación', 'Este juego tiene un diseño de ubicación deficiente, diseño de arma pobre, falta de equilibrio en un juego en solitario, hay muy pocos velos', 'Es patético que alguien mencione el surge 2 y las almas oscuras en la misma oración, The Surge 2 es pura basura, después del primer juego, que fue agradable y bien hecho, incluso si estaba sin pulir y un poco áspero en algunos lugares, fue sigue siendo una buena plataforma para avanzar', 'Horrible. ¿Cómo logró ser PEOR que el primer juego, que fue malo, pero no tan malo! Extremadamente aburrido y aburrido, evítalo a toda costa', 'Esperaba mas de este juego pero la verdad no me gustó es todo lo que tengo que decir', 'La escritura es terriblemente aburrida ... Para empeorar las cosas, la mecánica de combate es la peor que he visto. Estar atrapado en un espacio cerrado con un jefe abrumado desde el principio, y el juego tiene un cuello de botella para que no puedas avanzar más allá del principio sin vencerlo', 'Muy, muy mal juego y fluidez del juego. La suavidad del juego es horrible. IU de los años 90', 'Honestamente, estoy realmente decepcionado, especialmente porque este juego cuesta $ 75 en total. Hay un dlc de 0 días, y el juego es muy subóptimo. Parece bastante defectuoso, y su calidad de gráficos no se parece en nada al tráiler, lo que me hace sentir extremadamente decepcionado', 'Mecánica torpe y una historia ridículamente aburrida. Los personajes eran finos como el papel y completamente inmemorables, incluido el protagonista', 'La historia es irrelevante. El juego no es divertido en absoluto. Puedes matar el tiempo jugando Chaosbane mientras esperas un mejor juego', 'La jugabilidad es tan repetitiva y lo ha visto todo antes y, para empeorar las cosas, tiene problemas de ritmo de cuadro y aparece.¡No vale la pena acercarse al precio completo!', 'El juego arruina mucho de lo que se puede amar de MK. La lucha es decente, pero todo lo demás, desde las terminaciones de la torre fuera de lugar hasta una rutina loca para siempre en línea, daña la experiencia', 'romesas incumplidas y muchas mentiras. El peor juego de toda la franquicia', 'Esto es una vergüenza para un juego de Mortal Kombat, siempre un infierno de micro transacciones en línea con una actuación de voz terrible, los diseños de personajes son feos de ver y tiene sentido de justicia social', 'The War Machine es una vez más otro pobre esfuerzo para inyectar vida en un juego rancio, sin inspiración y roto', 'El peor juego del mundo para jugarlo es cómo golpear tu cabeza contra una pared. No sé a qué nivel debería ser el intelecto', 'Muy flojo. el modo zombie no es rejugable aburre en cuanto haces el huevo de pascua', 'Al final, Rise of Iron es, literalmente, más Destino. No aborda ninguno de los problemas que podría haber tenido con el original, y tampoco elimina el mundo existente', 'STAY no puede ser criticado por sus aspiraciones y el intento de hacer un personaje creíble en Quinn, para crear un individuo que el jugador quiera ayudar. Sin embargo, el resultado es una corriente casi interminable de diálogo mediocre que hizo increíblemente difícil quedarse hasta el final', 'Imagina el nuevo Doom en VR y completamente imposible de jugar', 'Si bien DOOM: VFR puede ser un juego divertido, la falta de ultraviolencia y el corto tiempo de juego eclipsan la diversión que ofrece DOOM: VFR, especialmente a su precio actual', 'Inacabado, rediseños pobres del elenco principal, y cambió un montón de efectos de sonido del arma', \"Con este segundo episodio, The Legacy of the First Blade arma todo el juego de roles que Ubisoft pasó decenas de horas para construir en una historia corta y altamente cuestionable de tres horas. Incluso los grandes acorazados y una nueva arma no salvarán a Assassin's Creed Odyssey de este cliffhanger equivocado que podría decepcionar a la mayoría de los aventureros\", 'Mutant Football League es un juego deportivo arcade barato y mal ejecutado. Creo que los desarrolladores entraron con todas las intenciones correctas, porque realmente no se están haciendo suficientes juegos deportivos para las personas que no están dispuestas a poner un gran compromiso en el juego para poder apreciarlo en cualquier nivel', 'Si bien Fantastic Contraption lo alienta a ser creativo, inmediatamente lo encajona al mismo tiempo con un número limitado de soluciones e incluso menos herramientas', 'Gráficamente seguro como está, casi todos los demás elementos de la serie de 15 años han sido recortados, manipulados sin sentido o directamente arruinados. La serie no ha sido buena desde hace mucho tiempo, pero este año es la primera que ha sido activamente mala', 'Desafortunadamente, los mejores atributos de Island Time VR, las imágenes y la actuación de voz, se ven eclipsados \\u200b\\u200bpor algunos defectos muy importantes en el juego repetitivo, un tiempo de ejecución muy corto y errores que rompen el juego', 'Si no estás discutiendo con tus amigos sobre si Naruto vencería a Goku y no estás rezando por la cuarta temporada de \"Jojo\\'s Bizarre Adventure\", no hay absolutamente ninguna razón para que te preocupes por este juego de lucha realmente débil', 'La Iglesia en la Oscuridad quiere ser un juego de sigilo que te ponga en medio de un culto del fin del mundo. En consecuencia, en lugar de darte una idea del mundo de un culto, obtienes un juego aburrido que te hará apreciar cómo para evitar el campo de visión de alguien', 'El componente interactivo real de The Grand Tour Game es realmente bastante pobre, con un manejo horrible y una presentación anticuada que hace que las carreras y los desafíos sean muy inferiores a los segmentos que intentan reemplazar, entre los clips del programa que ya has visto', 'De alguna manera, este juego es peor que el primero. El combate es malo, los gráficos apestan, la historia es confusa. El balanceo es malo y no es práctico en absoluto. Además, tiene errores como el infierno. Quizás el peor juego de Spider-Man', 'Tiene muchos errores, modo historia no completado y bajo nivel de contenido. No recomiendo comprarlo ahora mismo', 'Aquí vamos de nuevo, otro episodio completamente decepcionante de una franquicia tan (solía ser). Me siento mal por aquellos que prueban esto antes de probar el primer juego, si incluso probarán el primer juego después de jugar esto', 'En retrospectiva, no debería haber dado cero al primer episodio porque este episodio es incluso peor que el primero', 'El problema con el juego es que tiene muchos errores como: estaba luchando contra un jefe, y no tenían corazones, pero no fueron derrotados, me hizo reiniciar todo el nivel, otra vez tuve que destruir algo para avanzar a un nivel, pero no se rompería, tuve que reiniciar esa parte también. He descubierto que este juego tiene muchos errores para un juego de DC', 'Una buena formación de canciones pero problemas serios. No puedo creer que no hayan mejorado el soporte de la cámara']\n",
            "152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xza7RbWK1dbB",
        "colab_type": "text"
      },
      "source": [
        "Por utlimo, se imprime un texto entero con todos los textos unificados. Es importante tener una sola ***cadena*** con todos los textos, ya que ello facilita el análisis respecto a ***tokens*** que se realizará´posteriormente. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYNiqQI2XwUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f2f1eada-f34a-47a8-ac26-0466d6694e10"
      },
      "source": [
        "print(texto)\n",
        "doc = nlp(texto)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Este juego tiene todo lo que puedes pedir en un juego Iron Man VR Este es uno de los mejores juegos de PSVR que he jugado Muy buena experiencia de juego y diversión te está esperando Increíble juego, me encanta la historia y el personaje Increíble no solo para los amantes occidentales Con su increíble historia de mundo abierto, bien escrita y personajes profundos, Red Dead Redemption II es una montaña rusa llena de emociones Este juego es una obra maestra de la narración de cuentos, recomiendo a cualquiera con Ps4 que juegue este juego El nuevo comienzo de Kratos está lleno de corazón, cargado de acción y es fácilmente uno de los mejores juegos de esta generación Una expansión excepcionalmente buena que agrega una montaña de contenido nuevo que aborda específicamente los pocos defectos que había con el original La naturaleza del nuevo Hitman está bien establecida, las tareas siempre están bien hechas y son muy divertidas de jugar Los episodios más recientes continúan con la mejora constante de la calidad de Hitman. Marrakech ofrece un área de juegos aún más grande e impresionante con mucha más libertad de acción, al tiempo que presenta un desafío mayor Persona 5 ya era un líder fuerte por ser el mejor JRPG jamás creado, y Royal realmente me hace preguntarme qué más podría incluso competir Bellamente mejorado y, en su esencia, una mezcla tremendamente fascinante de la rutina diaria de la escuela secundaria y el extraño thriller de misterio La cantidad de cambio aportado al título es significativa, y todo parece una mejora notable. Para un juego que ya era uno de los mejores JRPG de los últimos años, Persona 5 Royal es una continuación que se consolida como una experiencia que vale la pena repetir en lugar de una secuela de Persona adecuada Literalmente acaba de hacer el juego original, que fue uno de los mejores JRPG de todos los tiempos, mejor Utilizando disparos rápidos en primera persona como marco, cada secuela ha mejorado enormemente el diseño de niveles, una selección más amplia de demonios para masacrar y un arsenal más grande que se une para refinar su identidad central de la manera más inteligente y respetuosa posible Un juego fantástico, que toma todos los elementos que hicieron de DOOM 2016 un reinicio tan sorprendente de la franquicia e implementó docenas de nuevos conceptos de una manera que hace que toda la experiencia se sienta fresca nuevamente DOOM Eternal superó las expectativas, tanto en lo que respecta a la dificultad como al disfrute, y aunque no sin sus fallas, se siente como un juego imprescindible para los jugadores de FPS Un juego hermoso, difícil de entender sin conocer la historia del creador pero tan inmersivo ... La música es fantástica y es un placer vivirla de principio a fin Puyo Puyo Champions ofrece un juego de rompecabezas competitivo familiar y divertido con una gran selección de personajes encantadores En general, Blazblu Chronophantasma Extend es imprescindible para cualquiera que esté interesado en sus juegos de lucha y esto está a la altura de cualquier cosa en la PS4 Todo sobre este juego es genial. Tiene diversidad no solo en sus personajes, sino también en las emociones que te hace sentir por su historia En pocas palabras, uno de los mejores juegos de lucha en 2D para PS4, Xbox One, PS3 e incluso consolas PS Vita De lo contrario, BlazBlue sigue siendo el juego de lucha elegante, rápido, competitivo y vibrante que vimos en versiones anteriores Uno de los mejores juegos que he jugado en mi vida. No es mentira que sea lo mismo con los otros 2 juegos de blazblue, pero eso no importa en absoluto Para un modo de historia de estilo de novela visual y un juego de lucha, no podría pedir mucho más, es competitivo y desafiante en este último aspecto Blood and Truth deja las viejas demostraciones tecnológicas glorificadas en el polvo y se da cuenta de todo el potencial de la realidad virtual con una increíble campaña de éxito que también es una carta de amor a la ciudad en la que está hecha Desde la historia convincente y bien actuada hasta su combate atractivo, SIE London Studios ha brindado una de las mejores experiencias de realidad virtual en la plataforma de Sony Simplemente un juego increíble con toda la emoción y la emoción que todos esperaban de la exageración de London Heist A riesgo de sonar demasiado enamorado, no puedo comenzar a entender cómo demonios Torchlight II ha envejecido tan bien Siete años después de su lanzamiento inicial, Torchlight 2 finalmente adorna la generación de la consola y demuestra que no tiene que tener Diablo en su título para tener un impacto Una de las mejores sorpresas que tuve con un juego de rol de acción. Probablemente el que se siente más cercano también a diablo 2 en términos de todo, además del tema y las instrucciones de arte BUENO: Excelente jugabilidad, toneladas de botines individuales, muchas misiones, niveles aleatorios, multijugador cooperativo, la capacidad de reproducción es excelente, mucho contenido por lo que cuesta Tras alejar la acción de los oscuros túneles subterráneos de Moscú en un tren, ir a lo desconocido y obligarse a hacer paradas durante todo el viaje, los autores de Metro Exodus crearon una aventura interactiva memorable que consiste en la felicidad de descubrir el amor y el dolor por la pérdida irremplazable, esperanza de un futuro mejor y desesperación por entender la verdad Así que siéntese y disfrute de la experiencia única, las maravillas visuales y los secretos más oscuros del querido universo Metro Apocalypse es una expansión completa que redefine la guerra estelar para todos los jugadores con una serie de nuevas opciones ofensivas y defensivas ssetto Corsa Competizione es un extraordinario juego de simulación de carreras que permite a los jugadores experimentar la atmósfera real de campeonatos Sumérgete en un juego de disparos en primera persona impulsado por la acción, ambientado en un futuro universo de ciencia ficción creado por V1 Interactive Uno de los mejores videojuegos que he jugado. Este juego siempre te mantendrá alerta cuando juegues a predator y fireteam. Como fanático personal de Predator, realmente disfruto de todas las referencias a las películas Este es uno de los mejores JRPG que he jugado y créanme que he jugado mucho. Este juego tiene todo en una historia, momentos divertidos, capítulos embrujados que dan escalofríos, lo tiene todo, incluso los minijuegos se sienten bien. Toda mi familia está haciendo el minijuego de ejercicios en el gimnasio para superar mi puntaje más alto Modern Warfare 2 vuelve con un buen trabajo de remasterización, pero que echa demasiado en falta su modo multijugador Beyond Blue lleva a los jugadores al futuro cercano, donde tendrán la oportunidad de explorar los misterios de nuestro océano a través de los ojos de Mirai, un explorador y científico de las profundidades del mar Bienvenido a Warzone: una nueva experiencia de combate en la que hasta 150 jugadores toman el papel de un veterano operador de nivel 1 y entran en el denso y extenso mundo de Verdansk Modern Warfare 2 vuelve con un buen trabajo de remasterización, pero que echa demasiado en falta su modo multijugador ¡¡¡MUY DIVERTIDO!!! Este juego es muy divertido ¡Definitivamente es una compra obligada! Este juego es divertido de jugar como Predator y el equipo de bomberos Un gran juego de acción en 2D protagonizado por mechas: espectacular, variado y muy completo Breeder Homegrown es un juego de terror corto sobre una familia que trata con una criatura extraña durante varias generaciones. Encontrarás algunos acertijos, pero el juego se basa principalmente en la atmósfera, la música y buenos diálogos La separación es una aventura en primera persona en su forma más ambiental y atmosférica Holfraine es un juego de disparos de héroes en tercera persona con diferentes personajes para elegir. Juega con tus compañeros de equipo y derrota al equipo contrario a través de partidos llenos de elementos dinámicos Stab Stab Stab es un juego de apuñalamiento de arena basado en la física para jugadores múltiples para hasta cuatro jugadores. Juega como aves de carne explosivas con picos afilados El juego es una dicha para jugar, mirar y escuchar. Los momentos de OG te llenarán de nostalgia, mientras que las partes nuevas y reimaginadas despertarán tu curiosidad por lo que está por venir. Square Enix enfrentó botas del tamaño de un océano, las llenó por completo y corrió a correr con ellas Tempest es un juego de rol de acción pirata de mundo abierto que ofrece una capacidad máxima para recorrer libremente tres vastos mundos llenos de docenas de colonias y fortalezas, cientos de misiones e innumerables barcos para saquear. Intercambia, lucha, explora por tu cuenta o llama a tus amigos para que hagan lo mismo juntos ¡El juego de golf para personas que odian el golf! Una tonta parodia de golf basada en la física donde cada campo de golf es un nuevo tipo sorprendente de golf, algunos brillantes o divertidos Una guerra de fantasía sin fin Gran estrategia de simulación. Conquista el continente en este gran juego de simulación de estrategia. El continente de Runersia es el hogar de seis potencias principales con más de 40 bases, 100 caballeros y 50 tipos de monstruos En el año 2091, los avances generalizados en tecnología e informática no han cambiado la naturaleza humana. Jugar con la vida de las personas nunca ha sido más divertido Es un juego genial. Aunque igual creo que las partes no tan importantes las hicieron bastante largas pudiendo enfocarse en cubrir más historia. También entrando que sería difícil incluir en esta primera parte un mundo abierto al salir de midgar por lo que tal vez lo hicieron así y cortaron allí exactamente. Excelente Remake, espero la segunda parte con emoción y ojalá sea mundo abierto Saints & Sinners es un juego diferente a cualquier otro en el universo de The Walking Dead. USTED impulsa cada desafío que enfrenta y la decisión que toma. Lucha contra los muertos vivientes, recorre las ruinas inundadas de Nueva Orleans y enfréntate a opciones desgarradoras para ti y los demás sobrevivientes Juego increíblemente divertido, ya jugué varios partidos, hasta el nivel 10. Predator me asusta cuando me persigue, corro lo más rápido que puedo. ¡La animación de recolección de trofeos después de que te mate es INCREÍBLE! ¡Jugaré este juego por un tiempo! Creo que es maravillosamente emocionante. Si obtiene apoyo y continúa creciendo, puede obtener el éxito que merece la fórmula Daymare: 1998 es un juego de terror y supervivencia en tercera persona con cámara sobre el hombro, desarrollado en Unreal Engine 4 para PC con Windows. El juego presenta gráficos de alta gama, banda sonora original, atmósfera inmersiva, mecánica de supervivencia hardcore y muchas conexiones con los adorados juegos de terror de supervivencia de la vieja escuela Experimente el paquete completo, remasterizado. Steelport, la ciudad original del pecado, nunca se había visto tan bien, ya que se ahoga en sexo, drogas y armas. Los Third Street Saints están a la altura del poder y los tuyos pueden controlar Un juego de suspenso de investigación con narración no lineal, Telling Lies gira en torno a un caché de conversaciones de video grabadas en secreto Además de presentar NPC totalmente expresados ​​al mundo de Fallout 76, Wastelanders trae una nueva línea de búsqueda principal, nuevas ubicaciones, nuevos enemigos, nuevas armas, un nuevo sistema de reputación y mucho más Beyond Blue lleva a los jugadores al futuro cercano, donde tendrán la oportunidad de explorar los misterios de nuestro océano a través de los ojos de Mirai, un explorador y científico de las profundidades del mar Sube el puntaje en una pelea relajada o supera los límites de tus reflejos en este refinado simulador de béisbol. La tercera entrada de la serie presenta un modo de franquicia completamente nuevo, importantes mejoras gráficas y adiciones en el campo, incluidos los pickoffs y los rasgos situacionales del jugador A través del juego, los jugadores pueden experimentar el miedo provocado por un terremoto y pueden aprender que la sabiduría, la valentía y el vínculo de las personas a través de la asistencia mutua son necesarias para la supervivencia John Wick Hex es un juego de estrategia rápido y orientado a la acción que te hace pensar y golpear como John Wick, el asesino profesional de la franquicia cinematográfica aclamada por la crítica Ellie se embarca en un viaje implacable para llevar a cabo la justicia y encontrar el cierre. Mientras caza a los responsables uno por uno, se enfrenta a las devastadoras repercusiones físicas y emocionales de sus acciones Command & Conquer y Red Alert son remasterizados en 4K por los antiguos miembros del equipo de Westwood Studios. Incluye las 3 expansiones, multijugador reconstruido, una interfaz de usuario modernizada, Editor de mapas, galería de imágenes adicionales y más de 7 horas de música remasterizada 'Summer in Mara' es una aventura de verano con elementos fáciles de juegos de rol y mecánicas de cultivo, artesanía y exploración en un archipiélago tropical. 'Summer in Mara' es una experiencia para un jugador en un ambiente tranquilo y relajante, con un aspecto artesanal y una narrativa interesante. Serás Koa, una pequeña aventurera que quiere explorar el mundo que la rodea Monster Train es un juego de construcción de mazos roguelike estratégico con un toque diferente. Ubicado en un tren al infierno, usarás la toma de decisiones tácticas para defender múltiples campos de batalla verticales. Con el modo multijugador competitivo en tiempo real y la repetibilidad infinita, Monster Train siempre llega a tiempo El juego está destinado a sumergirte en la mente de John, a medida que avanzas cada paso hacia el retorcido misterio de lo que sucedió Probablemente el mejor juego que jugué en los últimos 10 años. Nuevos gráficos realistas, mecánica, el juego es simplemente increíble. 12/10 Sony San Diego evitó desarrollar viñetas llamativas en la parte posterior de la caja a favor de refinar un juego ya excelente, exhibiendo una confianza que en sí misma es notablemente notable, al igual que la consistencia de esta serie MLB 15: The Show es el mejor juego de béisbol jamás creado. Pero lo hemos dicho antes sobre sus predecesores Oye, como siempre digo, si no está roto, no lo arregles. Más de lo mismo, pero sigue siendo el mejor juego de deportes en este momento Los gráficos son lentos, inconsistentes, con ralentizaciones extremas, desgarros y saltos de fotogramas Fps muy bajos en Ps4 Pro, por lo que el juego no se puede jugar y Graphic es horrible este juego es realmente malo, baja fps, retraso, mala física y más La gente quiere jugar este juego para la historia, pero la historia es muy mala Después de más de una docena de horas, puedo decir que el juego está dolorosamente sobrevalorado Uno de los peores juegos que jugué últimamente Este es uno de esos grandes juegos bellamente aburridos que tiene 1 fuente de logro, el realismo, y no es divertido fue un juego muy horrible, no entiendo por qué xcom2 ha producido una acción muy mala y muy mala cuando jugué este juego, me río, fue muy horrible En pocas palabras, ni siquiera sé cómo llegó al mercado. terrible juego, pistolas y mapas El lanzamiento de Out of Ammo suena interesante en el papel, pero la ejecución es probablemente el peor juego de PSVR que he jugado El juego es literalmente terrible. El juego tiene gráficos muy pobres y se siente muy insensible El juego es horrible. Shooter en primera persona que corre como mi nan Juego muy malo y aburrido. Casi me quedo dormido jugando este maldito juego. Simplemente no lo compres Una experiencia mediocre que es menos horror psicológico que tortura. Hay mejores experiencias de terror por ahí David Lynch no tiene miedo de hacer arte impenetrable, difícil de interpretar. Eso es parte de su genio: lo absurdo del horror, la belleza natural de lo misterios El juego es una degradación de Doom 1 en muchos aspectos. ¿Más atroz? Cuando el juego se bloquea, comienza de nuevo al INICIO DEL NIVEL Super Soccer Blast es un juego de deportes de estilo arcade. No es realista Como un juego de fútbol que se apoya fuertemente en una actitud arcade, en lugar de una simulación directa 1971 Project Heliosis es un juego de estrategia por turnos que combina tácticas militares de guerra moderna y combate cuerpo a cuerpo. Las armas de fuego y los vehículos son escasos, los conflictos y las hostilidades no tienen fin, y el terrible frío helado aniquila a sus amigos y enemigos a su paso Juego muy malo y aburrido. Casi me quedo dormido jugando este maldito juego. Simplemente no lo compres Ion Fury canaliza sin esfuerzo el espíritu de los tiradores de la vieja escuela como Duke Nukem 3D, pero la acción se ralentiza por el retroceso aburrido y los acertijos ambientales Gráficos horribles, tiempos de carga extremadamente largos y frecuentes, juego repetitivo, actuación de voz de nivel C y una historia sin inspiración hacen que sea un paquete extremadamente difícil de justificar Horrible sistema de guardado en el que si tu personaje muere, te lleva de vuelta al juego, salvo en mi caso, estuve a 3/4 de un rompecabezas y dos choques, mi personaje muere y la salvación me llevó todo el camino de regreso para guardar el juego y tuve que comenzar el rompecabezas desde cero nuevamente Lo último para terminarlo me pareció frustrantemente incómodo, casi imposible. En un hilo de Steam, los desarrolladores dijeron que había un parche para este problema, tal vez quieras intentar parchar la versión de PS4 eh lads. Arruinar un juego perfectamente bueno le habría dado un respetable 4, menos 3 por un jodky de mala calidad Este no es un buen juego! Si se tratara de un juego f2p con algunos cosméticos y potenciadores de XP, este juego sería para 8, incluso 9, ¡pero no lo es! Yo pago esta mierda 45 euros! ¡Después de cinco rondas de esto, obtienes todo literalmente todo! juego horrible con mala calidad, ¡no era lo que esperaba! ¡No malgastes tu dinero en un juego así! Además de horribles emparejamientos y una gran cantidad de fallas técnicas, Predator: Hunting Grounds está terriblemente desequilibrado, se ve francamente feo, carece de variedad y es simplemente desagradable de jugar Wow este juego es malo! ¡Y ya están llegando las 10 falsas 10 reseñas! 10 de 10 es? el mejor juego de todos, ¿sí? ridículo. Malos gráficos, espantosos enemigos con esponjas de bala AI y algunos diseños de juegos realmente malos en general Dios mío, este juego es una desgracia, no puedo en serio, lo intento, pero Nop, si quieres malgastar tu dinero Ok, es tu propia elección juego horrible con mala calidad, ¡no era lo que esperaba! ¡No malgastes tu dinero en un juego así Este juego es bastante pobre, lo compré porque se ve decente en los videos de YouTube (pero eso se veía en una pantalla muy pequeña), pero al jugar en una pantalla grande notarás que los gráficos son realmente algo de la era de la ps3, así que son las mecánicas de juego Soy un gran fanático de Predator, pero qué puedo decir ... Predator Hunting grounds es uno de los juegos más basura que he jugado. Error, errores y más errores. ¿Por qué lanzaron este juego realmente? Uno de los peores, si no los peores juegos que he tenido la desgracia de jugar Este juego no vale su precio actual. Recomendaría comprarlo cuando esté a la venta. No valía la pena hacer un pedido por adelantado y muestra que otro estudio envía un mal producto que ni siquiera se siente completo Muchos problemas: colisión, equilibrio, saltos, retrasos, trampas de colisión, emparejamiento infinito. El juego es demasiado crudo en el lanzamiento Probablemente sea uno de los peores remasterizadores de todos los tiempos, con una tasa de fotogramas horrible de retraso malo y se bloquea a menudo, los edificios y estructuras que apenas se cargan en Hanger 13 no deberían haberse molestado con un remaster porque el juego anterior funciona mucho mejor que el remaster Ugh Las imágenes son lo único que ofrece este juego. Los escritores de la historia deben haber llamado por teléfono en este juego, o haber sido reemplazados, ya que termina siendo una secuela menos divertida de un gran juego y más un comercial de 10 horas de duración para cualquier agenda que quieran impulsar Este juego es una pena, siete años esperando una gran secuela y crean una historia ridícula como esa, la prioridad no eran los fanáticos sino poner todas las agendas posibles en un juego. Incluso un niño de cinco años habría hecho una mejor historia Este es honestamente uno de los peores juegos que he jugado No sé qué juegan las personas que califican esto como 10, aparte de la creación del personaje, este juego es súper promedio. La historia es mediocre, el combate es torpe y este juego no tiene nada de especial. Una calificación tan alta solo le dice a Bandai que pueden seguir haciendo juegos mediocres siempre que tengan una buena personalización No lo disfruté, las peleas no fueron divertidas y no me gustó mucho la historia. Sin embargo, estoy feliz de que la gente lo haya disfrutado El diseño de niveles es tan malo, como un corredor de laberintos con enemigos en cada esquina. Sin peso en el impacto. Estuve esperando este juego por más de 2 años, omg tal decepcionante. Ni siquiera podía esperar el final, lo vendí y quiero olvidarlo Fue muy malo El combate y los gráficos no parecen pertenecer a esta generación Este juego tiene un diseño de ubicación deficiente, diseño de arma pobre, falta de equilibrio en un juego en solitario, hay muy pocos velos Es patético que alguien mencione el surge 2 y las almas oscuras en la misma oración, The Surge 2 es pura basura, después del primer juego, que fue agradable y bien hecho, incluso si estaba sin pulir y un poco áspero en algunos lugares, fue sigue siendo una buena plataforma para avanzar Horrible. ¿Cómo logró ser PEOR que el primer juego, que fue malo, pero no tan malo! Extremadamente aburrido y aburrido, evítalo a toda costa Esperaba mas de este juego pero la verdad no me gustó es todo lo que tengo que decir La escritura es terriblemente aburrida ... Para empeorar las cosas, la mecánica de combate es la peor que he visto. Estar atrapado en un espacio cerrado con un jefe abrumado desde el principio, y el juego tiene un cuello de botella para que no puedas avanzar más allá del principio sin vencerlo Muy, muy mal juego y fluidez del juego. La suavidad del juego es horrible. IU de los años 90 Honestamente, estoy realmente decepcionado, especialmente porque este juego cuesta $ 75 en total. Hay un dlc de 0 días, y el juego es muy subóptimo. Parece bastante defectuoso, y su calidad de gráficos no se parece en nada al tráiler, lo que me hace sentir extremadamente decepcionado Mecánica torpe y una historia ridículamente aburrida. Los personajes eran finos como el papel y completamente inmemorables, incluido el protagonista La historia es irrelevante. El juego no es divertido en absoluto. Puedes matar el tiempo jugando Chaosbane mientras esperas un mejor juego La jugabilidad es tan repetitiva y lo ha visto todo antes y, para empeorar las cosas, tiene problemas de ritmo de cuadro y aparece.¡No vale la pena acercarse al precio completo! El juego arruina mucho de lo que se puede amar de MK. La lucha es decente, pero todo lo demás, desde las terminaciones de la torre fuera de lugar hasta una rutina loca para siempre en línea, daña la experiencia romesas incumplidas y muchas mentiras. El peor juego de toda la franquicia Esto es una vergüenza para un juego de Mortal Kombat, siempre un infierno de micro transacciones en línea con una actuación de voz terrible, los diseños de personajes son feos de ver y tiene sentido de justicia social The War Machine es una vez más otro pobre esfuerzo para inyectar vida en un juego rancio, sin inspiración y roto El peor juego del mundo para jugarlo es cómo golpear tu cabeza contra una pared. No sé a qué nivel debería ser el intelecto Muy flojo. el modo zombie no es rejugable aburre en cuanto haces el huevo de pascua Al final, Rise of Iron es, literalmente, más Destino. No aborda ninguno de los problemas que podría haber tenido con el original, y tampoco elimina el mundo existente STAY no puede ser criticado por sus aspiraciones y el intento de hacer un personaje creíble en Quinn, para crear un individuo que el jugador quiera ayudar. Sin embargo, el resultado es una corriente casi interminable de diálogo mediocre que hizo increíblemente difícil quedarse hasta el final Imagina el nuevo Doom en VR y completamente imposible de jugar Si bien DOOM: VFR puede ser un juego divertido, la falta de ultraviolencia y el corto tiempo de juego eclipsan la diversión que ofrece DOOM: VFR, especialmente a su precio actual Inacabado, rediseños pobres del elenco principal, y cambió un montón de efectos de sonido del arma Con este segundo episodio, The Legacy of the First Blade arma todo el juego de roles que Ubisoft pasó decenas de horas para construir en una historia corta y altamente cuestionable de tres horas. Incluso los grandes acorazados y una nueva arma no salvarán a Assassin's Creed Odyssey de este cliffhanger equivocado que podría decepcionar a la mayoría de los aventureros Mutant Football League es un juego deportivo arcade barato y mal ejecutado. Creo que los desarrolladores entraron con todas las intenciones correctas, porque realmente no se están haciendo suficientes juegos deportivos para las personas que no están dispuestas a poner un gran compromiso en el juego para poder apreciarlo en cualquier nivel Si bien Fantastic Contraption lo alienta a ser creativo, inmediatamente lo encajona al mismo tiempo con un número limitado de soluciones e incluso menos herramientas Gráficamente seguro como está, casi todos los demás elementos de la serie de 15 años han sido recortados, manipulados sin sentido o directamente arruinados. La serie no ha sido buena desde hace mucho tiempo, pero este año es la primera que ha sido activamente mala Desafortunadamente, los mejores atributos de Island Time VR, las imágenes y la actuación de voz, se ven eclipsados ​​por algunos defectos muy importantes en el juego repetitivo, un tiempo de ejecución muy corto y errores que rompen el juego Si no estás discutiendo con tus amigos sobre si Naruto vencería a Goku y no estás rezando por la cuarta temporada de \"Jojo's Bizarre Adventure\", no hay absolutamente ninguna razón para que te preocupes por este juego de lucha realmente débil La Iglesia en la Oscuridad quiere ser un juego de sigilo que te ponga en medio de un culto del fin del mundo. En consecuencia, en lugar de darte una idea del mundo de un culto, obtienes un juego aburrido que te hará apreciar cómo para evitar el campo de visión de alguien El componente interactivo real de The Grand Tour Game es realmente bastante pobre, con un manejo horrible y una presentación anticuada que hace que las carreras y los desafíos sean muy inferiores a los segmentos que intentan reemplazar, entre los clips del programa que ya has visto De alguna manera, este juego es peor que el primero. El combate es malo, los gráficos apestan, la historia es confusa. El balanceo es malo y no es práctico en absoluto. Además, tiene errores como el infierno. Quizás el peor juego de Spider-Man Tiene muchos errores, modo historia no completado y bajo nivel de contenido. No recomiendo comprarlo ahora mismo Aquí vamos de nuevo, otro episodio completamente decepcionante de una franquicia tan (solía ser). Me siento mal por aquellos que prueban esto antes de probar el primer juego, si incluso probarán el primer juego después de jugar esto En retrospectiva, no debería haber dado cero al primer episodio porque este episodio es incluso peor que el primero El problema con el juego es que tiene muchos errores como: estaba luchando contra un jefe, y no tenían corazones, pero no fueron derrotados, me hizo reiniciar todo el nivel, otra vez tuve que destruir algo para avanzar a un nivel, pero no se rompería, tuve que reiniciar esa parte también. He descubierto que este juego tiene muchos errores para un juego de DC Una buena formación de canciones pero problemas serios. No puedo creer que no hayan mejorado el soporte de la cámara \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrJ-77vK41NU",
        "colab_type": "text"
      },
      "source": [
        "##***4. Análisis de tokens***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llSvFlYkYXrw",
        "colab_type": "text"
      },
      "source": [
        "###***A. Aplicación de Lematización***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0EVUSNW2GN-",
        "colab_type": "text"
      },
      "source": [
        "La tecnica de ***lematización*** consiste en extraer los ***tokens*** que representen un conjunto de palabras en su sentido neutro. ***Mezclar***, por ejemplo, representa ***mezcla*** y ***mezclando***. El objetivo de esta tecnica es reducir la cantidad de ***tokens*** a analizar posteriormente. La idea es quedarse solo con los ***tokens*** más relevantes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VzpnFQ3YVcE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d615cfa-84eb-462c-fe5d-2a02aaececf5"
      },
      "source": [
        "tokens = []\n",
        "for token in doc:\n",
        "  print(token.text + ' ----> ' + token.lemma_)\n",
        "  tokens.append(token.lemma_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mSe han truncado las últimas 5000 líneas del flujo de salida.\u001b[0m\n",
            "un ----> uno\n",
            "área ----> área\n",
            "de ----> de\n",
            "juegos ----> juego\n",
            "aún ----> aun\n",
            "más ----> más\n",
            "grande ----> grande\n",
            "e ----> e\n",
            "impresionante ----> impresionante\n",
            "con ----> con\n",
            "mucha ----> mucho\n",
            "más ----> más\n",
            "libertad ----> libertar\n",
            "de ----> de\n",
            "acción ----> acción\n",
            ", ----> ,\n",
            "al ----> al\n",
            "tiempo ----> tiempo\n",
            "que ----> que\n",
            "presenta ----> presentar\n",
            "un ----> uno\n",
            "desafío ----> desafiar\n",
            "mayor ----> mayor\n",
            "Persona ----> Persona\n",
            "5 ----> 5\n",
            "ya ----> ya\n",
            "era ----> ser\n",
            "un ----> uno\n",
            "líder ----> líder\n",
            "fuerte ----> fuerte\n",
            "por ----> por\n",
            "ser ----> ser\n",
            "el ----> el\n",
            "mejor ----> mejor\n",
            "JRPG ----> JRPG\n",
            "jamás ----> jamás\n",
            "creado ----> crear\n",
            ", ----> ,\n",
            "y ----> y\n",
            "Royal ----> Royal\n",
            "realmente ----> realmente\n",
            "me ----> me\n",
            "hace ----> hacer\n",
            "preguntarme ----> preguntarme\n",
            "qué ----> qué\n",
            "más ----> más\n",
            "podría ----> poder\n",
            "incluso ----> incluso\n",
            "competir ----> competir\n",
            "Bellamente ----> Bellamente\n",
            "mejorado ----> mejorar\n",
            "y ----> y\n",
            ", ----> ,\n",
            "en ----> en\n",
            "su ----> su\n",
            "esencia ----> esencia\n",
            ", ----> ,\n",
            "una ----> uno\n",
            "mezcla ----> mezclar\n",
            "tremendamente ----> tremendamente\n",
            "fascinante ----> fascinante\n",
            "de ----> de\n",
            "la ----> lo\n",
            "rutina ----> rutina\n",
            "diaria ----> diario\n",
            "de ----> de\n",
            "la ----> lo\n",
            "escuela ----> escuela\n",
            "secundaria ----> secundario\n",
            "y ----> y\n",
            "el ----> el\n",
            "extraño ----> extrañar\n",
            "thriller ----> thriller\n",
            "de ----> de\n",
            "misterio ----> misterio\n",
            "La ----> La\n",
            "cantidad ----> cantidad\n",
            "de ----> de\n",
            "cambio ----> cambiar\n",
            "aportado ----> aportar\n",
            "al ----> al\n",
            "título ----> título\n",
            "es ----> ser\n",
            "significativa ----> significativo\n",
            ", ----> ,\n",
            "y ----> y\n",
            "todo ----> todo\n",
            "parece ----> parecer\n",
            "una ----> uno\n",
            "mejora ----> mejorar\n",
            "notable ----> notable\n",
            ". ----> .\n",
            "Para ----> Para\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "que ----> que\n",
            "ya ----> ya\n",
            "era ----> ser\n",
            "uno ----> unir\n",
            "de ----> de\n",
            "los ----> lo\n",
            "mejores ----> mejorar\n",
            "JRPG ----> JRPG\n",
            "de ----> de\n",
            "los ----> lo\n",
            "últimos ----> último\n",
            "años ----> año\n",
            ", ----> ,\n",
            "Persona ----> Persona\n",
            "5 ----> 5\n",
            "Royal ----> Royal\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "continuación ----> continuación\n",
            "que ----> que\n",
            "se ----> se\n",
            "consolida ----> consolidar\n",
            "como ----> comer\n",
            "una ----> uno\n",
            "experiencia ----> experiencia\n",
            "que ----> que\n",
            "vale ----> valer\n",
            "la ----> lo\n",
            "pena ----> penar\n",
            "repetir ----> repetir\n",
            "en ----> en\n",
            "lugar ----> lugar\n",
            "de ----> de\n",
            "una ----> uno\n",
            "secuela ----> secuela\n",
            "de ----> de\n",
            "Persona ----> Persona\n",
            "adecuada ----> adecuar\n",
            "Literalmente ----> Literalmente\n",
            "acaba ----> acabar\n",
            "de ----> de\n",
            "hacer ----> hacer\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "original ----> original\n",
            ", ----> ,\n",
            "que ----> que\n",
            "fue ----> ser\n",
            "uno ----> unir\n",
            "de ----> de\n",
            "los ----> lo\n",
            "mejores ----> mejorar\n",
            "JRPG ----> JRPG\n",
            "de ----> de\n",
            "todos ----> todo\n",
            "los ----> lo\n",
            "tiempos ----> tiempo\n",
            ", ----> ,\n",
            "mejor ----> mejor\n",
            "Utilizando ----> Utilizando\n",
            "disparos ----> disparo\n",
            "rápidos ----> rápido\n",
            "en ----> en\n",
            "primera ----> primero\n",
            "persona ----> personar\n",
            "como ----> comer\n",
            "marco ----> marcar\n",
            ", ----> ,\n",
            "cada ----> cada\n",
            "secuela ----> secuela\n",
            "ha ----> haber\n",
            "mejorado ----> mejorar\n",
            "enormemente ----> enormemente\n",
            "el ----> el\n",
            "diseño ----> diseñar\n",
            "de ----> de\n",
            "niveles ----> nivelar\n",
            ", ----> ,\n",
            "una ----> uno\n",
            "selección ----> selección\n",
            "más ----> más\n",
            "amplia ----> amplio\n",
            "de ----> de\n",
            "demonios ----> demonio\n",
            "para ----> parir\n",
            "masacrar ----> masacrar\n",
            "y ----> y\n",
            "un ----> uno\n",
            "arsenal ----> arsenal\n",
            "más ----> más\n",
            "grande ----> grande\n",
            "que ----> que\n",
            "se ----> se\n",
            "une ----> unir\n",
            "para ----> parir\n",
            "refinar ----> refinar\n",
            "su ----> su\n",
            "identidad ----> identidad\n",
            "central ----> central\n",
            "de ----> de\n",
            "la ----> lo\n",
            "manera ----> manera\n",
            "más ----> más\n",
            "inteligente ----> inteligente\n",
            "y ----> y\n",
            "respetuosa ----> respetuoso\n",
            "posible ----> posible\n",
            "Un ----> Un\n",
            "juego ----> jugar\n",
            "fantástico ----> fantástico\n",
            ", ----> ,\n",
            "que ----> que\n",
            "toma ----> tomar\n",
            "todos ----> todo\n",
            "los ----> lo\n",
            "elementos ----> elemento\n",
            "que ----> que\n",
            "hicieron ----> hacer\n",
            "de ----> de\n",
            "DOOM ----> DOOM\n",
            "2016 ----> 2016\n",
            "un ----> uno\n",
            "reinicio ----> reinicio\n",
            "tan ----> tan\n",
            "sorprendente ----> sorprendente\n",
            "de ----> de\n",
            "la ----> lo\n",
            "franquicia ----> franquicia\n",
            "e ----> e\n",
            "implementó ----> implementar\n",
            "docenas ----> doceno\n",
            "de ----> de\n",
            "nuevos ----> nuevo\n",
            "conceptos ----> concepto\n",
            "de ----> de\n",
            "una ----> uno\n",
            "manera ----> manera\n",
            "que ----> que\n",
            "hace ----> hacer\n",
            "que ----> que\n",
            "toda ----> todo\n",
            "la ----> lo\n",
            "experiencia ----> experiencia\n",
            "se ----> se\n",
            "sienta ----> sentir\n",
            "fresca ----> fresco\n",
            "nuevamente ----> nuevamente\n",
            "DOOM ----> DOOM\n",
            "Eternal ----> Eternal\n",
            "superó ----> superar\n",
            "las ----> los\n",
            "expectativas ----> expectativa\n",
            ", ----> ,\n",
            "tanto ----> tanto\n",
            "en ----> en\n",
            "lo ----> el\n",
            "que ----> que\n",
            "respecta ----> respectar\n",
            "a ----> a\n",
            "la ----> lo\n",
            "dificultad ----> dificultar\n",
            "como ----> comer\n",
            "al ----> al\n",
            "disfrute ----> disfrutar\n",
            ", ----> ,\n",
            "y ----> y\n",
            "aunque ----> aunque\n",
            "no ----> no\n",
            "sin ----> sin\n",
            "sus ----> su\n",
            "fallas ----> fallo\n",
            ", ----> ,\n",
            "se ----> se\n",
            "siente ----> sentir\n",
            "como ----> comer\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "imprescindible ----> imprescindible\n",
            "para ----> parir\n",
            "los ----> lo\n",
            "jugadores ----> jugador\n",
            "de ----> de\n",
            "FPS ----> FPS\n",
            "Un ----> Un\n",
            "juego ----> jugar\n",
            "hermoso ----> hermoso\n",
            ", ----> ,\n",
            "difícil ----> difícil\n",
            "de ----> de\n",
            "entender ----> entender\n",
            "sin ----> sin\n",
            "conocer ----> conocer\n",
            "la ----> lo\n",
            "historia ----> historia\n",
            "del ----> del\n",
            "creador ----> creador\n",
            "pero ----> pero\n",
            "tan ----> tan\n",
            "inmersivo ----> inmersivo\n",
            "... ----> ...\n",
            "La ----> La\n",
            "música ----> músico\n",
            "es ----> ser\n",
            "fantástica ----> fantástico\n",
            "y ----> y\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "placer ----> placer\n",
            "vivirla ----> vivirla\n",
            "de ----> de\n",
            "principio ----> principiar\n",
            "a ----> a\n",
            "fin ----> fin\n",
            "Puyo ----> Puyo\n",
            "Puyo ----> Puyo\n",
            "Champions ----> Champions\n",
            "ofrece ----> ofrecer\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "rompecabezas ----> rompecabezas\n",
            "competitivo ----> competitivo\n",
            "familiar ----> familiar\n",
            "y ----> y\n",
            "divertido ----> divertir\n",
            "con ----> con\n",
            "una ----> uno\n",
            "gran ----> gran\n",
            "selección ----> selección\n",
            "de ----> de\n",
            "personajes ----> personaje\n",
            "encantadores ----> encantador\n",
            "En ----> En\n",
            "general ----> general\n",
            ", ----> ,\n",
            "Blazblu ----> Blazblu\n",
            "Chronophantasma ----> Chronophantasma\n",
            "Extend ----> Extend\n",
            "es ----> ser\n",
            "imprescindible ----> imprescindible\n",
            "para ----> parir\n",
            "cualquiera ----> cualquiera\n",
            "que ----> que\n",
            "esté ----> estar\n",
            "interesado ----> interesar\n",
            "en ----> en\n",
            "sus ----> su\n",
            "juegos ----> juego\n",
            "de ----> de\n",
            "lucha ----> luchar\n",
            "y ----> y\n",
            "esto ----> este\n",
            "está ----> estar\n",
            "a ----> a\n",
            "la ----> lo\n",
            "altura ----> altura\n",
            "de ----> de\n",
            "cualquier ----> cualquiera\n",
            "cosa ----> coser\n",
            "en ----> en\n",
            "la ----> lo\n",
            "PS4 ----> PS4\n",
            "Todo ----> Todo\n",
            "sobre ----> sobrar\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "genial ----> genial\n",
            ". ----> .\n",
            "Tiene ----> Tiene\n",
            "diversidad ----> diversidad\n",
            "no ----> no\n",
            "solo ----> solo\n",
            "en ----> en\n",
            "sus ----> su\n",
            "personajes ----> personaje\n",
            ", ----> ,\n",
            "sino ----> sino\n",
            "también ----> también\n",
            "en ----> en\n",
            "las ----> los\n",
            "emociones ----> emocionar\n",
            "que ----> que\n",
            "te ----> te\n",
            "hace ----> hacer\n",
            "sentir ----> sentir\n",
            "por ----> por\n",
            "su ----> su\n",
            "historia ----> historia\n",
            "En ----> En\n",
            "pocas ----> poco\n",
            "palabras ----> palabra\n",
            ", ----> ,\n",
            "uno ----> unir\n",
            "de ----> de\n",
            "los ----> lo\n",
            "mejores ----> mejorar\n",
            "juegos ----> juego\n",
            "de ----> de\n",
            "lucha ----> luchar\n",
            "en ----> en\n",
            "2D ----> 2D\n",
            "para ----> parir\n",
            "PS4 ----> PS4\n",
            ", ----> ,\n",
            "Xbox ----> Xbox\n",
            "One ----> One\n",
            ", ----> ,\n",
            "PS3 ----> PS3\n",
            "e ----> e\n",
            "incluso ----> incluso\n",
            "consolas ----> consola\n",
            "PS ----> PS\n",
            "Vita ----> Vita\n",
            "De ----> De\n",
            "lo ----> el\n",
            "contrario ----> contrario\n",
            ", ----> ,\n",
            "BlazBlue ----> BlazBlue\n",
            "sigue ----> seguir\n",
            "siendo ----> ser\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "lucha ----> luchar\n",
            "elegante ----> elegante\n",
            ", ----> ,\n",
            "rápido ----> rápido\n",
            ", ----> ,\n",
            "competitivo ----> competitivo\n",
            "y ----> y\n",
            "vibrante ----> vibrante\n",
            "que ----> que\n",
            "vimos ----> ver\n",
            "en ----> en\n",
            "versiones ----> versionar\n",
            "anteriores ----> anterior\n",
            "Uno ----> Uno\n",
            "de ----> de\n",
            "los ----> lo\n",
            "mejores ----> mejorar\n",
            "juegos ----> juego\n",
            "que ----> que\n",
            "he ----> haber\n",
            "jugado ----> jugar\n",
            "en ----> en\n",
            "mi ----> mi\n",
            "vida ----> vida\n",
            ". ----> .\n",
            "No ----> No\n",
            "es ----> ser\n",
            "mentira ----> mentira\n",
            "que ----> que\n",
            "sea ----> ser\n",
            "lo ----> el\n",
            "mismo ----> mismo\n",
            "con ----> con\n",
            "los ----> lo\n",
            "otros ----> otro\n",
            "2 ----> 2\n",
            "juegos ----> juego\n",
            "de ----> de\n",
            "blazblue ----> blazblue\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "eso ----> ese\n",
            "no ----> no\n",
            "importa ----> importar\n",
            "en ----> en\n",
            "absoluto ----> absoluto\n",
            "Para ----> Para\n",
            "un ----> uno\n",
            "modo ----> modo\n",
            "de ----> de\n",
            "historia ----> historia\n",
            "de ----> de\n",
            "estilo ----> estilar\n",
            "de ----> de\n",
            "novela ----> novelar\n",
            "visual ----> visual\n",
            "y ----> y\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "lucha ----> luchar\n",
            ", ----> ,\n",
            "no ----> no\n",
            "podría ----> poder\n",
            "pedir ----> pedir\n",
            "mucho ----> mucho\n",
            "más ----> más\n",
            ", ----> ,\n",
            "es ----> ser\n",
            "competitivo ----> competitivo\n",
            "y ----> y\n",
            "desafiante ----> desafiante\n",
            "en ----> en\n",
            "este ----> este\n",
            "último ----> último\n",
            "aspecto ----> aspecto\n",
            "Blood ----> Blood\n",
            "and ----> and\n",
            "Truth ----> Truth\n",
            "deja ----> dejar\n",
            "las ----> los\n",
            "viejas ----> viejo\n",
            "demostraciones ----> demostración\n",
            "tecnológicas ----> tecnológico\n",
            "glorificadas ----> glorificar\n",
            "en ----> en\n",
            "el ----> el\n",
            "polvo ----> polvo\n",
            "y ----> y\n",
            "se ----> se\n",
            "da ----> dar\n",
            "cuenta ----> contar\n",
            "de ----> de\n",
            "todo ----> todo\n",
            "el ----> el\n",
            "potencial ----> potencial\n",
            "de ----> de\n",
            "la ----> lo\n",
            "realidad ----> realidad\n",
            "virtual ----> virtual\n",
            "con ----> con\n",
            "una ----> uno\n",
            "increíble ----> increíble\n",
            "campaña ----> campaña\n",
            "de ----> de\n",
            "éxito ----> éxito\n",
            "que ----> que\n",
            "también ----> también\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "carta ----> carta\n",
            "de ----> de\n",
            "amor ----> amor\n",
            "a ----> a\n",
            "la ----> lo\n",
            "ciudad ----> ciudad\n",
            "en ----> en\n",
            "la ----> lo\n",
            "que ----> que\n",
            "está ----> estar\n",
            "hecha ----> hacer\n",
            "Desde ----> Desde\n",
            "la ----> lo\n",
            "historia ----> historia\n",
            "convincente ----> convincente\n",
            "y ----> y\n",
            "bien ----> bien\n",
            "actuada ----> actuar\n",
            "hasta ----> hasta\n",
            "su ----> su\n",
            "combate ----> combatir\n",
            "atractivo ----> atractivo\n",
            ", ----> ,\n",
            "SIE ----> SIE\n",
            "London ----> London\n",
            "Studios ----> Studios\n",
            "ha ----> haber\n",
            "brindado ----> brindar\n",
            "una ----> uno\n",
            "de ----> de\n",
            "las ----> los\n",
            "mejores ----> mejorar\n",
            "experiencias ----> experiencia\n",
            "de ----> de\n",
            "realidad ----> realidad\n",
            "virtual ----> virtual\n",
            "en ----> en\n",
            "la ----> lo\n",
            "plataforma ----> plataforma\n",
            "de ----> de\n",
            "Sony ----> Sony\n",
            "Simplemente ----> Simplemente\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "increíble ----> increíble\n",
            "con ----> con\n",
            "toda ----> todo\n",
            "la ----> lo\n",
            "emoción ----> emoción\n",
            "y ----> y\n",
            "la ----> lo\n",
            "emoción ----> emoción\n",
            "que ----> que\n",
            "todos ----> todo\n",
            "esperaban ----> esperar\n",
            "de ----> de\n",
            "la ----> lo\n",
            "exageración ----> exageración\n",
            "de ----> de\n",
            "London ----> London\n",
            "Heist ----> Heist\n",
            "A ----> A\n",
            "riesgo ----> riesgo\n",
            "de ----> de\n",
            "sonar ----> sonar\n",
            "demasiado ----> demasiar\n",
            "enamorado ----> enamorar\n",
            ", ----> ,\n",
            "no ----> no\n",
            "puedo ----> poder\n",
            "comenzar ----> comenzar\n",
            "a ----> a\n",
            "entender ----> entender\n",
            "cómo ----> cómo\n",
            "demonios ----> demonio\n",
            "Torchlight ----> Torchlight\n",
            "II ----> II\n",
            "ha ----> haber\n",
            "envejecido ----> envejecer\n",
            "tan ----> tan\n",
            "bien ----> bien\n",
            "Siete ----> Siete\n",
            "años ----> año\n",
            "después ----> después\n",
            "de ----> de\n",
            "su ----> su\n",
            "lanzamiento ----> lanzamiento\n",
            "inicial ----> inicial\n",
            ", ----> ,\n",
            "Torchlight ----> Torchlight\n",
            "2 ----> 2\n",
            "finalmente ----> finalmente\n",
            "adorna ----> adornar\n",
            "la ----> lo\n",
            "generación ----> generación\n",
            "de ----> de\n",
            "la ----> lo\n",
            "consola ----> consola\n",
            "y ----> y\n",
            "demuestra ----> demostrar\n",
            "que ----> que\n",
            "no ----> no\n",
            "tiene ----> tener\n",
            "que ----> que\n",
            "tener ----> tener\n",
            "Diablo ----> Diablo\n",
            "en ----> en\n",
            "su ----> su\n",
            "título ----> título\n",
            "para ----> parir\n",
            "tener ----> tener\n",
            "un ----> uno\n",
            "impacto ----> impactar\n",
            "Una ----> Una\n",
            "de ----> de\n",
            "las ----> los\n",
            "mejores ----> mejorar\n",
            "sorpresas ----> sorpresa\n",
            "que ----> que\n",
            "tuve ----> tener\n",
            "con ----> con\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "rol ----> rol\n",
            "de ----> de\n",
            "acción ----> acción\n",
            ". ----> .\n",
            "Probablemente ----> Probablemente\n",
            "el ----> el\n",
            "que ----> que\n",
            "se ----> se\n",
            "siente ----> sentir\n",
            "más ----> más\n",
            "cercano ----> cercano\n",
            "también ----> también\n",
            "a ----> a\n",
            "diablo ----> diablo\n",
            "2 ----> 2\n",
            "en ----> en\n",
            "términos ----> término\n",
            "de ----> de\n",
            "todo ----> todo\n",
            ", ----> ,\n",
            "además ----> además\n",
            "del ----> del\n",
            "tema ----> temer\n",
            "y ----> y\n",
            "las ----> los\n",
            "instrucciones ----> instrucción\n",
            "de ----> de\n",
            "arte ----> arte\n",
            "BUENO ----> BUENO\n",
            ": ----> :\n",
            "Excelente ----> Excelente\n",
            "jugabilidad ----> jugabilidad\n",
            ", ----> ,\n",
            "toneladas ----> tonelada\n",
            "de ----> de\n",
            "botines ----> botín\n",
            "individuales ----> individual\n",
            ", ----> ,\n",
            "muchas ----> mucho\n",
            "misiones ----> misionar\n",
            ", ----> ,\n",
            "niveles ----> nivelar\n",
            "aleatorios ----> aleatorio\n",
            ", ----> ,\n",
            "multijugador ----> multijugador\n",
            "cooperativo ----> cooperativo\n",
            ", ----> ,\n",
            "la ----> lo\n",
            "capacidad ----> capacidad\n",
            "de ----> de\n",
            "reproducción ----> reproducción\n",
            "es ----> ser\n",
            "excelente ----> excelente\n",
            ", ----> ,\n",
            "mucho ----> mucho\n",
            "contenido ----> contener\n",
            "por ----> por\n",
            "lo ----> el\n",
            "que ----> que\n",
            "cuesta ----> costar\n",
            "Tras ----> Tras\n",
            "alejar ----> alejar\n",
            "la ----> lo\n",
            "acción ----> acción\n",
            "de ----> de\n",
            "los ----> lo\n",
            "oscuros ----> oscuro\n",
            "túneles ----> túnel\n",
            "subterráneos ----> subterráneo\n",
            "de ----> de\n",
            "Moscú ----> Moscú\n",
            "en ----> en\n",
            "un ----> uno\n",
            "tren ----> tren\n",
            ", ----> ,\n",
            "ir ----> ir\n",
            "a ----> a\n",
            "lo ----> el\n",
            "desconocido ----> desconocer\n",
            "y ----> y\n",
            "obligarse ----> obligarse\n",
            "a ----> a\n",
            "hacer ----> hacer\n",
            "paradas ----> parar\n",
            "durante ----> durante\n",
            "todo ----> todo\n",
            "el ----> el\n",
            "viaje ----> viajar\n",
            ", ----> ,\n",
            "los ----> lo\n",
            "autores ----> autor\n",
            "de ----> de\n",
            "Metro ----> Metro\n",
            "Exodus ----> Exodus\n",
            "crearon ----> crear\n",
            "una ----> uno\n",
            "aventura ----> aventurar\n",
            "interactiva ----> interactivo\n",
            "memorable ----> memorable\n",
            "que ----> que\n",
            "consiste ----> consistir\n",
            "en ----> en\n",
            "la ----> lo\n",
            "felicidad ----> felicidad\n",
            "de ----> de\n",
            "descubrir ----> descubrir\n",
            "el ----> el\n",
            "amor ----> amor\n",
            "y ----> y\n",
            "el ----> el\n",
            "dolor ----> dolor\n",
            "por ----> por\n",
            "la ----> lo\n",
            "pérdida ----> pérdida\n",
            "irremplazable ----> irremplazable\n",
            ", ----> ,\n",
            "esperanza ----> esperanzar\n",
            "de ----> de\n",
            "un ----> uno\n",
            "futuro ----> futuro\n",
            "mejor ----> mejor\n",
            "y ----> y\n",
            "desesperación ----> desesperación\n",
            "por ----> por\n",
            "entender ----> entender\n",
            "la ----> lo\n",
            "verdad ----> verdad\n",
            "Así ----> Así\n",
            "que ----> que\n",
            "siéntese ----> siéntese\n",
            "y ----> y\n",
            "disfrute ----> disfrutar\n",
            "de ----> de\n",
            "la ----> lo\n",
            "experiencia ----> experiencia\n",
            "única ----> único\n",
            ", ----> ,\n",
            "las ----> los\n",
            "maravillas ----> maravillar\n",
            "visuales ----> visual\n",
            "y ----> y\n",
            "los ----> lo\n",
            "secretos ----> secreto\n",
            "más ----> más\n",
            "oscuros ----> oscuro\n",
            "del ----> del\n",
            "querido ----> querer\n",
            "universo ----> universo\n",
            "Metro ----> Metro\n",
            "Apocalypse ----> Apocalypse\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "expansión ----> expansión\n",
            "completa ----> completo\n",
            "que ----> que\n",
            "redefine ----> redefinir\n",
            "la ----> lo\n",
            "guerra ----> guerra\n",
            "estelar ----> estelar\n",
            "para ----> parir\n",
            "todos ----> todo\n",
            "los ----> lo\n",
            "jugadores ----> jugador\n",
            "con ----> con\n",
            "una ----> uno\n",
            "serie ----> seriar\n",
            "de ----> de\n",
            "nuevas ----> nuevo\n",
            "opciones ----> opción\n",
            "ofensivas ----> ofensivo\n",
            "y ----> y\n",
            "defensivas ----> defensivo\n",
            "ssetto ----> ssetto\n",
            "Corsa ----> Corsa\n",
            "Competizione ----> Competizione\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "extraordinario ----> extraordinario\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "simulación ----> simulación\n",
            "de ----> de\n",
            "carreras ----> carrera\n",
            "que ----> que\n",
            "permite ----> permitir\n",
            "a ----> a\n",
            "los ----> lo\n",
            "jugadores ----> jugador\n",
            "experimentar ----> experimentar\n",
            "la ----> lo\n",
            "atmósfera ----> atmósfera\n",
            "real ----> real\n",
            "de ----> de\n",
            "campeonatos ----> campeonato\n",
            "Sumérgete ----> Sumérgete\n",
            "en ----> en\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "disparos ----> disparo\n",
            "en ----> en\n",
            "primera ----> primero\n",
            "persona ----> personar\n",
            "impulsado ----> impulsar\n",
            "por ----> por\n",
            "la ----> lo\n",
            "acción ----> acción\n",
            ", ----> ,\n",
            "ambientado ----> ambientar\n",
            "en ----> en\n",
            "un ----> uno\n",
            "futuro ----> futuro\n",
            "universo ----> universo\n",
            "de ----> de\n",
            "ciencia ----> ciencia\n",
            "ficción ----> ficción\n",
            "creado ----> crear\n",
            "por ----> por\n",
            "V1 ----> V1\n",
            "Interactive ----> Interactive\n",
            "Uno ----> Uno\n",
            "de ----> de\n",
            "los ----> lo\n",
            "mejores ----> mejorar\n",
            "videojuegos ----> videojuego\n",
            "que ----> que\n",
            "he ----> haber\n",
            "jugado ----> jugar\n",
            ". ----> .\n",
            "Este ----> Este\n",
            "juego ----> jugar\n",
            "siempre ----> siempre\n",
            "te ----> te\n",
            "mantendrá ----> mantener\n",
            "alerta ----> alertar\n",
            "cuando ----> cuando\n",
            "juegues ----> jugar\n",
            "a ----> a\n",
            "predator ----> predator\n",
            "y ----> y\n",
            "fireteam ----> fireteam\n",
            ". ----> .\n",
            "Como ----> Como\n",
            "fanático ----> fanático\n",
            "personal ----> personal\n",
            "de ----> de\n",
            "Predator ----> Predator\n",
            ", ----> ,\n",
            "realmente ----> realmente\n",
            "disfruto ----> disfrutar\n",
            "de ----> de\n",
            "todas ----> todo\n",
            "las ----> los\n",
            "referencias ----> referenciar\n",
            "a ----> a\n",
            "las ----> los\n",
            "películas ----> película\n",
            "Este ----> Este\n",
            "es ----> ser\n",
            "uno ----> unir\n",
            "de ----> de\n",
            "los ----> lo\n",
            "mejores ----> mejorar\n",
            "JRPG ----> JRPG\n",
            "que ----> que\n",
            "he ----> haber\n",
            "jugado ----> jugar\n",
            "y ----> y\n",
            "créanme ----> créanme\n",
            "que ----> que\n",
            "he ----> haber\n",
            "jugado ----> jugar\n",
            "mucho ----> mucho\n",
            ". ----> .\n",
            "Este ----> Este\n",
            "juego ----> jugar\n",
            "tiene ----> tener\n",
            "todo ----> todo\n",
            "en ----> en\n",
            "una ----> uno\n",
            "historia ----> historia\n",
            ", ----> ,\n",
            "momentos ----> momento\n",
            "divertidos ----> divertir\n",
            ", ----> ,\n",
            "capítulos ----> capítulo\n",
            "embrujados ----> embrujar\n",
            "que ----> que\n",
            "dan ----> dar\n",
            "escalofríos ----> escalofrío\n",
            ", ----> ,\n",
            "lo ----> el\n",
            "tiene ----> tener\n",
            "todo ----> todo\n",
            ", ----> ,\n",
            "incluso ----> incluso\n",
            "los ----> lo\n",
            "minijuegos ----> minijuegos\n",
            "se ----> se\n",
            "sienten ----> sentir\n",
            "bien ----> bien\n",
            ". ----> .\n",
            "Toda ----> Toda\n",
            "mi ----> mi\n",
            "familia ----> familia\n",
            "está ----> estar\n",
            "haciendo ----> hacer\n",
            "el ----> el\n",
            "minijuego ----> minijuego\n",
            "de ----> de\n",
            "ejercicios ----> ejercicio\n",
            "en ----> en\n",
            "el ----> el\n",
            "gimnasio ----> gimnasio\n",
            "para ----> parir\n",
            "superar ----> superar\n",
            "mi ----> mi\n",
            "puntaje ----> puntaje\n",
            "más ----> más\n",
            "alto ----> alto\n",
            "Modern ----> Modern\n",
            "Warfare ----> Warfare\n",
            "2 ----> 2\n",
            "vuelve ----> volver\n",
            "con ----> con\n",
            "un ----> uno\n",
            "buen ----> bueno\n",
            "trabajo ----> trabajar\n",
            "de ----> de\n",
            "remasterización ----> remasterización\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "que ----> que\n",
            "echa ----> echar\n",
            "demasiado ----> demasiar\n",
            "en ----> en\n",
            "falta ----> falto\n",
            "su ----> su\n",
            "modo ----> modo\n",
            "multijugador ----> multijugador\n",
            "Beyond ----> Beyond\n",
            "Blue ----> Blue\n",
            "lleva ----> llevar\n",
            "a ----> a\n",
            "los ----> lo\n",
            "jugadores ----> jugador\n",
            "al ----> al\n",
            "futuro ----> futuro\n",
            "cercano ----> cercano\n",
            ", ----> ,\n",
            "donde ----> donde\n",
            "tendrán ----> tener\n",
            "la ----> lo\n",
            "oportunidad ----> oportunidad\n",
            "de ----> de\n",
            "explorar ----> explorar\n",
            "los ----> lo\n",
            "misterios ----> misterio\n",
            "de ----> de\n",
            "nuestro ----> nuestro\n",
            "océano ----> océano\n",
            "a ----> a\n",
            "través ----> través\n",
            "de ----> de\n",
            "los ----> lo\n",
            "ojos ----> ojo\n",
            "de ----> de\n",
            "Mirai ----> Mirai\n",
            ", ----> ,\n",
            "un ----> uno\n",
            "explorador ----> explorador\n",
            "y ----> y\n",
            "científico ----> científico\n",
            "de ----> de\n",
            "las ----> los\n",
            "profundidades ----> profundidad\n",
            "del ----> del\n",
            "mar ----> mar\n",
            "Bienvenido ----> Bienvenido\n",
            "a ----> a\n",
            "Warzone ----> Warzone\n",
            ": ----> :\n",
            "una ----> uno\n",
            "nueva ----> nuevo\n",
            "experiencia ----> experiencia\n",
            "de ----> de\n",
            "combate ----> combatir\n",
            "en ----> en\n",
            "la ----> lo\n",
            "que ----> que\n",
            "hasta ----> hasta\n",
            "150 ----> 150\n",
            "jugadores ----> jugador\n",
            "toman ----> tomar\n",
            "el ----> el\n",
            "papel ----> papel\n",
            "de ----> de\n",
            "un ----> uno\n",
            "veterano ----> veterano\n",
            "operador ----> operador\n",
            "de ----> de\n",
            "nivel ----> nivel\n",
            "1 ----> 1\n",
            "y ----> y\n",
            "entran ----> entrar\n",
            "en ----> en\n",
            "el ----> el\n",
            "denso ----> denso\n",
            "y ----> y\n",
            "extenso ----> extenso\n",
            "mundo ----> mundo\n",
            "de ----> de\n",
            "Verdansk ----> Verdansk\n",
            "Modern ----> Modern\n",
            "Warfare ----> Warfare\n",
            "2 ----> 2\n",
            "vuelve ----> volver\n",
            "con ----> con\n",
            "un ----> uno\n",
            "buen ----> bueno\n",
            "trabajo ----> trabajar\n",
            "de ----> de\n",
            "remasterización ----> remasterización\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "que ----> que\n",
            "echa ----> echar\n",
            "demasiado ----> demasiar\n",
            "en ----> en\n",
            "falta ----> falto\n",
            "su ----> su\n",
            "modo ----> modo\n",
            "multijugador ----> multijugador\n",
            "¡ ----> ¡\n",
            "¡ ----> ¡\n",
            "¡ ----> ¡\n",
            "MUY ----> MUY\n",
            "DIVERTIDO ----> DIVERTIDO\n",
            "! ----> !\n",
            "! ----> !\n",
            "! ----> !\n",
            "Este ----> Este\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "muy ----> muy\n",
            "divertido ----> divertir\n",
            "¡ ----> ¡\n",
            "Definitivamente ----> Definitivamente\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "compra ----> comprar\n",
            "obligada ----> obligar\n",
            "! ----> !\n",
            "Este ----> Este\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "divertido ----> divertir\n",
            "de ----> de\n",
            "jugar ----> jugar\n",
            "como ----> comer\n",
            "Predator ----> Predator\n",
            "y ----> y\n",
            "el ----> el\n",
            "equipo ----> equipar\n",
            "de ----> de\n",
            "bomberos ----> bombero\n",
            "Un ----> Un\n",
            "gran ----> gran\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "acción ----> acción\n",
            "en ----> en\n",
            "2D ----> 2D\n",
            "protagonizado ----> protagonizar\n",
            "por ----> por\n",
            "mechas ----> mechar\n",
            ": ----> :\n",
            "espectacular ----> espectacular\n",
            ", ----> ,\n",
            "variado ----> variar\n",
            "y ----> y\n",
            "muy ----> muy\n",
            "completo ----> completar\n",
            "Breeder ----> Breeder\n",
            "Homegrown ----> Homegrown\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "terror ----> terror\n",
            "corto ----> cortar\n",
            "sobre ----> sobrar\n",
            "una ----> uno\n",
            "familia ----> familia\n",
            "que ----> que\n",
            "trata ----> tratar\n",
            "con ----> con\n",
            "una ----> uno\n",
            "criatura ----> criatura\n",
            "extraña ----> extraño\n",
            "durante ----> durante\n",
            "varias ----> varios\n",
            "generaciones ----> generación\n",
            ". ----> .\n",
            "Encontrarás ----> Encontrarás\n",
            "algunos ----> alguno\n",
            "acertijos ----> acertijo\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "se ----> se\n",
            "basa ----> basar\n",
            "principalmente ----> principalmente\n",
            "en ----> en\n",
            "la ----> lo\n",
            "atmósfera ----> atmósfera\n",
            ", ----> ,\n",
            "la ----> lo\n",
            "música ----> músico\n",
            "y ----> y\n",
            "buenos ----> bueno\n",
            "diálogos ----> diálogo\n",
            "La ----> La\n",
            "separación ----> separación\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "aventura ----> aventurar\n",
            "en ----> en\n",
            "primera ----> primero\n",
            "persona ----> personar\n",
            "en ----> en\n",
            "su ----> su\n",
            "forma ----> formar\n",
            "más ----> más\n",
            "ambiental ----> ambiental\n",
            "y ----> y\n",
            "atmosférica ----> atmosférico\n",
            "Holfraine ----> Holfraine\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "disparos ----> disparo\n",
            "de ----> de\n",
            "héroes ----> héroe\n",
            "en ----> en\n",
            "tercera ----> tercero\n",
            "persona ----> personar\n",
            "con ----> con\n",
            "diferentes ----> diferente\n",
            "personajes ----> personaje\n",
            "para ----> parir\n",
            "elegir ----> elegir\n",
            ". ----> .\n",
            "Juega ----> Juega\n",
            "con ----> con\n",
            "tus ----> tu\n",
            "compañeros ----> compañero\n",
            "de ----> de\n",
            "equipo ----> equipar\n",
            "y ----> y\n",
            "derrota ----> derrotar\n",
            "al ----> al\n",
            "equipo ----> equipar\n",
            "contrario ----> contrario\n",
            "a ----> a\n",
            "través ----> través\n",
            "de ----> de\n",
            "partidos ----> partir\n",
            "llenos ----> lleno\n",
            "de ----> de\n",
            "elementos ----> elemento\n",
            "dinámicos ----> dinámico\n",
            "Stab ----> Stab\n",
            "Stab ----> Stab\n",
            "Stab ----> Stab\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "apuñalamiento ----> apuñalamiento\n",
            "de ----> de\n",
            "arena ----> arenar\n",
            "basado ----> basar\n",
            "en ----> en\n",
            "la ----> lo\n",
            "física ----> físico\n",
            "para ----> parir\n",
            "jugadores ----> jugador\n",
            "múltiples ----> múltiple\n",
            "para ----> parir\n",
            "hasta ----> hasta\n",
            "cuatro ----> cuatro\n",
            "jugadores ----> jugador\n",
            ". ----> .\n",
            "Juega ----> Juega\n",
            "como ----> comer\n",
            "aves ----> ave\n",
            "de ----> de\n",
            "carne ----> carne\n",
            "explosivas ----> explosivo\n",
            "con ----> con\n",
            "picos ----> pico\n",
            "afilados ----> afilar\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "dicha ----> decir\n",
            "para ----> parir\n",
            "jugar ----> jugar\n",
            ", ----> ,\n",
            "mirar ----> mirar\n",
            "y ----> y\n",
            "escuchar ----> escuchar\n",
            ". ----> .\n",
            "Los ----> Los\n",
            "momentos ----> momento\n",
            "de ----> de\n",
            "OG ----> OG\n",
            "te ----> te\n",
            "llenarán ----> llenar\n",
            "de ----> de\n",
            "nostalgia ----> nostalgia\n",
            ", ----> ,\n",
            "mientras ----> mientras\n",
            "que ----> que\n",
            "las ----> los\n",
            "partes ----> partir\n",
            "nuevas ----> nuevo\n",
            "y ----> y\n",
            "reimaginadas ----> reimaginadas\n",
            "despertarán ----> despertar\n",
            "tu ----> tu\n",
            "curiosidad ----> curiosidad\n",
            "por ----> por\n",
            "lo ----> el\n",
            "que ----> que\n",
            "está ----> estar\n",
            "por ----> por\n",
            "venir ----> venir\n",
            ". ----> .\n",
            "Square ----> Square\n",
            "Enix ----> Enix\n",
            "enfrentó ----> enfrentar\n",
            "botas ----> boto\n",
            "del ----> del\n",
            "tamaño ----> tamaño\n",
            "de ----> de\n",
            "un ----> uno\n",
            "océano ----> océano\n",
            ", ----> ,\n",
            "las ----> los\n",
            "llenó ----> llenar\n",
            "por ----> por\n",
            "completo ----> completar\n",
            "y ----> y\n",
            "corrió ----> correr\n",
            "a ----> a\n",
            "correr ----> correr\n",
            "con ----> con\n",
            "ellas ----> ellos\n",
            "Tempest ----> Tempest\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "rol ----> rol\n",
            "de ----> de\n",
            "acción ----> acción\n",
            "pirata ----> pirata\n",
            "de ----> de\n",
            "mundo ----> mundo\n",
            "abierto ----> abrir\n",
            "que ----> que\n",
            "ofrece ----> ofrecer\n",
            "una ----> uno\n",
            "capacidad ----> capacidad\n",
            "máxima ----> máximo\n",
            "para ----> parir\n",
            "recorrer ----> recorrer\n",
            "libremente ----> libremente\n",
            "tres ----> tres\n",
            "vastos ----> vasto\n",
            "mundos ----> mundo\n",
            "llenos ----> lleno\n",
            "de ----> de\n",
            "docenas ----> doceno\n",
            "de ----> de\n",
            "colonias ----> colonia\n",
            "y ----> y\n",
            "fortalezas ----> fortaleza\n",
            ", ----> ,\n",
            "cientos ----> ciento\n",
            "de ----> de\n",
            "misiones ----> misionar\n",
            "e ----> e\n",
            "innumerables ----> innumerable\n",
            "barcos ----> barco\n",
            "para ----> parir\n",
            "saquear ----> saquear\n",
            ". ----> .\n",
            "Intercambia ----> Intercambia\n",
            ", ----> ,\n",
            "lucha ----> luchar\n",
            ", ----> ,\n",
            "explora ----> explorar\n",
            "por ----> por\n",
            "tu ----> tu\n",
            "cuenta ----> contar\n",
            "o ----> o\n",
            "llama ----> llamar\n",
            "a ----> a\n",
            "tus ----> tu\n",
            "amigos ----> amigo\n",
            "para ----> parir\n",
            "que ----> que\n",
            "hagan ----> hacer\n",
            "lo ----> el\n",
            "mismo ----> mismo\n",
            "juntos ----> junto\n",
            "¡ ----> ¡\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "golf ----> golf\n",
            "para ----> parir\n",
            "personas ----> personar\n",
            "que ----> que\n",
            "odian ----> odiar\n",
            "el ----> el\n",
            "golf ----> golf\n",
            "! ----> !\n",
            "Una ----> Una\n",
            "tonta ----> tonto\n",
            "parodia ----> parodiar\n",
            "de ----> de\n",
            "golf ----> golf\n",
            "basada ----> basar\n",
            "en ----> en\n",
            "la ----> lo\n",
            "física ----> físico\n",
            "donde ----> donde\n",
            "cada ----> cada\n",
            "campo ----> campar\n",
            "de ----> de\n",
            "golf ----> golf\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "nuevo ----> nuevo\n",
            "tipo ----> tipo\n",
            "sorprendente ----> sorprendente\n",
            "de ----> de\n",
            "golf ----> golf\n",
            ", ----> ,\n",
            "algunos ----> alguno\n",
            "brillantes ----> brillante\n",
            "o ----> o\n",
            "divertidos ----> divertir\n",
            "Una ----> Una\n",
            "guerra ----> guerra\n",
            "de ----> de\n",
            "fantasía ----> fantasía\n",
            "sin ----> sin\n",
            "fin ----> fin\n",
            "Gran ----> Gran\n",
            "estrategia ----> estrategia\n",
            "de ----> de\n",
            "simulación ----> simulación\n",
            ". ----> .\n",
            "Conquista ----> Conquista\n",
            "el ----> el\n",
            "continente ----> continente\n",
            "en ----> en\n",
            "este ----> este\n",
            "gran ----> gran\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "simulación ----> simulación\n",
            "de ----> de\n",
            "estrategia ----> estrategia\n",
            ". ----> .\n",
            "El ----> El\n",
            "continente ----> continente\n",
            "de ----> de\n",
            "Runersia ----> Runersia\n",
            "es ----> ser\n",
            "el ----> el\n",
            "hogar ----> hogar\n",
            "de ----> de\n",
            "seis ----> seis\n",
            "potencias ----> potenciar\n",
            "principales ----> principal\n",
            "con ----> con\n",
            "más ----> más\n",
            "de ----> de\n",
            "40 ----> 40\n",
            "bases ----> base\n",
            ", ----> ,\n",
            "100 ----> 100\n",
            "caballeros ----> caballero\n",
            "y ----> y\n",
            "50 ----> 50\n",
            "tipos ----> tipo\n",
            "de ----> de\n",
            "monstruos ----> monstruo\n",
            "En ----> En\n",
            "el ----> el\n",
            "año ----> año\n",
            "2091 ----> 2091\n",
            ", ----> ,\n",
            "los ----> lo\n",
            "avances ----> avanzar\n",
            "generalizados ----> generalizar\n",
            "en ----> en\n",
            "tecnología ----> tecnología\n",
            "e ----> e\n",
            "informática ----> informático\n",
            "no ----> no\n",
            "han ----> haber\n",
            "cambiado ----> cambiar\n",
            "la ----> lo\n",
            "naturaleza ----> naturaleza\n",
            "humana ----> humano\n",
            ". ----> .\n",
            "Jugar ----> Jugar\n",
            "con ----> con\n",
            "la ----> lo\n",
            "vida ----> vida\n",
            "de ----> de\n",
            "las ----> los\n",
            "personas ----> personar\n",
            "nunca ----> nunca\n",
            "ha ----> haber\n",
            "sido ----> ser\n",
            "más ----> más\n",
            "divertido ----> divertir\n",
            "Es ----> Es\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "genial ----> genial\n",
            ". ----> .\n",
            "Aunque ----> Aunque\n",
            "igual ----> igual\n",
            "creo ----> creer\n",
            "que ----> que\n",
            "las ----> los\n",
            "partes ----> partir\n",
            "no ----> no\n",
            "tan ----> tan\n",
            "importantes ----> importante\n",
            "las ----> los\n",
            "hicieron ----> hacer\n",
            "bastante ----> bastante\n",
            "largas ----> largo\n",
            "pudiendo ----> poder\n",
            "enfocarse ----> enfocarse\n",
            "en ----> en\n",
            "cubrir ----> cubrir\n",
            "más ----> más\n",
            "historia ----> historia\n",
            ". ----> .\n",
            "También ----> También\n",
            "entrando ----> entrar\n",
            "que ----> que\n",
            "sería ----> ser\n",
            "difícil ----> difícil\n",
            "incluir ----> incluir\n",
            "en ----> en\n",
            "esta ----> este\n",
            "primera ----> primero\n",
            "parte ----> partir\n",
            "un ----> uno\n",
            "mundo ----> mundo\n",
            "abierto ----> abrir\n",
            "al ----> al\n",
            "salir ----> salir\n",
            "de ----> de\n",
            "midgar ----> midgar\n",
            "por ----> por\n",
            "lo ----> el\n",
            "que ----> que\n",
            "tal ----> tal\n",
            "vez ----> vez\n",
            "lo ----> el\n",
            "hicieron ----> hacer\n",
            "así ----> asir\n",
            "y ----> y\n",
            "cortaron ----> cortar\n",
            "allí ----> allí\n",
            "exactamente ----> exactamente\n",
            ". ----> .\n",
            "Excelente ----> Excelente\n",
            "Remake ----> Remake\n",
            ", ----> ,\n",
            "espero ----> esperar\n",
            "la ----> lo\n",
            "segunda ----> segundar\n",
            "parte ----> partir\n",
            "con ----> con\n",
            "emoción ----> emoción\n",
            "y ----> y\n",
            "ojalá ----> ojalá\n",
            "sea ----> ser\n",
            "mundo ----> mundo\n",
            "abierto ----> abrir\n",
            "Saints ----> Saints\n",
            "& ----> &\n",
            "Sinners ----> Sinners\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "diferente ----> diferente\n",
            "a ----> a\n",
            "cualquier ----> cualquiera\n",
            "otro ----> otro\n",
            "en ----> en\n",
            "el ----> el\n",
            "universo ----> universo\n",
            "de ----> de\n",
            "The ----> The\n",
            "Walking ----> Walking\n",
            "Dead ----> Dead\n",
            ". ----> .\n",
            "USTED ----> USTED\n",
            "impulsa ----> impulsar\n",
            "cada ----> cada\n",
            "desafío ----> desafiar\n",
            "que ----> que\n",
            "enfrenta ----> enfrentar\n",
            "y ----> y\n",
            "la ----> lo\n",
            "decisión ----> decisión\n",
            "que ----> que\n",
            "toma ----> tomar\n",
            ". ----> .\n",
            "Lucha ----> Lucha\n",
            "contra ----> contra\n",
            "los ----> lo\n",
            "muertos ----> muerto\n",
            "vivientes ----> viviente\n",
            ", ----> ,\n",
            "recorre ----> recorrer\n",
            "las ----> los\n",
            "ruinas ----> ruina\n",
            "inundadas ----> inundar\n",
            "de ----> de\n",
            "Nueva ----> Nueva\n",
            "Orleans ----> Orleans\n",
            "y ----> y\n",
            "enfréntate ----> enfréntate\n",
            "a ----> a\n",
            "opciones ----> opción\n",
            "desgarradoras ----> desgarrador\n",
            "para ----> parir\n",
            "ti ----> ti\n",
            "y ----> y\n",
            "los ----> lo\n",
            "demás ----> demás\n",
            "sobrevivientes ----> sobreviviente\n",
            "Juego ----> Juego\n",
            "increíblemente ----> increíblemente\n",
            "divertido ----> divertir\n",
            ", ----> ,\n",
            "ya ----> ya\n",
            "jugué ----> jugar\n",
            "varios ----> vario\n",
            "partidos ----> partir\n",
            ", ----> ,\n",
            "hasta ----> hasta\n",
            "el ----> el\n",
            "nivel ----> nivel\n",
            "10 ----> 10\n",
            ". ----> .\n",
            "Predator ----> Predator\n",
            "me ----> me\n",
            "asusta ----> asustar\n",
            "cuando ----> cuando\n",
            "me ----> me\n",
            "persigue ----> perseguir\n",
            ", ----> ,\n",
            "corro ----> correr\n",
            "lo ----> el\n",
            "más ----> más\n",
            "rápido ----> rápido\n",
            "que ----> que\n",
            "puedo ----> poder\n",
            ". ----> .\n",
            "¡ ----> ¡\n",
            "La ----> La\n",
            "animación ----> animación\n",
            "de ----> de\n",
            "recolección ----> recolección\n",
            "de ----> de\n",
            "trofeos ----> trofeo\n",
            "después ----> después\n",
            "de ----> de\n",
            "que ----> que\n",
            "te ----> te\n",
            "mate ----> matar\n",
            "es ----> ser\n",
            "INCREÍBLE ----> INCREÍBLE\n",
            "! ----> !\n",
            "¡ ----> ¡\n",
            "Jugaré ----> Jugaré\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "por ----> por\n",
            "un ----> uno\n",
            "tiempo ----> tiempo\n",
            "! ----> !\n",
            "Creo ----> Creo\n",
            "que ----> que\n",
            "es ----> ser\n",
            "maravillosamente ----> maravillosamente\n",
            "emocionante ----> emocionante\n",
            ". ----> .\n",
            "Si ----> Si\n",
            "obtiene ----> obtener\n",
            "apoyo ----> apoyar\n",
            "y ----> y\n",
            "continúa ----> continuar\n",
            "creciendo ----> crecer\n",
            ", ----> ,\n",
            "puede ----> poder\n",
            "obtener ----> obtener\n",
            "el ----> el\n",
            "éxito ----> éxito\n",
            "que ----> que\n",
            "merece ----> merecer\n",
            "la ----> lo\n",
            "fórmula ----> fórmula\n",
            "Daymare ----> Daymare\n",
            ": ----> :\n",
            "1998 ----> 1998\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "terror ----> terror\n",
            "y ----> y\n",
            "supervivencia ----> supervivencia\n",
            "en ----> en\n",
            "tercera ----> tercero\n",
            "persona ----> personar\n",
            "con ----> con\n",
            "cámara ----> cámara\n",
            "sobre ----> sobrar\n",
            "el ----> el\n",
            "hombro ----> hombro\n",
            ", ----> ,\n",
            "desarrollado ----> desarrollar\n",
            "en ----> en\n",
            "Unreal ----> Unreal\n",
            "Engine ----> Engine\n",
            "4 ----> 4\n",
            "para ----> parir\n",
            "PC ----> PC\n",
            "con ----> con\n",
            "Windows ----> Windows\n",
            ". ----> .\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "presenta ----> presentar\n",
            "gráficos ----> gráfico\n",
            "de ----> de\n",
            "alta ----> alto\n",
            "gama ----> gama\n",
            ", ----> ,\n",
            "banda ----> banda\n",
            "sonora ----> sonoro\n",
            "original ----> original\n",
            ", ----> ,\n",
            "atmósfera ----> atmósfera\n",
            "inmersiva ----> inmersiva\n",
            ", ----> ,\n",
            "mecánica ----> mecánico\n",
            "de ----> de\n",
            "supervivencia ----> supervivencia\n",
            "hardcore ----> hardcore\n",
            "y ----> y\n",
            "muchas ----> mucho\n",
            "conexiones ----> conexionar\n",
            "con ----> con\n",
            "los ----> lo\n",
            "adorados ----> adorar\n",
            "juegos ----> juego\n",
            "de ----> de\n",
            "terror ----> terror\n",
            "de ----> de\n",
            "supervivencia ----> supervivencia\n",
            "de ----> de\n",
            "la ----> lo\n",
            "vieja ----> viejo\n",
            "escuela ----> escuela\n",
            "Experimente ----> Experimente\n",
            "el ----> el\n",
            "paquete ----> paquete\n",
            "completo ----> completar\n",
            ", ----> ,\n",
            "remasterizado ----> remasterizado\n",
            ". ----> .\n",
            "Steelport ----> Steelport\n",
            ", ----> ,\n",
            "la ----> lo\n",
            "ciudad ----> ciudad\n",
            "original ----> original\n",
            "del ----> del\n",
            "pecado ----> pecar\n",
            ", ----> ,\n",
            "nunca ----> nunca\n",
            "se ----> se\n",
            "había ----> haber\n",
            "visto ----> vestir\n",
            "tan ----> tan\n",
            "bien ----> bien\n",
            ", ----> ,\n",
            "ya ----> ya\n",
            "que ----> que\n",
            "se ----> se\n",
            "ahoga ----> ahogar\n",
            "en ----> en\n",
            "sexo ----> sexo\n",
            ", ----> ,\n",
            "drogas ----> drogar\n",
            "y ----> y\n",
            "armas ----> armar\n",
            ". ----> .\n",
            "Los ----> Los\n",
            "Third ----> Third\n",
            "Street ----> Street\n",
            "Saints ----> Saints\n",
            "están ----> estar\n",
            "a ----> a\n",
            "la ----> lo\n",
            "altura ----> altura\n",
            "del ----> del\n",
            "poder ----> poder\n",
            "y ----> y\n",
            "los ----> lo\n",
            "tuyos ----> tuyo\n",
            "pueden ----> poder\n",
            "controlar ----> controlar\n",
            "Un ----> Un\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "suspenso ----> suspender\n",
            "de ----> de\n",
            "investigación ----> investigación\n",
            "con ----> con\n",
            "narración ----> narración\n",
            "no ----> no\n",
            "lineal ----> lineal\n",
            ", ----> ,\n",
            "Telling ----> Telling\n",
            "Lies ----> Lies\n",
            "gira ----> girar\n",
            "en ----> en\n",
            "torno ----> tornar\n",
            "a ----> a\n",
            "un ----> uno\n",
            "caché ----> cachar\n",
            "de ----> de\n",
            "conversaciones ----> conversación\n",
            "de ----> de\n",
            "video ----> video\n",
            "grabadas ----> grabar\n",
            "en ----> en\n",
            "secreto ----> secretar\n",
            "Además ----> Además\n",
            "de ----> de\n",
            "presentar ----> presentar\n",
            "NPC ----> NPC\n",
            "totalmente ----> totalmente\n",
            "expresados ----> expresar\n",
            "​​al ----> ​​al\n",
            "mundo ----> mundo\n",
            "de ----> de\n",
            "Fallout ----> Fallout\n",
            "76 ----> 76\n",
            ", ----> ,\n",
            "Wastelanders ----> Wastelanders\n",
            "trae ----> traer\n",
            "una ----> uno\n",
            "nueva ----> nuevo\n",
            "línea ----> líneo\n",
            "de ----> de\n",
            "búsqueda ----> búsqueda\n",
            "principal ----> principal\n",
            ", ----> ,\n",
            "nuevas ----> nuevo\n",
            "ubicaciones ----> ubicación\n",
            ", ----> ,\n",
            "nuevos ----> nuevo\n",
            "enemigos ----> enemigo\n",
            ", ----> ,\n",
            "nuevas ----> nuevo\n",
            "armas ----> armar\n",
            ", ----> ,\n",
            "un ----> uno\n",
            "nuevo ----> nuevo\n",
            "sistema ----> sistema\n",
            "de ----> de\n",
            "reputación ----> reputación\n",
            "y ----> y\n",
            "mucho ----> mucho\n",
            "más ----> más\n",
            "Beyond ----> Beyond\n",
            "Blue ----> Blue\n",
            "lleva ----> llevar\n",
            "a ----> a\n",
            "los ----> lo\n",
            "jugadores ----> jugador\n",
            "al ----> al\n",
            "futuro ----> futuro\n",
            "cercano ----> cercano\n",
            ", ----> ,\n",
            "donde ----> donde\n",
            "tendrán ----> tener\n",
            "la ----> lo\n",
            "oportunidad ----> oportunidad\n",
            "de ----> de\n",
            "explorar ----> explorar\n",
            "los ----> lo\n",
            "misterios ----> misterio\n",
            "de ----> de\n",
            "nuestro ----> nuestro\n",
            "océano ----> océano\n",
            "a ----> a\n",
            "través ----> través\n",
            "de ----> de\n",
            "los ----> lo\n",
            "ojos ----> ojo\n",
            "de ----> de\n",
            "Mirai ----> Mirai\n",
            ", ----> ,\n",
            "un ----> uno\n",
            "explorador ----> explorador\n",
            "y ----> y\n",
            "científico ----> científico\n",
            "de ----> de\n",
            "las ----> los\n",
            "profundidades ----> profundidad\n",
            "del ----> del\n",
            "mar ----> mar\n",
            "Sube ----> Sube\n",
            "el ----> el\n",
            "puntaje ----> puntaje\n",
            "en ----> en\n",
            "una ----> uno\n",
            "pelea ----> pelear\n",
            "relajada ----> relajar\n",
            "o ----> o\n",
            "supera ----> superar\n",
            "los ----> lo\n",
            "límites ----> límite\n",
            "de ----> de\n",
            "tus ----> tu\n",
            "reflejos ----> reflejo\n",
            "en ----> en\n",
            "este ----> este\n",
            "refinado ----> refinar\n",
            "simulador ----> simulador\n",
            "de ----> de\n",
            "béisbol ----> béisbol\n",
            ". ----> .\n",
            "La ----> La\n",
            "tercera ----> tercero\n",
            "entrada ----> entrar\n",
            "de ----> de\n",
            "la ----> lo\n",
            "serie ----> seriar\n",
            "presenta ----> presentar\n",
            "un ----> uno\n",
            "modo ----> modo\n",
            "de ----> de\n",
            "franquicia ----> franquicia\n",
            "completamente ----> completamente\n",
            "nuevo ----> nuevo\n",
            ", ----> ,\n",
            "importantes ----> importante\n",
            "mejoras ----> mejorar\n",
            "gráficas ----> gráfico\n",
            "y ----> y\n",
            "adiciones ----> adicionar\n",
            "en ----> en\n",
            "el ----> el\n",
            "campo ----> campar\n",
            ", ----> ,\n",
            "incluidos ----> incluir\n",
            "los ----> lo\n",
            "pickoffs ----> pickoffs\n",
            "y ----> y\n",
            "los ----> lo\n",
            "rasgos ----> rasgo\n",
            "situacionales ----> situacional\n",
            "del ----> del\n",
            "jugador ----> jugador\n",
            "A ----> A\n",
            "través ----> través\n",
            "del ----> del\n",
            "juego ----> jugar\n",
            ", ----> ,\n",
            "los ----> lo\n",
            "jugadores ----> jugador\n",
            "pueden ----> poder\n",
            "experimentar ----> experimentar\n",
            "el ----> el\n",
            "miedo ----> miedo\n",
            "provocado ----> provocar\n",
            "por ----> por\n",
            "un ----> uno\n",
            "terremoto ----> terremoto\n",
            "y ----> y\n",
            "pueden ----> poder\n",
            "aprender ----> aprender\n",
            "que ----> que\n",
            "la ----> lo\n",
            "sabiduría ----> sabiduría\n",
            ", ----> ,\n",
            "la ----> lo\n",
            "valentía ----> valentía\n",
            "y ----> y\n",
            "el ----> el\n",
            "vínculo ----> vínculo\n",
            "de ----> de\n",
            "las ----> los\n",
            "personas ----> personar\n",
            "a ----> a\n",
            "través ----> través\n",
            "de ----> de\n",
            "la ----> lo\n",
            "asistencia ----> asistencia\n",
            "mutua ----> mutuo\n",
            "son ----> ser\n",
            "necesarias ----> necesario\n",
            "para ----> parir\n",
            "la ----> lo\n",
            "supervivencia ----> supervivencia\n",
            "John ----> John\n",
            "Wick ----> Wick\n",
            "Hex ----> Hex\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "estrategia ----> estrategia\n",
            "rápido ----> rápido\n",
            "y ----> y\n",
            "orientado ----> orientar\n",
            "a ----> a\n",
            "la ----> lo\n",
            "acción ----> acción\n",
            "que ----> que\n",
            "te ----> te\n",
            "hace ----> hacer\n",
            "pensar ----> pensar\n",
            "y ----> y\n",
            "golpear ----> golpear\n",
            "como ----> comer\n",
            "John ----> John\n",
            "Wick ----> Wick\n",
            ", ----> ,\n",
            "el ----> el\n",
            "asesino ----> asesinar\n",
            "profesional ----> profesional\n",
            "de ----> de\n",
            "la ----> lo\n",
            "franquicia ----> franquicia\n",
            "cinematográfica ----> cinematográfico\n",
            "aclamada ----> aclamar\n",
            "por ----> por\n",
            "la ----> lo\n",
            "crítica ----> crítico\n",
            "Ellie ----> Ellie\n",
            "se ----> se\n",
            "embarca ----> embarcar\n",
            "en ----> en\n",
            "un ----> uno\n",
            "viaje ----> viajar\n",
            "implacable ----> implacable\n",
            "para ----> parir\n",
            "llevar ----> llevar\n",
            "a ----> a\n",
            "cabo ----> cabo\n",
            "la ----> lo\n",
            "justicia ----> justicia\n",
            "y ----> y\n",
            "encontrar ----> encontrar\n",
            "el ----> el\n",
            "cierre ----> cerrar\n",
            ". ----> .\n",
            "Mientras ----> Mientras\n",
            "caza ----> cazar\n",
            "a ----> a\n",
            "los ----> lo\n",
            "responsables ----> responsable\n",
            "uno ----> unir\n",
            "por ----> por\n",
            "uno ----> unir\n",
            ", ----> ,\n",
            "se ----> se\n",
            "enfrenta ----> enfrentar\n",
            "a ----> a\n",
            "las ----> los\n",
            "devastadoras ----> devastador\n",
            "repercusiones ----> repercusión\n",
            "físicas ----> físico\n",
            "y ----> y\n",
            "emocionales ----> emocional\n",
            "de ----> de\n",
            "sus ----> su\n",
            "acciones ----> accionar\n",
            "Command ----> Command\n",
            "& ----> &\n",
            "Conquer ----> Conquer\n",
            "y ----> y\n",
            "Red ----> Red\n",
            "Alert ----> Alert\n",
            "son ----> ser\n",
            "remasterizados ----> remasterizados\n",
            "en ----> en\n",
            "4 ----> 4\n",
            "K ----> K\n",
            "por ----> por\n",
            "los ----> lo\n",
            "antiguos ----> antiguo\n",
            "miembros ----> miembro\n",
            "del ----> del\n",
            "equipo ----> equipar\n",
            "de ----> de\n",
            "Westwood ----> Westwood\n",
            "Studios ----> Studios\n",
            ". ----> .\n",
            "Incluye ----> Incluye\n",
            "las ----> los\n",
            "3 ----> 3\n",
            "expansiones ----> expansionar\n",
            ", ----> ,\n",
            "multijugador ----> multijugador\n",
            "reconstruido ----> reconstruir\n",
            ", ----> ,\n",
            "una ----> uno\n",
            "interfaz ----> interfaz\n",
            "de ----> de\n",
            "usuario ----> usuario\n",
            "modernizada ----> modernizar\n",
            ", ----> ,\n",
            "Editor ----> Editor\n",
            "de ----> de\n",
            "mapas ----> mapa\n",
            ", ----> ,\n",
            "galería ----> galería\n",
            "de ----> de\n",
            "imágenes ----> imagen\n",
            "adicionales ----> adicional\n",
            "y ----> y\n",
            "más ----> más\n",
            "de ----> de\n",
            "7 ----> 7\n",
            "horas ----> hora\n",
            "de ----> de\n",
            "música ----> músico\n",
            "remasterizada ----> remasterizada\n",
            "' ----> '\n",
            "Summer ----> Summer\n",
            "in ----> in\n",
            "Mara ----> Mara\n",
            "' ----> '\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "aventura ----> aventurar\n",
            "de ----> de\n",
            "verano ----> verano\n",
            "con ----> con\n",
            "elementos ----> elemento\n",
            "fáciles ----> fácil\n",
            "de ----> de\n",
            "juegos ----> juego\n",
            "de ----> de\n",
            "rol ----> rol\n",
            "y ----> y\n",
            "mecánicas ----> mecánico\n",
            "de ----> de\n",
            "cultivo ----> cultivar\n",
            ", ----> ,\n",
            "artesanía ----> artesanía\n",
            "y ----> y\n",
            "exploración ----> exploración\n",
            "en ----> en\n",
            "un ----> uno\n",
            "archipiélago ----> archipiélago\n",
            "tropical ----> tropical\n",
            ". ----> .\n",
            "' ----> '\n",
            "Summer ----> Summer\n",
            "in ----> in\n",
            "Mara ----> Mara\n",
            "' ----> '\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "experiencia ----> experiencia\n",
            "para ----> parir\n",
            "un ----> uno\n",
            "jugador ----> jugador\n",
            "en ----> en\n",
            "un ----> uno\n",
            "ambiente ----> ambientar\n",
            "tranquilo ----> tranquilo\n",
            "y ----> y\n",
            "relajante ----> relajante\n",
            ", ----> ,\n",
            "con ----> con\n",
            "un ----> uno\n",
            "aspecto ----> aspecto\n",
            "artesanal ----> artesanal\n",
            "y ----> y\n",
            "una ----> uno\n",
            "narrativa ----> narrativo\n",
            "interesante ----> interesante\n",
            ". ----> .\n",
            "Serás ----> Serás\n",
            "Koa ----> Koa\n",
            ", ----> ,\n",
            "una ----> uno\n",
            "pequeña ----> pequeño\n",
            "aventurera ----> aventurero\n",
            "que ----> que\n",
            "quiere ----> querer\n",
            "explorar ----> explorar\n",
            "el ----> el\n",
            "mundo ----> mundo\n",
            "que ----> que\n",
            "la ----> lo\n",
            "rodea ----> rodear\n",
            "Monster ----> Monster\n",
            "Train ----> Train\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "construcción ----> construcción\n",
            "de ----> de\n",
            "mazos ----> mazo\n",
            "roguelike ----> roguelike\n",
            "estratégico ----> estratégico\n",
            "con ----> con\n",
            "un ----> uno\n",
            "toque ----> tocar\n",
            "diferente ----> diferente\n",
            ". ----> .\n",
            "Ubicado ----> Ubicado\n",
            "en ----> en\n",
            "un ----> uno\n",
            "tren ----> tren\n",
            "al ----> al\n",
            "infierno ----> infierno\n",
            ", ----> ,\n",
            "usarás ----> usar\n",
            "la ----> lo\n",
            "toma ----> tomar\n",
            "de ----> de\n",
            "decisiones ----> decisión\n",
            "tácticas ----> táctico\n",
            "para ----> parir\n",
            "defender ----> defender\n",
            "múltiples ----> múltiple\n",
            "campos ----> campo\n",
            "de ----> de\n",
            "batalla ----> batallar\n",
            "verticales ----> vertical\n",
            ". ----> .\n",
            "Con ----> Con\n",
            "el ----> el\n",
            "modo ----> modo\n",
            "multijugador ----> multijugador\n",
            "competitivo ----> competitivo\n",
            "en ----> en\n",
            "tiempo ----> tiempo\n",
            "real ----> real\n",
            "y ----> y\n",
            "la ----> lo\n",
            "repetibilidad ----> repetibilidad\n",
            "infinita ----> infinito\n",
            ", ----> ,\n",
            "Monster ----> Monster\n",
            "Train ----> Train\n",
            "siempre ----> siempre\n",
            "llega ----> llegar\n",
            "a ----> a\n",
            "tiempo ----> tiempo\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "está ----> estar\n",
            "destinado ----> destinar\n",
            "a ----> a\n",
            "sumergirte ----> sumergirte\n",
            "en ----> en\n",
            "la ----> lo\n",
            "mente ----> mente\n",
            "de ----> de\n",
            "John ----> John\n",
            ", ----> ,\n",
            "a ----> a\n",
            "medida ----> medir\n",
            "que ----> que\n",
            "avanzas ----> avanzar\n",
            "cada ----> cada\n",
            "paso ----> pasar\n",
            "hacia ----> hacia\n",
            "el ----> el\n",
            "retorcido ----> retorcer\n",
            "misterio ----> misterio\n",
            "de ----> de\n",
            "lo ----> el\n",
            "que ----> que\n",
            "sucedió ----> suceder\n",
            "Probablemente ----> Probablemente\n",
            "el ----> el\n",
            "mejor ----> mejor\n",
            "juego ----> jugar\n",
            "que ----> que\n",
            "jugué ----> jugar\n",
            "en ----> en\n",
            "los ----> lo\n",
            "últimos ----> último\n",
            "10 ----> 10\n",
            "años ----> año\n",
            ". ----> .\n",
            "Nuevos ----> Nuevos\n",
            "gráficos ----> gráfico\n",
            "realistas ----> realista\n",
            ", ----> ,\n",
            "mecánica ----> mecánico\n",
            ", ----> ,\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "simplemente ----> simplemente\n",
            "increíble ----> increíble\n",
            ". ----> .\n",
            "12/10 ----> 12/10\n",
            "Sony ----> Sony\n",
            "San ----> San\n",
            "Diego ----> Diego\n",
            "evitó ----> evitar\n",
            "desarrollar ----> desarrollar\n",
            "viñetas ----> viñeta\n",
            "llamativas ----> llamativo\n",
            "en ----> en\n",
            "la ----> lo\n",
            "parte ----> partir\n",
            "posterior ----> posterior\n",
            "de ----> de\n",
            "la ----> lo\n",
            "caja ----> caja\n",
            "a ----> a\n",
            "favor ----> favor\n",
            "de ----> de\n",
            "refinar ----> refinar\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "ya ----> ya\n",
            "excelente ----> excelente\n",
            ", ----> ,\n",
            "exhibiendo ----> exhibir\n",
            "una ----> uno\n",
            "confianza ----> confianza\n",
            "que ----> que\n",
            "en ----> en\n",
            "sí ----> sí\n",
            "misma ----> mismo\n",
            "es ----> ser\n",
            "notablemente ----> notablemente\n",
            "notable ----> notable\n",
            ", ----> ,\n",
            "al ----> al\n",
            "igual ----> igual\n",
            "que ----> que\n",
            "la ----> lo\n",
            "consistencia ----> consistencia\n",
            "de ----> de\n",
            "esta ----> este\n",
            "serie ----> seriar\n",
            "MLB ----> MLB\n",
            "15 ----> 15\n",
            ": ----> :\n",
            "The ----> The\n",
            "Show ----> Show\n",
            "es ----> ser\n",
            "el ----> el\n",
            "mejor ----> mejor\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "béisbol ----> béisbol\n",
            "jamás ----> jamás\n",
            "creado ----> crear\n",
            ". ----> .\n",
            "Pero ----> Pero\n",
            "lo ----> el\n",
            "hemos ----> hemo\n",
            "dicho ----> decir\n",
            "antes ----> antes\n",
            "sobre ----> sobrar\n",
            "sus ----> su\n",
            "predecesores ----> predecesor\n",
            "Oye ----> Oye\n",
            ", ----> ,\n",
            "como ----> comer\n",
            "siempre ----> siempre\n",
            "digo ----> decir\n",
            ", ----> ,\n",
            "si ----> si\n",
            "no ----> no\n",
            "está ----> estar\n",
            "roto ----> rotar\n",
            ", ----> ,\n",
            "no ----> no\n",
            "lo ----> el\n",
            "arregles ----> arreglar\n",
            ". ----> .\n",
            "Más ----> Más\n",
            "de ----> de\n",
            "lo ----> el\n",
            "mismo ----> mismo\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "sigue ----> seguir\n",
            "siendo ----> ser\n",
            "el ----> el\n",
            "mejor ----> mejor\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "deportes ----> deporte\n",
            "en ----> en\n",
            "este ----> este\n",
            "momento ----> momento\n",
            "Los ----> Los\n",
            "gráficos ----> gráfico\n",
            "son ----> ser\n",
            "lentos ----> lento\n",
            ", ----> ,\n",
            "inconsistentes ----> inconsistente\n",
            ", ----> ,\n",
            "con ----> con\n",
            "ralentizaciones ----> ralentización\n",
            "extremas ----> extremo\n",
            ", ----> ,\n",
            "desgarros ----> desgarro\n",
            "y ----> y\n",
            "saltos ----> salto\n",
            "de ----> de\n",
            "fotogramas ----> fotograma\n",
            "Fps ----> Fps\n",
            "muy ----> muy\n",
            "bajos ----> bajo\n",
            "en ----> en\n",
            "Ps4 ----> Ps4\n",
            "Pro ----> Pro\n",
            ", ----> ,\n",
            "por ----> por\n",
            "lo ----> el\n",
            "que ----> que\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "no ----> no\n",
            "se ----> se\n",
            "puede ----> poder\n",
            "jugar ----> jugar\n",
            "y ----> y\n",
            "Graphic ----> Graphic\n",
            "es ----> ser\n",
            "horrible ----> horrible\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "realmente ----> realmente\n",
            "malo ----> malo\n",
            ", ----> ,\n",
            "baja ----> bajo\n",
            "fps ----> fps\n",
            ", ----> ,\n",
            "retraso ----> retrasar\n",
            ", ----> ,\n",
            "mala ----> malo\n",
            "física ----> físico\n",
            "y ----> y\n",
            "más ----> más\n",
            "La ----> La\n",
            "gente ----> gente\n",
            "quiere ----> querer\n",
            "jugar ----> jugar\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "para ----> parir\n",
            "la ----> lo\n",
            "historia ----> historia\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "la ----> lo\n",
            "historia ----> historia\n",
            "es ----> ser\n",
            "muy ----> muy\n",
            "mala ----> malo\n",
            "Después ----> Después\n",
            "de ----> de\n",
            "más ----> más\n",
            "de ----> de\n",
            "una ----> uno\n",
            "docena ----> doceno\n",
            "de ----> de\n",
            "horas ----> hora\n",
            ", ----> ,\n",
            "puedo ----> poder\n",
            "decir ----> decir\n",
            "que ----> que\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "está ----> estar\n",
            "dolorosamente ----> dolorosamente\n",
            "sobrevalorado ----> sobrevalorar\n",
            "Uno ----> Uno\n",
            "de ----> de\n",
            "los ----> lo\n",
            "peores ----> peor\n",
            "juegos ----> juego\n",
            "que ----> que\n",
            "jugué ----> jugar\n",
            "últimamente ----> últimamente\n",
            "Este ----> Este\n",
            "es ----> ser\n",
            "uno ----> unir\n",
            "de ----> de\n",
            "esos ----> ese\n",
            "grandes ----> grande\n",
            "juegos ----> juego\n",
            "bellamente ----> bellamente\n",
            "aburridos ----> aburrir\n",
            "que ----> que\n",
            "tiene ----> tener\n",
            "1 ----> 1\n",
            "fuente ----> fuente\n",
            "de ----> de\n",
            "logro ----> lograr\n",
            ", ----> ,\n",
            "el ----> el\n",
            "realismo ----> realismo\n",
            ", ----> ,\n",
            "y ----> y\n",
            "no ----> no\n",
            "es ----> ser\n",
            "divertido ----> divertir\n",
            "fue ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "muy ----> muy\n",
            "horrible ----> horrible\n",
            ", ----> ,\n",
            "no ----> no\n",
            "entiendo ----> entender\n",
            "por ----> por\n",
            "qué ----> qué\n",
            "xcom2 ----> xcom2\n",
            "ha ----> haber\n",
            "producido ----> producir\n",
            "una ----> uno\n",
            "acción ----> acción\n",
            "muy ----> muy\n",
            "mala ----> malo\n",
            "y ----> y\n",
            "muy ----> muy\n",
            "mala ----> malo\n",
            "cuando ----> cuando\n",
            "jugué ----> jugar\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            ", ----> ,\n",
            "me ----> me\n",
            "río ----> reír\n",
            ", ----> ,\n",
            "fue ----> ser\n",
            "muy ----> muy\n",
            "horrible ----> horrible\n",
            "En ----> En\n",
            "pocas ----> poco\n",
            "palabras ----> palabra\n",
            ", ----> ,\n",
            "ni ----> ni\n",
            "siquiera ----> siquiera\n",
            "sé ----> ser\n",
            "cómo ----> cómo\n",
            "llegó ----> llegar\n",
            "al ----> al\n",
            "mercado ----> mercar\n",
            ". ----> .\n",
            "terrible ----> terrible\n",
            "juego ----> jugar\n",
            ", ----> ,\n",
            "pistolas ----> pistola\n",
            "y ----> y\n",
            "mapas ----> mapa\n",
            "El ----> El\n",
            "lanzamiento ----> lanzamiento\n",
            "de ----> de\n",
            "Out ----> Out\n",
            "of ----> of\n",
            "Ammo ----> Ammo\n",
            "suena ----> sonar\n",
            "interesante ----> interesante\n",
            "en ----> en\n",
            "el ----> el\n",
            "papel ----> papel\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "la ----> lo\n",
            "ejecución ----> ejecución\n",
            "es ----> ser\n",
            "probablemente ----> probablemente\n",
            "el ----> el\n",
            "peor ----> peor\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "PSVR ----> PSVR\n",
            "que ----> que\n",
            "he ----> haber\n",
            "jugado ----> jugar\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "literalmente ----> literalmente\n",
            "terrible ----> terrible\n",
            ". ----> .\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "tiene ----> tener\n",
            "gráficos ----> gráfico\n",
            "muy ----> muy\n",
            "pobres ----> pobre\n",
            "y ----> y\n",
            "se ----> se\n",
            "siente ----> sentir\n",
            "muy ----> muy\n",
            "insensible ----> insensible\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "horrible ----> horrible\n",
            ". ----> .\n",
            "Shooter ----> Shooter\n",
            "en ----> en\n",
            "primera ----> primero\n",
            "persona ----> personar\n",
            "que ----> que\n",
            "corre ----> correr\n",
            "como ----> comer\n",
            "mi ----> mi\n",
            "nan ----> nan\n",
            "Juego ----> Juego\n",
            "muy ----> muy\n",
            "malo ----> malo\n",
            "y ----> y\n",
            "aburrido ----> aburrir\n",
            ". ----> .\n",
            "Casi ----> Casi\n",
            "me ----> me\n",
            "quedo ----> quedar\n",
            "dormido ----> dormir\n",
            "jugando ----> jugar\n",
            "este ----> este\n",
            "maldito ----> maldito\n",
            "juego ----> jugar\n",
            ". ----> .\n",
            "Simplemente ----> Simplemente\n",
            "no ----> no\n",
            "lo ----> el\n",
            "compres ----> comprar\n",
            "Una ----> Una\n",
            "experiencia ----> experiencia\n",
            "mediocre ----> mediocre\n",
            "que ----> que\n",
            "es ----> ser\n",
            "menos ----> menos\n",
            "horror ----> horror\n",
            "psicológico ----> psicológico\n",
            "que ----> que\n",
            "tortura ----> torturar\n",
            ". ----> .\n",
            "Hay ----> Hay\n",
            "mejores ----> mejorar\n",
            "experiencias ----> experiencia\n",
            "de ----> de\n",
            "terror ----> terror\n",
            "por ----> por\n",
            "ahí ----> ahí\n",
            "David ----> David\n",
            "Lynch ----> Lynch\n",
            "no ----> no\n",
            "tiene ----> tener\n",
            "miedo ----> miedo\n",
            "de ----> de\n",
            "hacer ----> hacer\n",
            "arte ----> arte\n",
            "impenetrable ----> impenetrable\n",
            ", ----> ,\n",
            "difícil ----> difícil\n",
            "de ----> de\n",
            "interpretar ----> interpretar\n",
            ". ----> .\n",
            "Eso ----> Eso\n",
            "es ----> ser\n",
            "parte ----> partir\n",
            "de ----> de\n",
            "su ----> su\n",
            "genio ----> genio\n",
            ": ----> :\n",
            "lo ----> el\n",
            "absurdo ----> absurdo\n",
            "del ----> del\n",
            "horror ----> horror\n",
            ", ----> ,\n",
            "la ----> lo\n",
            "belleza ----> belleza\n",
            "natural ----> natural\n",
            "de ----> de\n",
            "lo ----> el\n",
            "misterios ----> misterio\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "degradación ----> degradación\n",
            "de ----> de\n",
            "Doom ----> Doom\n",
            "1 ----> 1\n",
            "en ----> en\n",
            "muchos ----> mucho\n",
            "aspectos ----> aspecto\n",
            ". ----> .\n",
            "¿ ----> ¿\n",
            "Más ----> Más\n",
            "atroz ----> atroz\n",
            "? ----> ?\n",
            "Cuando ----> Cuando\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "se ----> se\n",
            "bloquea ----> bloquear\n",
            ", ----> ,\n",
            "comienza ----> comenzar\n",
            "de ----> de\n",
            "nuevo ----> nuevo\n",
            "al ----> al\n",
            "INICIO ----> INICIO\n",
            "DEL ----> DEL\n",
            "NIVEL ----> NIVEL\n",
            "Super ----> Super\n",
            "Soccer ----> Soccer\n",
            "Blast ----> Blast\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "deportes ----> deporte\n",
            "de ----> de\n",
            "estilo ----> estilar\n",
            "arcade ----> arcade\n",
            ". ----> .\n",
            "No ----> No\n",
            "es ----> ser\n",
            "realista ----> realista\n",
            "Como ----> Como\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "fútbol ----> fútbol\n",
            "que ----> que\n",
            "se ----> se\n",
            "apoya ----> apoyar\n",
            "fuertemente ----> fuertemente\n",
            "en ----> en\n",
            "una ----> uno\n",
            "actitud ----> actitud\n",
            "arcade ----> arcade\n",
            ", ----> ,\n",
            "en ----> en\n",
            "lugar ----> lugar\n",
            "de ----> de\n",
            "una ----> uno\n",
            "simulación ----> simulación\n",
            "directa ----> directo\n",
            "1971 ----> 1971\n",
            "Project ----> Project\n",
            "Heliosis ----> Heliosis\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "estrategia ----> estrategia\n",
            "por ----> por\n",
            "turnos ----> turno\n",
            "que ----> que\n",
            "combina ----> combinar\n",
            "tácticas ----> táctico\n",
            "militares ----> militar\n",
            "de ----> de\n",
            "guerra ----> guerra\n",
            "moderna ----> moderno\n",
            "y ----> y\n",
            "combate ----> combatir\n",
            "cuerpo ----> cuerpo\n",
            "a ----> a\n",
            "cuerpo ----> cuerpo\n",
            ". ----> .\n",
            "Las ----> Las\n",
            "armas ----> armar\n",
            "de ----> de\n",
            "fuego ----> fuego\n",
            "y ----> y\n",
            "los ----> lo\n",
            "vehículos ----> vehículo\n",
            "son ----> ser\n",
            "escasos ----> escaso\n",
            ", ----> ,\n",
            "los ----> lo\n",
            "conflictos ----> conflicto\n",
            "y ----> y\n",
            "las ----> los\n",
            "hostilidades ----> hostilidad\n",
            "no ----> no\n",
            "tienen ----> tener\n",
            "fin ----> fin\n",
            ", ----> ,\n",
            "y ----> y\n",
            "el ----> el\n",
            "terrible ----> terrible\n",
            "frío ----> freír\n",
            "helado ----> helar\n",
            "aniquila ----> aniquilar\n",
            "a ----> a\n",
            "sus ----> su\n",
            "amigos ----> amigo\n",
            "y ----> y\n",
            "enemigos ----> enemigo\n",
            "a ----> a\n",
            "su ----> su\n",
            "paso ----> pasar\n",
            "Juego ----> Juego\n",
            "muy ----> muy\n",
            "malo ----> malo\n",
            "y ----> y\n",
            "aburrido ----> aburrir\n",
            ". ----> .\n",
            "Casi ----> Casi\n",
            "me ----> me\n",
            "quedo ----> quedar\n",
            "dormido ----> dormir\n",
            "jugando ----> jugar\n",
            "este ----> este\n",
            "maldito ----> maldito\n",
            "juego ----> jugar\n",
            ". ----> .\n",
            "Simplemente ----> Simplemente\n",
            "no ----> no\n",
            "lo ----> el\n",
            "compres ----> comprar\n",
            "Ion ----> Ion\n",
            "Fury ----> Fury\n",
            "canaliza ----> canalizar\n",
            "sin ----> sin\n",
            "esfuerzo ----> esforzar\n",
            "el ----> el\n",
            "espíritu ----> espíritu\n",
            "de ----> de\n",
            "los ----> lo\n",
            "tiradores ----> tirador\n",
            "de ----> de\n",
            "la ----> lo\n",
            "vieja ----> viejo\n",
            "escuela ----> escuela\n",
            "como ----> comer\n",
            "Duke ----> Duke\n",
            "Nukem ----> Nukem\n",
            "3D ----> 3D\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "la ----> lo\n",
            "acción ----> acción\n",
            "se ----> se\n",
            "ralentiza ----> ralentizar\n",
            "por ----> por\n",
            "el ----> el\n",
            "retroceso ----> retroceso\n",
            "aburrido ----> aburrir\n",
            "y ----> y\n",
            "los ----> lo\n",
            "acertijos ----> acertijo\n",
            "ambientales ----> ambiental\n",
            "Gráficos ----> Gráficos\n",
            "horribles ----> horrible\n",
            ", ----> ,\n",
            "tiempos ----> tiempo\n",
            "de ----> de\n",
            "carga ----> cargar\n",
            "extremadamente ----> extremadamente\n",
            "largos ----> largo\n",
            "y ----> y\n",
            "frecuentes ----> frecuente\n",
            ", ----> ,\n",
            "juego ----> jugar\n",
            "repetitivo ----> repetitivo\n",
            ", ----> ,\n",
            "actuación ----> actuación\n",
            "de ----> de\n",
            "voz ----> voz\n",
            "de ----> de\n",
            "nivel ----> nivel\n",
            "C ----> C\n",
            "y ----> y\n",
            "una ----> uno\n",
            "historia ----> historia\n",
            "sin ----> sin\n",
            "inspiración ----> inspiración\n",
            "hacen ----> hacer\n",
            "que ----> que\n",
            "sea ----> ser\n",
            "un ----> uno\n",
            "paquete ----> paquete\n",
            "extremadamente ----> extremadamente\n",
            "difícil ----> difícil\n",
            "de ----> de\n",
            "justificar ----> justificar\n",
            "Horrible ----> Horrible\n",
            "sistema ----> sistema\n",
            "de ----> de\n",
            "guardado ----> guardar\n",
            "en ----> en\n",
            "el ----> el\n",
            "que ----> que\n",
            "si ----> si\n",
            "tu ----> tu\n",
            "personaje ----> personaje\n",
            "muere ----> morir\n",
            ", ----> ,\n",
            "te ----> te\n",
            "lleva ----> llevar\n",
            "de ----> de\n",
            "vuelta ----> volver\n",
            "al ----> al\n",
            "juego ----> jugar\n",
            ", ----> ,\n",
            "salvo ----> salvar\n",
            "en ----> en\n",
            "mi ----> mi\n",
            "caso ----> casar\n",
            ", ----> ,\n",
            "estuve ----> estar\n",
            "a ----> a\n",
            "3/4 ----> 3/4\n",
            "de ----> de\n",
            "un ----> uno\n",
            "rompecabezas ----> rompecabezas\n",
            "y ----> y\n",
            "dos ----> do\n",
            "choques ----> choque\n",
            ", ----> ,\n",
            "mi ----> mi\n",
            "personaje ----> personaje\n",
            "muere ----> morir\n",
            "y ----> y\n",
            "la ----> lo\n",
            "salvación ----> salvación\n",
            "me ----> me\n",
            "llevó ----> llevar\n",
            "todo ----> todo\n",
            "el ----> el\n",
            "camino ----> caminar\n",
            "de ----> de\n",
            "regreso ----> regresar\n",
            "para ----> parir\n",
            "guardar ----> guardar\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "y ----> y\n",
            "tuve ----> tener\n",
            "que ----> que\n",
            "comenzar ----> comenzar\n",
            "el ----> el\n",
            "rompecabezas ----> rompecabezas\n",
            "desde ----> desde\n",
            "cero ----> cero\n",
            "nuevamente ----> nuevamente\n",
            "Lo ----> Lo\n",
            "último ----> último\n",
            "para ----> parir\n",
            "terminarlo ----> terminarlo\n",
            "me ----> me\n",
            "pareció ----> parecer\n",
            "frustrantemente ----> frustrantemente\n",
            "incómodo ----> incómodo\n",
            ", ----> ,\n",
            "casi ----> casi\n",
            "imposible ----> imposible\n",
            ". ----> .\n",
            "En ----> En\n",
            "un ----> uno\n",
            "hilo ----> hilar\n",
            "de ----> de\n",
            "Steam ----> Steam\n",
            ", ----> ,\n",
            "los ----> lo\n",
            "desarrolladores ----> desarrollador\n",
            "dijeron ----> decir\n",
            "que ----> que\n",
            "había ----> haber\n",
            "un ----> uno\n",
            "parche ----> parche\n",
            "para ----> parir\n",
            "este ----> este\n",
            "problema ----> problema\n",
            ", ----> ,\n",
            "tal ----> tal\n",
            "vez ----> vez\n",
            "quieras ----> querer\n",
            "intentar ----> intentar\n",
            "parchar ----> parchar\n",
            "la ----> lo\n",
            "versión ----> versión\n",
            "de ----> de\n",
            "PS4 ----> PS4\n",
            "eh ----> eh\n",
            "lads ----> lads\n",
            ". ----> .\n",
            "Arruinar ----> Arruinar\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "perfectamente ----> perfectamente\n",
            "bueno ----> bueno\n",
            "le ----> le\n",
            "habría ----> haber\n",
            "dado ----> dar\n",
            "un ----> uno\n",
            "respetable ----> respetable\n",
            "4 ----> 4\n",
            ", ----> ,\n",
            "menos ----> menos\n",
            "3 ----> 3\n",
            "por ----> por\n",
            "un ----> uno\n",
            "jodky ----> jodky\n",
            "de ----> de\n",
            "mala ----> malo\n",
            "calidad ----> calidad\n",
            "Este ----> Este\n",
            "no ----> no\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "buen ----> bueno\n",
            "juego ----> jugar\n",
            "! ----> !\n",
            "Si ----> Si\n",
            "se ----> se\n",
            "tratara ----> tratar\n",
            "de ----> de\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "f2p ----> f2p\n",
            "con ----> con\n",
            "algunos ----> alguno\n",
            "cosméticos ----> cosmético\n",
            "y ----> y\n",
            "potenciadores ----> potenciador\n",
            "de ----> de\n",
            "XP ----> XP\n",
            ", ----> ,\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "sería ----> ser\n",
            "para ----> parir\n",
            "8 ----> 8\n",
            ", ----> ,\n",
            "incluso ----> incluso\n",
            "9 ----> 9\n",
            ", ----> ,\n",
            "¡ ----> ¡\n",
            "pero ----> pero\n",
            "no ----> no\n",
            "lo ----> el\n",
            "es ----> ser\n",
            "! ----> !\n",
            "Yo ----> Yo\n",
            "pago ----> pagar\n",
            "esta ----> este\n",
            "mierda ----> mierda\n",
            "45 ----> 45\n",
            "euros ----> euro\n",
            "! ----> !\n",
            "¡ ----> ¡\n",
            "Después ----> Después\n",
            "de ----> de\n",
            "cinco ----> cincar\n",
            "rondas ----> rondar\n",
            "de ----> de\n",
            "esto ----> este\n",
            ", ----> ,\n",
            "obtienes ----> obtener\n",
            "todo ----> todo\n",
            "literalmente ----> literalmente\n",
            "todo ----> todo\n",
            "! ----> !\n",
            "juego ----> jugar\n",
            "horrible ----> horrible\n",
            "con ----> con\n",
            "mala ----> malo\n",
            "calidad ----> calidad\n",
            ", ----> ,\n",
            "¡ ----> ¡\n",
            "no ----> no\n",
            "era ----> ser\n",
            "lo ----> el\n",
            "que ----> que\n",
            "esperaba ----> esperar\n",
            "! ----> !\n",
            "¡ ----> ¡\n",
            "No ----> No\n",
            "malgastes ----> malgastar\n",
            "tu ----> tu\n",
            "dinero ----> dinero\n",
            "en ----> en\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "así ----> asir\n",
            "! ----> !\n",
            "Además ----> Además\n",
            "de ----> de\n",
            "horribles ----> horrible\n",
            "emparejamientos ----> emparejamiento\n",
            "y ----> y\n",
            "una ----> uno\n",
            "gran ----> gran\n",
            "cantidad ----> cantidad\n",
            "de ----> de\n",
            "fallas ----> fallo\n",
            "técnicas ----> técnico\n",
            ", ----> ,\n",
            "Predator ----> Predator\n",
            ": ----> :\n",
            "Hunting ----> Hunting\n",
            "Grounds ----> Grounds\n",
            "está ----> estar\n",
            "terriblemente ----> terriblemente\n",
            "desequilibrado ----> desequilibrar\n",
            ", ----> ,\n",
            "se ----> se\n",
            "ve ----> ver\n",
            "francamente ----> francamente\n",
            "feo ----> feo\n",
            ", ----> ,\n",
            "carece ----> carecer\n",
            "de ----> de\n",
            "variedad ----> variedad\n",
            "y ----> y\n",
            "es ----> ser\n",
            "simplemente ----> simplemente\n",
            "desagradable ----> desagradable\n",
            "de ----> de\n",
            "jugar ----> jugar\n",
            "Wow ----> Wow\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "malo ----> malo\n",
            "! ----> !\n",
            "¡ ----> ¡\n",
            "Y ----> Y\n",
            "ya ----> ya\n",
            "están ----> estar\n",
            "llegando ----> llegar\n",
            "las ----> los\n",
            "10 ----> 10\n",
            "falsas ----> falso\n",
            "10 ----> 10\n",
            "reseñas ----> reseñar\n",
            "! ----> !\n",
            "10 ----> 10\n",
            "de ----> de\n",
            "10 ----> 10\n",
            "es ----> ser\n",
            "? ----> ?\n",
            "el ----> el\n",
            "mejor ----> mejor\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "todos ----> todo\n",
            ", ----> ,\n",
            "¿ ----> ¿\n",
            "sí ----> sí\n",
            "? ----> ?\n",
            "ridículo ----> ridículo\n",
            ". ----> .\n",
            "Malos ----> Malos\n",
            "gráficos ----> gráfico\n",
            ", ----> ,\n",
            "espantosos ----> espantoso\n",
            "enemigos ----> enemigo\n",
            "con ----> con\n",
            "esponjas ----> esponjar\n",
            "de ----> de\n",
            "bala ----> balar\n",
            "AI ----> AI\n",
            "y ----> y\n",
            "algunos ----> alguno\n",
            "diseños ----> diseño\n",
            "de ----> de\n",
            "juegos ----> juego\n",
            "realmente ----> realmente\n",
            "malos ----> malo\n",
            "en ----> en\n",
            "general ----> general\n",
            "Dios ----> Dios\n",
            "mío ----> miar\n",
            ", ----> ,\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "desgracia ----> desgraciar\n",
            ", ----> ,\n",
            "no ----> no\n",
            "puedo ----> poder\n",
            "en ----> en\n",
            "serio ----> seriar\n",
            ", ----> ,\n",
            "lo ----> el\n",
            "intento ----> intentar\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "Nop ----> Nop\n",
            ", ----> ,\n",
            "si ----> si\n",
            "quieres ----> querer\n",
            "malgastar ----> malgastar\n",
            "tu ----> tu\n",
            "dinero ----> dinero\n",
            "Ok ----> Ok\n",
            ", ----> ,\n",
            "es ----> ser\n",
            "tu ----> tu\n",
            "propia ----> propio\n",
            "elección ----> elección\n",
            "juego ----> jugar\n",
            "horrible ----> horrible\n",
            "con ----> con\n",
            "mala ----> malo\n",
            "calidad ----> calidad\n",
            ", ----> ,\n",
            "¡ ----> ¡\n",
            "no ----> no\n",
            "era ----> ser\n",
            "lo ----> el\n",
            "que ----> que\n",
            "esperaba ----> esperar\n",
            "! ----> !\n",
            "¡ ----> ¡\n",
            "No ----> No\n",
            "malgastes ----> malgastar\n",
            "tu ----> tu\n",
            "dinero ----> dinero\n",
            "en ----> en\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "así ----> asir\n",
            "Este ----> Este\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "bastante ----> bastante\n",
            "pobre ----> pobre\n",
            ", ----> ,\n",
            "lo ----> el\n",
            "compré ----> comprar\n",
            "porque ----> porque\n",
            "se ----> se\n",
            "ve ----> ver\n",
            "decente ----> decente\n",
            "en ----> en\n",
            "los ----> lo\n",
            "videos ----> videos\n",
            "de ----> de\n",
            "YouTube ----> YouTube\n",
            "( ----> (\n",
            "pero ----> pero\n",
            "eso ----> ese\n",
            "se ----> se\n",
            "veía ----> ver\n",
            "en ----> en\n",
            "una ----> uno\n",
            "pantalla ----> pantalla\n",
            "muy ----> muy\n",
            "pequeña ----> pequeño\n",
            ") ----> )\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "al ----> al\n",
            "jugar ----> jugar\n",
            "en ----> en\n",
            "una ----> uno\n",
            "pantalla ----> pantalla\n",
            "grande ----> grande\n",
            "notarás ----> notar\n",
            "que ----> que\n",
            "los ----> lo\n",
            "gráficos ----> gráfico\n",
            "son ----> ser\n",
            "realmente ----> realmente\n",
            "algo ----> algo\n",
            "de ----> de\n",
            "la ----> lo\n",
            "era ----> ser\n",
            "de ----> de\n",
            "la ----> lo\n",
            "ps3 ----> ps3\n",
            ", ----> ,\n",
            "así ----> asir\n",
            "que ----> que\n",
            "son ----> ser\n",
            "las ----> los\n",
            "mecánicas ----> mecánico\n",
            "de ----> de\n",
            "juego ----> jugar\n",
            "Soy ----> Soy\n",
            "un ----> uno\n",
            "gran ----> gran\n",
            "fanático ----> fanático\n",
            "de ----> de\n",
            "Predator ----> Predator\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "qué ----> qué\n",
            "puedo ----> poder\n",
            "decir ----> decir\n",
            "... ----> ...\n",
            "Predator ----> Predator\n",
            "Hunting ----> Hunting\n",
            "grounds ----> grounds\n",
            "es ----> ser\n",
            "uno ----> unir\n",
            "de ----> de\n",
            "los ----> lo\n",
            "juegos ----> juego\n",
            "más ----> más\n",
            "basura ----> basura\n",
            "que ----> que\n",
            "he ----> haber\n",
            "jugado ----> jugar\n",
            ". ----> .\n",
            "Error ----> Error\n",
            ", ----> ,\n",
            "errores ----> error\n",
            "y ----> y\n",
            "más ----> más\n",
            "errores ----> error\n",
            ". ----> .\n",
            "¿ ----> ¿\n",
            "Por ----> Por\n",
            "qué ----> qué\n",
            "lanzaron ----> lanzar\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "realmente ----> realmente\n",
            "? ----> ?\n",
            "Uno ----> Uno\n",
            "de ----> de\n",
            "los ----> lo\n",
            "peores ----> peor\n",
            ", ----> ,\n",
            "si ----> si\n",
            "no ----> no\n",
            "los ----> lo\n",
            "peores ----> peor\n",
            "juegos ----> juego\n",
            "que ----> que\n",
            "he ----> haber\n",
            "tenido ----> tener\n",
            "la ----> lo\n",
            "desgracia ----> desgraciar\n",
            "de ----> de\n",
            "jugar ----> jugar\n",
            "Este ----> Este\n",
            "juego ----> jugar\n",
            "no ----> no\n",
            "vale ----> valer\n",
            "su ----> su\n",
            "precio ----> preciar\n",
            "actual ----> actual\n",
            ". ----> .\n",
            "Recomendaría ----> Recomendaría\n",
            "comprarlo ----> comprarlo\n",
            "cuando ----> cuando\n",
            "esté ----> estar\n",
            "a ----> a\n",
            "la ----> lo\n",
            "venta ----> venta\n",
            ". ----> .\n",
            "No ----> No\n",
            "valía ----> valer\n",
            "la ----> lo\n",
            "pena ----> penar\n",
            "hacer ----> hacer\n",
            "un ----> uno\n",
            "pedido ----> pedir\n",
            "por ----> por\n",
            "adelantado ----> adelantar\n",
            "y ----> y\n",
            "muestra ----> mostrar\n",
            "que ----> que\n",
            "otro ----> otro\n",
            "estudio ----> estudiar\n",
            "envía ----> enviar\n",
            "un ----> uno\n",
            "mal ----> mal\n",
            "producto ----> producto\n",
            "que ----> que\n",
            "ni ----> ni\n",
            "siquiera ----> siquiera\n",
            "se ----> se\n",
            "siente ----> sentir\n",
            "completo ----> completar\n",
            "Muchos ----> Muchos\n",
            "problemas ----> problema\n",
            ": ----> :\n",
            "colisión ----> colisión\n",
            ", ----> ,\n",
            "equilibrio ----> equilibrio\n",
            ", ----> ,\n",
            "saltos ----> salto\n",
            ", ----> ,\n",
            "retrasos ----> retraso\n",
            ", ----> ,\n",
            "trampas ----> trampa\n",
            "de ----> de\n",
            "colisión ----> colisión\n",
            ", ----> ,\n",
            "emparejamiento ----> emparejamiento\n",
            "infinito ----> infinito\n",
            ". ----> .\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "demasiado ----> demasiar\n",
            "crudo ----> crudo\n",
            "en ----> en\n",
            "el ----> el\n",
            "lanzamiento ----> lanzamiento\n",
            "Probablemente ----> Probablemente\n",
            "sea ----> ser\n",
            "uno ----> unir\n",
            "de ----> de\n",
            "los ----> lo\n",
            "peores ----> peor\n",
            "remasterizadores ----> remasterizadores\n",
            "de ----> de\n",
            "todos ----> todo\n",
            "los ----> lo\n",
            "tiempos ----> tiempo\n",
            ", ----> ,\n",
            "con ----> con\n",
            "una ----> uno\n",
            "tasa ----> tasar\n",
            "de ----> de\n",
            "fotogramas ----> fotograma\n",
            "horrible ----> horrible\n",
            "de ----> de\n",
            "retraso ----> retrasar\n",
            "malo ----> malo\n",
            "y ----> y\n",
            "se ----> se\n",
            "bloquea ----> bloquear\n",
            "a ----> a\n",
            "menudo ----> menudo\n",
            ", ----> ,\n",
            "los ----> lo\n",
            "edificios ----> edificio\n",
            "y ----> y\n",
            "estructuras ----> estructurar\n",
            "que ----> que\n",
            "apenas ----> apenar\n",
            "se ----> se\n",
            "cargan ----> cargar\n",
            "en ----> en\n",
            "Hanger ----> Hanger\n",
            "13 ----> 13\n",
            "no ----> no\n",
            "deberían ----> deber\n",
            "haberse ----> haberse\n",
            "molestado ----> molestar\n",
            "con ----> con\n",
            "un ----> uno\n",
            "remaster ----> remaster\n",
            "porque ----> porque\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "anterior ----> anterior\n",
            "funciona ----> funcionar\n",
            "mucho ----> mucho\n",
            "mejor ----> mejor\n",
            "que ----> que\n",
            "el ----> el\n",
            "remaster ----> remaster\n",
            "Ugh ----> Ugh\n",
            "Las ----> Las\n",
            "imágenes ----> imagen\n",
            "son ----> ser\n",
            "lo ----> el\n",
            "único ----> único\n",
            "que ----> que\n",
            "ofrece ----> ofrecer\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            ". ----> .\n",
            "Los ----> Los\n",
            "escritores ----> escritor\n",
            "de ----> de\n",
            "la ----> lo\n",
            "historia ----> historia\n",
            "deben ----> deber\n",
            "haber ----> haber\n",
            "llamado ----> llamar\n",
            "por ----> por\n",
            "teléfono ----> teléfono\n",
            "en ----> en\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            ", ----> ,\n",
            "o ----> o\n",
            "haber ----> haber\n",
            "sido ----> ser\n",
            "reemplazados ----> reemplazar\n",
            ", ----> ,\n",
            "ya ----> ya\n",
            "que ----> que\n",
            "termina ----> terminar\n",
            "siendo ----> ser\n",
            "una ----> uno\n",
            "secuela ----> secuela\n",
            "menos ----> menos\n",
            "divertida ----> divertir\n",
            "de ----> de\n",
            "un ----> uno\n",
            "gran ----> gran\n",
            "juego ----> jugar\n",
            "y ----> y\n",
            "más ----> más\n",
            "un ----> uno\n",
            "comercial ----> comercial\n",
            "de ----> de\n",
            "10 ----> 10\n",
            "horas ----> hora\n",
            "de ----> de\n",
            "duración ----> duración\n",
            "para ----> parir\n",
            "cualquier ----> cualquiera\n",
            "agenda ----> agenda\n",
            "que ----> que\n",
            "quieran ----> querer\n",
            "impulsar ----> impulsar\n",
            "Este ----> Este\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "pena ----> penar\n",
            ", ----> ,\n",
            "siete ----> siete\n",
            "años ----> año\n",
            "esperando ----> esperar\n",
            "una ----> uno\n",
            "gran ----> gran\n",
            "secuela ----> secuela\n",
            "y ----> y\n",
            "crean ----> creer\n",
            "una ----> uno\n",
            "historia ----> historia\n",
            "ridícula ----> ridículo\n",
            "como ----> comer\n",
            "esa ----> ese\n",
            ", ----> ,\n",
            "la ----> lo\n",
            "prioridad ----> prioridad\n",
            "no ----> no\n",
            "eran ----> ser\n",
            "los ----> lo\n",
            "fanáticos ----> fanático\n",
            "sino ----> sino\n",
            "poner ----> poner\n",
            "todas ----> todo\n",
            "las ----> los\n",
            "agendas ----> agenda\n",
            "posibles ----> posible\n",
            "en ----> en\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            ". ----> .\n",
            "Incluso ----> Incluso\n",
            "un ----> uno\n",
            "niño ----> niño\n",
            "de ----> de\n",
            "cinco ----> cincar\n",
            "años ----> año\n",
            "habría ----> haber\n",
            "hecho ----> hacer\n",
            "una ----> uno\n",
            "mejor ----> mejor\n",
            "historia ----> historia\n",
            "Este ----> Este\n",
            "es ----> ser\n",
            "honestamente ----> honestamente\n",
            "uno ----> unir\n",
            "de ----> de\n",
            "los ----> lo\n",
            "peores ----> peor\n",
            "juegos ----> juego\n",
            "que ----> que\n",
            "he ----> haber\n",
            "jugado ----> jugar\n",
            "No ----> No\n",
            "sé ----> ser\n",
            "qué ----> qué\n",
            "juegan ----> jugar\n",
            "las ----> los\n",
            "personas ----> personar\n",
            "que ----> que\n",
            "califican ----> calificar\n",
            "esto ----> este\n",
            "como ----> comer\n",
            "10 ----> 10\n",
            ", ----> ,\n",
            "aparte ----> apartar\n",
            "de ----> de\n",
            "la ----> lo\n",
            "creación ----> creación\n",
            "del ----> del\n",
            "personaje ----> personaje\n",
            ", ----> ,\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "súper ----> súper\n",
            "promedio ----> promediar\n",
            ". ----> .\n",
            "La ----> La\n",
            "historia ----> historia\n",
            "es ----> ser\n",
            "mediocre ----> mediocre\n",
            ", ----> ,\n",
            "el ----> el\n",
            "combate ----> combatir\n",
            "es ----> ser\n",
            "torpe ----> torpe\n",
            "y ----> y\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "no ----> no\n",
            "tiene ----> tener\n",
            "nada ----> nadar\n",
            "de ----> de\n",
            "especial ----> especial\n",
            ". ----> .\n",
            "Una ----> Una\n",
            "calificación ----> calificación\n",
            "tan ----> tan\n",
            "alta ----> alto\n",
            "solo ----> solo\n",
            "le ----> le\n",
            "dice ----> decir\n",
            "a ----> a\n",
            "Bandai ----> Bandai\n",
            "que ----> que\n",
            "pueden ----> poder\n",
            "seguir ----> seguir\n",
            "haciendo ----> hacer\n",
            "juegos ----> juego\n",
            "mediocres ----> mediocre\n",
            "siempre ----> siempre\n",
            "que ----> que\n",
            "tengan ----> tener\n",
            "una ----> uno\n",
            "buena ----> bueno\n",
            "personalización ----> personalización\n",
            "No ----> No\n",
            "lo ----> el\n",
            "disfruté ----> disfrutar\n",
            ", ----> ,\n",
            "las ----> los\n",
            "peleas ----> pelear\n",
            "no ----> no\n",
            "fueron ----> ser\n",
            "divertidas ----> divertir\n",
            "y ----> y\n",
            "no ----> no\n",
            "me ----> me\n",
            "gustó ----> gustar\n",
            "mucho ----> mucho\n",
            "la ----> lo\n",
            "historia ----> historia\n",
            ". ----> .\n",
            "Sin ----> Sin\n",
            "embargo ----> embargar\n",
            ", ----> ,\n",
            "estoy ----> estar\n",
            "feliz ----> feliz\n",
            "de ----> de\n",
            "que ----> que\n",
            "la ----> lo\n",
            "gente ----> gente\n",
            "lo ----> el\n",
            "haya ----> haber\n",
            "disfrutado ----> disfrutar\n",
            "El ----> El\n",
            "diseño ----> diseñar\n",
            "de ----> de\n",
            "niveles ----> nivelar\n",
            "es ----> ser\n",
            "tan ----> tan\n",
            "malo ----> malo\n",
            ", ----> ,\n",
            "como ----> comer\n",
            "un ----> uno\n",
            "corredor ----> corredor\n",
            "de ----> de\n",
            "laberintos ----> laberinto\n",
            "con ----> con\n",
            "enemigos ----> enemigo\n",
            "en ----> en\n",
            "cada ----> cada\n",
            "esquina ----> esquinar\n",
            ". ----> .\n",
            "Sin ----> Sin\n",
            "peso ----> pesar\n",
            "en ----> en\n",
            "el ----> el\n",
            "impacto ----> impactar\n",
            ". ----> .\n",
            "Estuve ----> Estuve\n",
            "esperando ----> esperar\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "por ----> por\n",
            "más ----> más\n",
            "de ----> de\n",
            "2 ----> 2\n",
            "años ----> año\n",
            ", ----> ,\n",
            "omg ----> omg\n",
            "tal ----> tal\n",
            "decepcionante ----> decepcionante\n",
            ". ----> .\n",
            "Ni ----> Ni\n",
            "siquiera ----> siquiera\n",
            "podía ----> poder\n",
            "esperar ----> esperar\n",
            "el ----> el\n",
            "final ----> final\n",
            ", ----> ,\n",
            "lo ----> el\n",
            "vendí ----> vender\n",
            "y ----> y\n",
            "quiero ----> querer\n",
            "olvidarlo ----> olvidarlo\n",
            "Fue ----> Fue\n",
            "muy ----> muy\n",
            "malo ----> malo\n",
            "El ----> El\n",
            "combate ----> combatir\n",
            "y ----> y\n",
            "los ----> lo\n",
            "gráficos ----> gráfico\n",
            "no ----> no\n",
            "parecen ----> parecer\n",
            "pertenecer ----> pertenecer\n",
            "a ----> a\n",
            "esta ----> este\n",
            "generación ----> generación\n",
            "Este ----> Este\n",
            "juego ----> jugar\n",
            "tiene ----> tener\n",
            "un ----> uno\n",
            "diseño ----> diseñar\n",
            "de ----> de\n",
            "ubicación ----> ubicación\n",
            "deficiente ----> deficiente\n",
            ", ----> ,\n",
            "diseño ----> diseñar\n",
            "de ----> de\n",
            "arma ----> armar\n",
            "pobre ----> pobre\n",
            ", ----> ,\n",
            "falta ----> falto\n",
            "de ----> de\n",
            "equilibrio ----> equilibrio\n",
            "en ----> en\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "en ----> en\n",
            "solitario ----> solitario\n",
            ", ----> ,\n",
            "hay ----> haber\n",
            "muy ----> muy\n",
            "pocos ----> poco\n",
            "velos ----> velo\n",
            "Es ----> Es\n",
            "patético ----> patético\n",
            "que ----> que\n",
            "alguien ----> alguien\n",
            "mencione ----> mencionar\n",
            "el ----> el\n",
            "surge ----> surgir\n",
            "2 ----> 2\n",
            "y ----> y\n",
            "las ----> los\n",
            "almas ----> alma\n",
            "oscuras ----> oscuro\n",
            "en ----> en\n",
            "la ----> lo\n",
            "misma ----> mismo\n",
            "oración ----> oración\n",
            ", ----> ,\n",
            "The ----> The\n",
            "Surge ----> Surge\n",
            "2 ----> 2\n",
            "es ----> ser\n",
            "pura ----> puro\n",
            "basura ----> basura\n",
            ", ----> ,\n",
            "después ----> después\n",
            "del ----> del\n",
            "primer ----> ﻿1\n",
            "juego ----> jugar\n",
            ", ----> ,\n",
            "que ----> que\n",
            "fue ----> ser\n",
            "agradable ----> agradable\n",
            "y ----> y\n",
            "bien ----> bien\n",
            "hecho ----> hacer\n",
            ", ----> ,\n",
            "incluso ----> incluso\n",
            "si ----> si\n",
            "estaba ----> estar\n",
            "sin ----> sin\n",
            "pulir ----> pulir\n",
            "y ----> y\n",
            "un ----> uno\n",
            "poco ----> poco\n",
            "áspero ----> áspero\n",
            "en ----> en\n",
            "algunos ----> alguno\n",
            "lugares ----> lugar\n",
            ", ----> ,\n",
            "fue ----> ser\n",
            "sigue ----> seguir\n",
            "siendo ----> ser\n",
            "una ----> uno\n",
            "buena ----> bueno\n",
            "plataforma ----> plataforma\n",
            "para ----> parir\n",
            "avanzar ----> avanzar\n",
            "Horrible ----> Horrible\n",
            ". ----> .\n",
            "¿ ----> ¿\n",
            "Cómo ----> Cómo\n",
            "logró ----> lograr\n",
            "ser ----> ser\n",
            "PEOR ----> PEOR\n",
            "que ----> que\n",
            "el ----> el\n",
            "primer ----> ﻿1\n",
            "juego ----> jugar\n",
            ", ----> ,\n",
            "que ----> que\n",
            "fue ----> ser\n",
            "malo ----> malo\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "no ----> no\n",
            "tan ----> tan\n",
            "malo ----> malo\n",
            "! ----> !\n",
            "Extremadamente ----> Extremadamente\n",
            "aburrido ----> aburrir\n",
            "y ----> y\n",
            "aburrido ----> aburrir\n",
            ", ----> ,\n",
            "evítalo ----> evítalo\n",
            "a ----> a\n",
            "toda ----> todo\n",
            "costa ----> costa\n",
            "Esperaba ----> Esperaba\n",
            "mas ----> mas\n",
            "de ----> de\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "pero ----> pero\n",
            "la ----> lo\n",
            "verdad ----> verdad\n",
            "no ----> no\n",
            "me ----> me\n",
            "gustó ----> gustar\n",
            "es ----> ser\n",
            "todo ----> todo\n",
            "lo ----> el\n",
            "que ----> que\n",
            "tengo ----> tener\n",
            "que ----> que\n",
            "decir ----> decir\n",
            "La ----> La\n",
            "escritura ----> escriturar\n",
            "es ----> ser\n",
            "terriblemente ----> terriblemente\n",
            "aburrida ----> aburrir\n",
            "... ----> ...\n",
            "Para ----> Para\n",
            "empeorar ----> empeorar\n",
            "las ----> los\n",
            "cosas ----> coser\n",
            ", ----> ,\n",
            "la ----> lo\n",
            "mecánica ----> mecánico\n",
            "de ----> de\n",
            "combate ----> combatir\n",
            "es ----> ser\n",
            "la ----> lo\n",
            "peor ----> peor\n",
            "que ----> que\n",
            "he ----> haber\n",
            "visto ----> vestir\n",
            ". ----> .\n",
            "Estar ----> Estar\n",
            "atrapado ----> atrapar\n",
            "en ----> en\n",
            "un ----> uno\n",
            "espacio ----> espaciar\n",
            "cerrado ----> cerrar\n",
            "con ----> con\n",
            "un ----> uno\n",
            "jefe ----> jefe\n",
            "abrumado ----> abrumar\n",
            "desde ----> desde\n",
            "el ----> el\n",
            "principio ----> principiar\n",
            ", ----> ,\n",
            "y ----> y\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "tiene ----> tener\n",
            "un ----> uno\n",
            "cuello ----> cuello\n",
            "de ----> de\n",
            "botella ----> botella\n",
            "para ----> parir\n",
            "que ----> que\n",
            "no ----> no\n",
            "puedas ----> poder\n",
            "avanzar ----> avanzar\n",
            "más ----> más\n",
            "allá ----> allá\n",
            "del ----> del\n",
            "principio ----> principiar\n",
            "sin ----> sin\n",
            "vencerlo ----> vencerlo\n",
            "Muy ----> Muy\n",
            ", ----> ,\n",
            "muy ----> muy\n",
            "mal ----> mal\n",
            "juego ----> jugar\n",
            "y ----> y\n",
            "fluidez ----> fluidez\n",
            "del ----> del\n",
            "juego ----> jugar\n",
            ". ----> .\n",
            "La ----> La\n",
            "suavidad ----> suavidad\n",
            "del ----> del\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "horrible ----> horrible\n",
            ". ----> .\n",
            "IU ----> IU\n",
            "de ----> de\n",
            "los ----> lo\n",
            "años ----> año\n",
            "90 ----> 90\n",
            "Honestamente ----> Honestamente\n",
            ", ----> ,\n",
            "estoy ----> estar\n",
            "realmente ----> realmente\n",
            "decepcionado ----> decepcionar\n",
            ", ----> ,\n",
            "especialmente ----> especialmente\n",
            "porque ----> porque\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "cuesta ----> costar\n",
            "$ ----> $\n",
            "75 ----> 75\n",
            "en ----> en\n",
            "total ----> total\n",
            ". ----> .\n",
            "Hay ----> Hay\n",
            "un ----> uno\n",
            "dlc ----> dlc\n",
            "de ----> de\n",
            "0 ----> 0\n",
            "días ----> día\n",
            ", ----> ,\n",
            "y ----> y\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "muy ----> muy\n",
            "subóptimo ----> subóptimo\n",
            ". ----> .\n",
            "Parece ----> Parece\n",
            "bastante ----> bastante\n",
            "defectuoso ----> defectuoso\n",
            ", ----> ,\n",
            "y ----> y\n",
            "su ----> su\n",
            "calidad ----> calidad\n",
            "de ----> de\n",
            "gráficos ----> gráfico\n",
            "no ----> no\n",
            "se ----> se\n",
            "parece ----> parecer\n",
            "en ----> en\n",
            "nada ----> nadar\n",
            "al ----> al\n",
            "tráiler ----> tráiler\n",
            ", ----> ,\n",
            "lo ----> el\n",
            "que ----> que\n",
            "me ----> me\n",
            "hace ----> hacer\n",
            "sentir ----> sentir\n",
            "extremadamente ----> extremadamente\n",
            "decepcionado ----> decepcionar\n",
            "Mecánica ----> Mecánica\n",
            "torpe ----> torpe\n",
            "y ----> y\n",
            "una ----> uno\n",
            "historia ----> historia\n",
            "ridículamente ----> ridículamente\n",
            "aburrida ----> aburrir\n",
            ". ----> .\n",
            "Los ----> Los\n",
            "personajes ----> personaje\n",
            "eran ----> ser\n",
            "finos ----> fino\n",
            "como ----> comer\n",
            "el ----> el\n",
            "papel ----> papel\n",
            "y ----> y\n",
            "completamente ----> completamente\n",
            "inmemorables ----> inmemorable\n",
            ", ----> ,\n",
            "incluido ----> incluir\n",
            "el ----> el\n",
            "protagonista ----> protagonista\n",
            "La ----> La\n",
            "historia ----> historia\n",
            "es ----> ser\n",
            "irrelevante ----> irrelevante\n",
            ". ----> .\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "no ----> no\n",
            "es ----> ser\n",
            "divertido ----> divertir\n",
            "en ----> en\n",
            "absoluto ----> absoluto\n",
            ". ----> .\n",
            "Puedes ----> Puedes\n",
            "matar ----> matar\n",
            "el ----> el\n",
            "tiempo ----> tiempo\n",
            "jugando ----> jugar\n",
            "Chaosbane ----> Chaosbane\n",
            "mientras ----> mientras\n",
            "esperas ----> esperar\n",
            "un ----> uno\n",
            "mejor ----> mejor\n",
            "juego ----> jugar\n",
            "La ----> La\n",
            "jugabilidad ----> jugabilidad\n",
            "es ----> ser\n",
            "tan ----> tan\n",
            "repetitiva ----> repetitivo\n",
            "y ----> y\n",
            "lo ----> el\n",
            "ha ----> haber\n",
            "visto ----> vestir\n",
            "todo ----> todo\n",
            "antes ----> antes\n",
            "y ----> y\n",
            ", ----> ,\n",
            "para ----> parir\n",
            "empeorar ----> empeorar\n",
            "las ----> los\n",
            "cosas ----> coser\n",
            ", ----> ,\n",
            "tiene ----> tener\n",
            "problemas ----> problema\n",
            "de ----> de\n",
            "ritmo ----> ritmar\n",
            "de ----> de\n",
            "cuadro ----> cuadrar\n",
            "y ----> y\n",
            "aparece.¡No ----> aparece.¡No\n",
            "vale ----> valer\n",
            "la ----> lo\n",
            "pena ----> penar\n",
            "acercarse ----> acercarse\n",
            "al ----> al\n",
            "precio ----> preciar\n",
            "completo ----> completar\n",
            "! ----> !\n",
            "El ----> El\n",
            "juego ----> jugar\n",
            "arruina ----> arruinar\n",
            "mucho ----> mucho\n",
            "de ----> de\n",
            "lo ----> el\n",
            "que ----> que\n",
            "se ----> se\n",
            "puede ----> poder\n",
            "amar ----> amar\n",
            "de ----> de\n",
            "MK ----> MK\n",
            ". ----> .\n",
            "La ----> La\n",
            "lucha ----> luchar\n",
            "es ----> ser\n",
            "decente ----> decente\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "todo ----> todo\n",
            "lo ----> el\n",
            "demás ----> demás\n",
            ", ----> ,\n",
            "desde ----> desde\n",
            "las ----> los\n",
            "terminaciones ----> terminación\n",
            "de ----> de\n",
            "la ----> lo\n",
            "torre ----> torrar\n",
            "fuera ----> ser\n",
            "de ----> de\n",
            "lugar ----> lugar\n",
            "hasta ----> hasta\n",
            "una ----> uno\n",
            "rutina ----> rutina\n",
            "loca ----> loco\n",
            "para ----> parir\n",
            "siempre ----> siempre\n",
            "en ----> en\n",
            "línea ----> líneo\n",
            ", ----> ,\n",
            "daña ----> dañar\n",
            "la ----> lo\n",
            "experiencia ----> experiencia\n",
            "romesas ----> romesas\n",
            "incumplidas ----> incumplir\n",
            "y ----> y\n",
            "muchas ----> mucho\n",
            "mentiras ----> mentira\n",
            ". ----> .\n",
            "El ----> El\n",
            "peor ----> peor\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "toda ----> todo\n",
            "la ----> lo\n",
            "franquicia ----> franquicia\n",
            "Esto ----> Esto\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "vergüenza ----> vergüenza\n",
            "para ----> parir\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "Mortal ----> Mortal\n",
            "Kombat ----> Kombat\n",
            ", ----> ,\n",
            "siempre ----> siempre\n",
            "un ----> uno\n",
            "infierno ----> infierno\n",
            "de ----> de\n",
            "micro ----> micro\n",
            "transacciones ----> transaccionar\n",
            "en ----> en\n",
            "línea ----> líneo\n",
            "con ----> con\n",
            "una ----> uno\n",
            "actuación ----> actuación\n",
            "de ----> de\n",
            "voz ----> voz\n",
            "terrible ----> terrible\n",
            ", ----> ,\n",
            "los ----> lo\n",
            "diseños ----> diseño\n",
            "de ----> de\n",
            "personajes ----> personaje\n",
            "son ----> ser\n",
            "feos ----> feo\n",
            "de ----> de\n",
            "ver ----> ver\n",
            "y ----> y\n",
            "tiene ----> tener\n",
            "sentido ----> sentir\n",
            "de ----> de\n",
            "justicia ----> justicia\n",
            "social ----> social\n",
            "The ----> The\n",
            "War ----> War\n",
            "Machine ----> Machine\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "vez ----> vez\n",
            "más ----> más\n",
            "otro ----> otro\n",
            "pobre ----> pobre\n",
            "esfuerzo ----> esforzar\n",
            "para ----> parir\n",
            "inyectar ----> inyectar\n",
            "vida ----> vida\n",
            "en ----> en\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "rancio ----> ranciar\n",
            ", ----> ,\n",
            "sin ----> sin\n",
            "inspiración ----> inspiración\n",
            "y ----> y\n",
            "roto ----> rotar\n",
            "El ----> El\n",
            "peor ----> peor\n",
            "juego ----> jugar\n",
            "del ----> del\n",
            "mundo ----> mundo\n",
            "para ----> parir\n",
            "jugarlo ----> jugarlo\n",
            "es ----> ser\n",
            "cómo ----> cómo\n",
            "golpear ----> golpear\n",
            "tu ----> tu\n",
            "cabeza ----> cabeza\n",
            "contra ----> contra\n",
            "una ----> uno\n",
            "pared ----> pared\n",
            ". ----> .\n",
            "No ----> No\n",
            "sé ----> ser\n",
            "a ----> a\n",
            "qué ----> qué\n",
            "nivel ----> nivel\n",
            "debería ----> deber\n",
            "ser ----> ser\n",
            "el ----> el\n",
            "intelecto ----> intelecto\n",
            "Muy ----> Muy\n",
            "flojo ----> flojo\n",
            ". ----> .\n",
            "el ----> el\n",
            "modo ----> modo\n",
            "zombie ----> zombie\n",
            "no ----> no\n",
            "es ----> ser\n",
            "rejugable ----> rejugable\n",
            "aburre ----> aburrir\n",
            "en ----> en\n",
            "cuanto ----> cuanto\n",
            "haces ----> haz\n",
            "el ----> el\n",
            "huevo ----> huevar\n",
            "de ----> de\n",
            "pascua ----> pascua\n",
            "Al ----> Al\n",
            "final ----> final\n",
            ", ----> ,\n",
            "Rise ----> Rise\n",
            "of ----> of\n",
            "Iron ----> Iron\n",
            "es ----> ser\n",
            ", ----> ,\n",
            "literalmente ----> literalmente\n",
            ", ----> ,\n",
            "más ----> más\n",
            "Destino ----> Destino\n",
            ". ----> .\n",
            "No ----> No\n",
            "aborda ----> abordar\n",
            "ninguno ----> ninguno\n",
            "de ----> de\n",
            "los ----> lo\n",
            "problemas ----> problema\n",
            "que ----> que\n",
            "podría ----> poder\n",
            "haber ----> haber\n",
            "tenido ----> tener\n",
            "con ----> con\n",
            "el ----> el\n",
            "original ----> original\n",
            ", ----> ,\n",
            "y ----> y\n",
            "tampoco ----> tampoco\n",
            "elimina ----> eliminar\n",
            "el ----> el\n",
            "mundo ----> mundo\n",
            "existente ----> existente\n",
            "STAY ----> STAY\n",
            "no ----> no\n",
            "puede ----> poder\n",
            "ser ----> ser\n",
            "criticado ----> criticar\n",
            "por ----> por\n",
            "sus ----> su\n",
            "aspiraciones ----> aspiración\n",
            "y ----> y\n",
            "el ----> el\n",
            "intento ----> intentar\n",
            "de ----> de\n",
            "hacer ----> hacer\n",
            "un ----> uno\n",
            "personaje ----> personaje\n",
            "creíble ----> creíble\n",
            "en ----> en\n",
            "Quinn ----> Quinn\n",
            ", ----> ,\n",
            "para ----> parir\n",
            "crear ----> crear\n",
            "un ----> uno\n",
            "individuo ----> individuo\n",
            "que ----> que\n",
            "el ----> el\n",
            "jugador ----> jugador\n",
            "quiera ----> querer\n",
            "ayudar ----> ayudar\n",
            ". ----> .\n",
            "Sin ----> Sin\n",
            "embargo ----> embargar\n",
            ", ----> ,\n",
            "el ----> el\n",
            "resultado ----> resultar\n",
            "es ----> ser\n",
            "una ----> uno\n",
            "corriente ----> corriente\n",
            "casi ----> casi\n",
            "interminable ----> interminable\n",
            "de ----> de\n",
            "diálogo ----> diálogo\n",
            "mediocre ----> mediocre\n",
            "que ----> que\n",
            "hizo ----> hacer\n",
            "increíblemente ----> increíblemente\n",
            "difícil ----> difícil\n",
            "quedarse ----> quedarse\n",
            "hasta ----> hasta\n",
            "el ----> el\n",
            "final ----> final\n",
            "Imagina ----> Imagina\n",
            "el ----> el\n",
            "nuevo ----> nuevo\n",
            "Doom ----> Doom\n",
            "en ----> en\n",
            "VR ----> VR\n",
            "y ----> y\n",
            "completamente ----> completamente\n",
            "imposible ----> imposible\n",
            "de ----> de\n",
            "jugar ----> jugar\n",
            "Si ----> Si\n",
            "bien ----> bien\n",
            "DOOM ----> DOOM\n",
            ": ----> :\n",
            "VFR ----> VFR\n",
            "puede ----> poder\n",
            "ser ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "divertido ----> divertir\n",
            ", ----> ,\n",
            "la ----> lo\n",
            "falta ----> falto\n",
            "de ----> de\n",
            "ultraviolencia ----> ultraviolencia\n",
            "y ----> y\n",
            "el ----> el\n",
            "corto ----> cortar\n",
            "tiempo ----> tiempo\n",
            "de ----> de\n",
            "juego ----> jugar\n",
            "eclipsan ----> eclipsar\n",
            "la ----> lo\n",
            "diversión ----> diversión\n",
            "que ----> que\n",
            "ofrece ----> ofrecer\n",
            "DOOM ----> DOOM\n",
            ": ----> :\n",
            "VFR ----> VFR\n",
            ", ----> ,\n",
            "especialmente ----> especialmente\n",
            "a ----> a\n",
            "su ----> su\n",
            "precio ----> preciar\n",
            "actual ----> actual\n",
            "Inacabado ----> Inacabado\n",
            ", ----> ,\n",
            "rediseños ----> rediseños\n",
            "pobres ----> pobre\n",
            "del ----> del\n",
            "elenco ----> elenco\n",
            "principal ----> principal\n",
            ", ----> ,\n",
            "y ----> y\n",
            "cambió ----> cambiar\n",
            "un ----> uno\n",
            "montón ----> montón\n",
            "de ----> de\n",
            "efectos ----> efecto\n",
            "de ----> de\n",
            "sonido ----> sonido\n",
            "del ----> del\n",
            "arma ----> armar\n",
            "Con ----> Con\n",
            "este ----> este\n",
            "segundo ----> segundar\n",
            "episodio ----> episodio\n",
            ", ----> ,\n",
            "The ----> The\n",
            "Legacy ----> Legacy\n",
            "of ----> of\n",
            "the ----> the\n",
            "First ----> First\n",
            "Blade ----> Blade\n",
            "arma ----> armar\n",
            "todo ----> todo\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "roles ----> rolar\n",
            "que ----> que\n",
            "Ubisoft ----> Ubisoft\n",
            "pasó ----> pasar\n",
            "decenas ----> decena\n",
            "de ----> de\n",
            "horas ----> hora\n",
            "para ----> parir\n",
            "construir ----> construir\n",
            "en ----> en\n",
            "una ----> uno\n",
            "historia ----> historia\n",
            "corta ----> corto\n",
            "y ----> y\n",
            "altamente ----> altamente\n",
            "cuestionable ----> cuestionable\n",
            "de ----> de\n",
            "tres ----> tres\n",
            "horas ----> hora\n",
            ". ----> .\n",
            "Incluso ----> Incluso\n",
            "los ----> lo\n",
            "grandes ----> grande\n",
            "acorazados ----> acorazar\n",
            "y ----> y\n",
            "una ----> uno\n",
            "nueva ----> nuevo\n",
            "arma ----> armar\n",
            "no ----> no\n",
            "salvarán ----> salvar\n",
            "a ----> a\n",
            "Assassin ----> Assassin\n",
            "'s ----> 's\n",
            "Creed ----> Creed\n",
            "Odyssey ----> Odyssey\n",
            "de ----> de\n",
            "este ----> este\n",
            "cliffhanger ----> cliffhanger\n",
            "equivocado ----> equivocar\n",
            "que ----> que\n",
            "podría ----> poder\n",
            "decepcionar ----> decepcionar\n",
            "a ----> a\n",
            "la ----> lo\n",
            "mayoría ----> mayoría\n",
            "de ----> de\n",
            "los ----> lo\n",
            "aventureros ----> aventurero\n",
            "Mutant ----> Mutant\n",
            "Football ----> Football\n",
            "League ----> League\n",
            "es ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "deportivo ----> deportivo\n",
            "arcade ----> arcade\n",
            "barato ----> barato\n",
            "y ----> y\n",
            "mal ----> mal\n",
            "ejecutado ----> ejecutar\n",
            ". ----> .\n",
            "Creo ----> Creo\n",
            "que ----> que\n",
            "los ----> lo\n",
            "desarrolladores ----> desarrollador\n",
            "entraron ----> entrar\n",
            "con ----> con\n",
            "todas ----> todo\n",
            "las ----> los\n",
            "intenciones ----> intención\n",
            "correctas ----> correcto\n",
            ", ----> ,\n",
            "porque ----> porque\n",
            "realmente ----> realmente\n",
            "no ----> no\n",
            "se ----> se\n",
            "están ----> estar\n",
            "haciendo ----> hacer\n",
            "suficientes ----> suficiente\n",
            "juegos ----> juego\n",
            "deportivos ----> deportivo\n",
            "para ----> parir\n",
            "las ----> los\n",
            "personas ----> personar\n",
            "que ----> que\n",
            "no ----> no\n",
            "están ----> estar\n",
            "dispuestas ----> disponer\n",
            "a ----> a\n",
            "poner ----> poner\n",
            "un ----> uno\n",
            "gran ----> gran\n",
            "compromiso ----> compromiso\n",
            "en ----> en\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "para ----> parir\n",
            "poder ----> poder\n",
            "apreciarlo ----> apreciarlo\n",
            "en ----> en\n",
            "cualquier ----> cualquiera\n",
            "nivel ----> nivel\n",
            "Si ----> Si\n",
            "bien ----> bien\n",
            "Fantastic ----> Fantastic\n",
            "Contraption ----> Contraption\n",
            "lo ----> el\n",
            "alienta ----> alentar\n",
            "a ----> a\n",
            "ser ----> ser\n",
            "creativo ----> creativo\n",
            ", ----> ,\n",
            "inmediatamente ----> inmediatamente\n",
            "lo ----> el\n",
            "encajona ----> encajonar\n",
            "al ----> al\n",
            "mismo ----> mismo\n",
            "tiempo ----> tiempo\n",
            "con ----> con\n",
            "un ----> uno\n",
            "número ----> número\n",
            "limitado ----> limitar\n",
            "de ----> de\n",
            "soluciones ----> solucionar\n",
            "e ----> e\n",
            "incluso ----> incluso\n",
            "menos ----> menos\n",
            "herramientas ----> herramienta\n",
            "Gráficamente ----> Gráficamente\n",
            "seguro ----> seguro\n",
            "como ----> comer\n",
            "está ----> estar\n",
            ", ----> ,\n",
            "casi ----> casi\n",
            "todos ----> todo\n",
            "los ----> lo\n",
            "demás ----> demás\n",
            "elementos ----> elemento\n",
            "de ----> de\n",
            "la ----> lo\n",
            "serie ----> seriar\n",
            "de ----> de\n",
            "15 ----> 15\n",
            "años ----> año\n",
            "han ----> haber\n",
            "sido ----> ser\n",
            "recortados ----> recortar\n",
            ", ----> ,\n",
            "manipulados ----> manipular\n",
            "sin ----> sin\n",
            "sentido ----> sentir\n",
            "o ----> o\n",
            "directamente ----> directamente\n",
            "arruinados ----> arruinar\n",
            ". ----> .\n",
            "La ----> La\n",
            "serie ----> seriar\n",
            "no ----> no\n",
            "ha ----> haber\n",
            "sido ----> ser\n",
            "buena ----> bueno\n",
            "desde ----> desde\n",
            "hace ----> hacer\n",
            "mucho ----> mucho\n",
            "tiempo ----> tiempo\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "este ----> este\n",
            "año ----> año\n",
            "es ----> ser\n",
            "la ----> lo\n",
            "primera ----> primero\n",
            "que ----> que\n",
            "ha ----> haber\n",
            "sido ----> ser\n",
            "activamente ----> activamente\n",
            "mala ----> malo\n",
            "Desafortunadamente ----> Desafortunadamente\n",
            ", ----> ,\n",
            "los ----> lo\n",
            "mejores ----> mejorar\n",
            "atributos ----> atributo\n",
            "de ----> de\n",
            "Island ----> Island\n",
            "Time ----> Time\n",
            "VR ----> VR\n",
            ", ----> ,\n",
            "las ----> los\n",
            "imágenes ----> imagen\n",
            "y ----> y\n",
            "la ----> lo\n",
            "actuación ----> actuación\n",
            "de ----> de\n",
            "voz ----> voz\n",
            ", ----> ,\n",
            "se ----> se\n",
            "ven ----> ver\n",
            "eclipsados ----> eclipsar\n",
            "​​por ----> ​​por\n",
            "algunos ----> alguno\n",
            "defectos ----> defecto\n",
            "muy ----> muy\n",
            "importantes ----> importante\n",
            "en ----> en\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "repetitivo ----> repetitivo\n",
            ", ----> ,\n",
            "un ----> uno\n",
            "tiempo ----> tiempo\n",
            "de ----> de\n",
            "ejecución ----> ejecución\n",
            "muy ----> muy\n",
            "corto ----> cortar\n",
            "y ----> y\n",
            "errores ----> error\n",
            "que ----> que\n",
            "rompen ----> romper\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "Si ----> Si\n",
            "no ----> no\n",
            "estás ----> estar\n",
            "discutiendo ----> discutir\n",
            "con ----> con\n",
            "tus ----> tu\n",
            "amigos ----> amigo\n",
            "sobre ----> sobrar\n",
            "si ----> si\n",
            "Naruto ----> Naruto\n",
            "vencería ----> vencer\n",
            "a ----> a\n",
            "Goku ----> Goku\n",
            "y ----> y\n",
            "no ----> no\n",
            "estás ----> estar\n",
            "rezando ----> rezar\n",
            "por ----> por\n",
            "la ----> lo\n",
            "cuarta ----> cuartar\n",
            "temporada ----> temporada\n",
            "de ----> de\n",
            "\" ----> \"\n",
            "Jojo ----> Jojo\n",
            "'s ----> 's\n",
            "Bizarre ----> Bizarre\n",
            "Adventure ----> Adventure\n",
            "\" ----> \"\n",
            ", ----> ,\n",
            "no ----> no\n",
            "hay ----> haber\n",
            "absolutamente ----> absolutamente\n",
            "ninguna ----> ninguno\n",
            "razón ----> razón\n",
            "para ----> parir\n",
            "que ----> que\n",
            "te ----> te\n",
            "preocupes ----> preocupar\n",
            "por ----> por\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "lucha ----> luchar\n",
            "realmente ----> realmente\n",
            "débil ----> débil\n",
            "La ----> La\n",
            "Iglesia ----> Iglesia\n",
            "en ----> en\n",
            "la ----> lo\n",
            "Oscuridad ----> Oscuridad\n",
            "quiere ----> querer\n",
            "ser ----> ser\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "sigilo ----> sigilar\n",
            "que ----> que\n",
            "te ----> te\n",
            "ponga ----> poner\n",
            "en ----> en\n",
            "medio ----> mediar\n",
            "de ----> de\n",
            "un ----> uno\n",
            "culto ----> culto\n",
            "del ----> del\n",
            "fin ----> fin\n",
            "del ----> del\n",
            "mundo ----> mundo\n",
            ". ----> .\n",
            "En ----> En\n",
            "consecuencia ----> consecuencia\n",
            ", ----> ,\n",
            "en ----> en\n",
            "lugar ----> lugar\n",
            "de ----> de\n",
            "darte ----> darte\n",
            "una ----> uno\n",
            "idea ----> ideo\n",
            "del ----> del\n",
            "mundo ----> mundo\n",
            "de ----> de\n",
            "un ----> uno\n",
            "culto ----> culto\n",
            ", ----> ,\n",
            "obtienes ----> obtener\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "aburrido ----> aburrir\n",
            "que ----> que\n",
            "te ----> te\n",
            "hará ----> hacer\n",
            "apreciar ----> apreciar\n",
            "cómo ----> cómo\n",
            "para ----> parir\n",
            "evitar ----> evitar\n",
            "el ----> el\n",
            "campo ----> campar\n",
            "de ----> de\n",
            "visión ----> visión\n",
            "de ----> de\n",
            "alguien ----> alguien\n",
            "El ----> El\n",
            "componente ----> componente\n",
            "interactivo ----> interactivo\n",
            "real ----> real\n",
            "de ----> de\n",
            "The ----> The\n",
            "Grand ----> Grand\n",
            "Tour ----> Tour\n",
            "Game ----> Game\n",
            "es ----> ser\n",
            "realmente ----> realmente\n",
            "bastante ----> bastante\n",
            "pobre ----> pobre\n",
            ", ----> ,\n",
            "con ----> con\n",
            "un ----> uno\n",
            "manejo ----> manejar\n",
            "horrible ----> horrible\n",
            "y ----> y\n",
            "una ----> uno\n",
            "presentación ----> presentación\n",
            "anticuada ----> anticuar\n",
            "que ----> que\n",
            "hace ----> hacer\n",
            "que ----> que\n",
            "las ----> los\n",
            "carreras ----> carrera\n",
            "y ----> y\n",
            "los ----> lo\n",
            "desafíos ----> desafío\n",
            "sean ----> ser\n",
            "muy ----> muy\n",
            "inferiores ----> inferior\n",
            "a ----> a\n",
            "los ----> lo\n",
            "segmentos ----> segmento\n",
            "que ----> que\n",
            "intentan ----> intentar\n",
            "reemplazar ----> reemplazar\n",
            ", ----> ,\n",
            "entre ----> entrar\n",
            "los ----> lo\n",
            "clips ----> clip\n",
            "del ----> del\n",
            "programa ----> programar\n",
            "que ----> que\n",
            "ya ----> ya\n",
            "has ----> haber\n",
            "visto ----> vestir\n",
            "De ----> De\n",
            "alguna ----> alguno\n",
            "manera ----> manera\n",
            ", ----> ,\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "peor ----> peor\n",
            "que ----> que\n",
            "el ----> el\n",
            "primero ----> 1\n",
            ". ----> .\n",
            "El ----> El\n",
            "combate ----> combatir\n",
            "es ----> ser\n",
            "malo ----> malo\n",
            ", ----> ,\n",
            "los ----> lo\n",
            "gráficos ----> gráfico\n",
            "apestan ----> apestar\n",
            ", ----> ,\n",
            "la ----> lo\n",
            "historia ----> historia\n",
            "es ----> ser\n",
            "confusa ----> confuso\n",
            ". ----> .\n",
            "El ----> El\n",
            "balanceo ----> balancear\n",
            "es ----> ser\n",
            "malo ----> malo\n",
            "y ----> y\n",
            "no ----> no\n",
            "es ----> ser\n",
            "práctico ----> práctico\n",
            "en ----> en\n",
            "absoluto ----> absoluto\n",
            ". ----> .\n",
            "Además ----> Además\n",
            ", ----> ,\n",
            "tiene ----> tener\n",
            "errores ----> error\n",
            "como ----> comer\n",
            "el ----> el\n",
            "infierno ----> infierno\n",
            ". ----> .\n",
            "Quizás ----> Quizás\n",
            "el ----> el\n",
            "peor ----> peor\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "Spider ----> Spider\n",
            "- ----> -\n",
            "Man ----> Man\n",
            "Tiene ----> Tiene\n",
            "muchos ----> mucho\n",
            "errores ----> error\n",
            ", ----> ,\n",
            "modo ----> modo\n",
            "historia ----> historia\n",
            "no ----> no\n",
            "completado ----> completar\n",
            "y ----> y\n",
            "bajo ----> bajar\n",
            "nivel ----> nivel\n",
            "de ----> de\n",
            "contenido ----> contener\n",
            ". ----> .\n",
            "No ----> No\n",
            "recomiendo ----> recomer\n",
            "comprarlo ----> comprarlo\n",
            "ahora ----> ahora\n",
            "mismo ----> mismo\n",
            "Aquí ----> Aquí\n",
            "vamos ----> ir\n",
            "de ----> de\n",
            "nuevo ----> nuevo\n",
            ", ----> ,\n",
            "otro ----> otro\n",
            "episodio ----> episodio\n",
            "completamente ----> completamente\n",
            "decepcionante ----> decepcionante\n",
            "de ----> de\n",
            "una ----> uno\n",
            "franquicia ----> franquicia\n",
            "tan ----> tan\n",
            "( ----> (\n",
            "solía ----> soler\n",
            "ser ----> ser\n",
            ") ----> )\n",
            ". ----> .\n",
            "Me ----> Me\n",
            "siento ----> sentir\n",
            "mal ----> mal\n",
            "por ----> por\n",
            "aquellos ----> aquel\n",
            "que ----> que\n",
            "prueban ----> probar\n",
            "esto ----> este\n",
            "antes ----> antes\n",
            "de ----> de\n",
            "probar ----> probar\n",
            "el ----> el\n",
            "primer ----> ﻿1\n",
            "juego ----> jugar\n",
            ", ----> ,\n",
            "si ----> si\n",
            "incluso ----> incluso\n",
            "probarán ----> probar\n",
            "el ----> el\n",
            "primer ----> ﻿1\n",
            "juego ----> jugar\n",
            "después ----> después\n",
            "de ----> de\n",
            "jugar ----> jugar\n",
            "esto ----> este\n",
            "En ----> En\n",
            "retrospectiva ----> retrospectivo\n",
            ", ----> ,\n",
            "no ----> no\n",
            "debería ----> deber\n",
            "haber ----> haber\n",
            "dado ----> dar\n",
            "cero ----> cero\n",
            "al ----> al\n",
            "primer ----> ﻿1\n",
            "episodio ----> episodio\n",
            "porque ----> porque\n",
            "este ----> este\n",
            "episodio ----> episodio\n",
            "es ----> ser\n",
            "incluso ----> incluso\n",
            "peor ----> peor\n",
            "que ----> que\n",
            "el ----> el\n",
            "primero ----> 1\n",
            "El ----> El\n",
            "problema ----> problema\n",
            "con ----> con\n",
            "el ----> el\n",
            "juego ----> jugar\n",
            "es ----> ser\n",
            "que ----> que\n",
            "tiene ----> tener\n",
            "muchos ----> mucho\n",
            "errores ----> error\n",
            "como ----> comer\n",
            ": ----> :\n",
            "estaba ----> estar\n",
            "luchando ----> luchar\n",
            "contra ----> contra\n",
            "un ----> uno\n",
            "jefe ----> jefe\n",
            ", ----> ,\n",
            "y ----> y\n",
            "no ----> no\n",
            "tenían ----> tener\n",
            "corazones ----> corazón\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "no ----> no\n",
            "fueron ----> ser\n",
            "derrotados ----> derrotar\n",
            ", ----> ,\n",
            "me ----> me\n",
            "hizo ----> hacer\n",
            "reiniciar ----> reiniciar\n",
            "todo ----> todo\n",
            "el ----> el\n",
            "nivel ----> nivel\n",
            ", ----> ,\n",
            "otra ----> otro\n",
            "vez ----> vez\n",
            "tuve ----> tener\n",
            "que ----> que\n",
            "destruir ----> destruir\n",
            "algo ----> algo\n",
            "para ----> parir\n",
            "avanzar ----> avanzar\n",
            "a ----> a\n",
            "un ----> uno\n",
            "nivel ----> nivel\n",
            ", ----> ,\n",
            "pero ----> pero\n",
            "no ----> no\n",
            "se ----> se\n",
            "rompería ----> romper\n",
            ", ----> ,\n",
            "tuve ----> tener\n",
            "que ----> que\n",
            "reiniciar ----> reiniciar\n",
            "esa ----> ese\n",
            "parte ----> partir\n",
            "también ----> también\n",
            ". ----> .\n",
            "He ----> He\n",
            "descubierto ----> descubrir\n",
            "que ----> que\n",
            "este ----> este\n",
            "juego ----> jugar\n",
            "tiene ----> tener\n",
            "muchos ----> mucho\n",
            "errores ----> error\n",
            "para ----> parir\n",
            "un ----> uno\n",
            "juego ----> jugar\n",
            "de ----> de\n",
            "DC ----> DC\n",
            "Una ----> Una\n",
            "buena ----> bueno\n",
            "formación ----> formación\n",
            "de ----> de\n",
            "canciones ----> canción\n",
            "pero ----> pero\n",
            "problemas ----> problema\n",
            "serios ----> serio\n",
            ". ----> .\n",
            "No ----> No\n",
            "puedo ----> poder\n",
            "creer ----> creer\n",
            "que ----> que\n",
            "no ----> no\n",
            "hayan ----> haber\n",
            "mejorado ----> mejorar\n",
            "el ----> el\n",
            "soporte ----> soportar\n",
            "de ----> de\n",
            "la ----> lo\n",
            "cámara ----> cámara\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DASIJcH3zNz",
        "colab_type": "text"
      },
      "source": [
        "A continuación se imprimen cuantos ***tokens*** quedan por analizar. Como resultado de la tecnica de ***lematización***, ahora se podra realizar el análisis respecto a las ***5182*** palabras restantes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwOPTtD4Y8t2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "315b2871-6fd9-4d62-cd34-6ebec767dd7e"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt31fkbs4Q4T",
        "colab_type": "text"
      },
      "source": [
        "###***B. Eliminación de tokens irrelevantes***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJmu-pw95MFX",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se procedera a eliminar aquellos ***tokens*** que no sean palabras como tal, es decir, se eliminan signos de puntuación, caracteres raros, entre otros. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-jQ5dwEY_KB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6f45ab6-7cf7-4d71-adf8-e1f3ae25213d"
      },
      "source": [
        "tokens = [w.lower() for w in tokens if w.isalpha()]\n",
        "len(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La_IL7pM5x-y",
        "colab_type": "text"
      },
      "source": [
        "Llegados a este punto, se muestra el grafico de las primeras ***30*** palabras que más se repiten o que poseen mayor frecuencia en el texto. Como se puede observar, aun existen multiples palabras muy irrelevantes, tales como ***de***, ***el***, ***y***, ***con***, ***a***, etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "869cDmNoZPjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "de898f00-7c52-4fae-d646-65b607fa589f"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "freq = nltk.FreqDist(tokens)\n",
        "freq.plot(30, cumulative = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WysOuCGj6pJW",
        "colab_type": "text"
      },
      "source": [
        "El tipo de palabras como las mencionadas anteriormente, las cuales son las más predominantes en el gráfico anterior, se denominan ***stop words***. Se trata de palabras que se usan muy seguido, y son irrelevantes en su totalidad en casi cualquier contexto. Por lo tanto, en el siguiente codigo, dichas palabras proceden a ser eliminadas del conjunto de ***tokens*** manejado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMNZll1MaYJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens2 = tokens[:]\n",
        "for token in tokens:\n",
        "  if nlp.vocab[token].is_stop == True:\n",
        "    tokens2.remove(token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9euL4SPk78xw",
        "colab_type": "text"
      },
      "source": [
        "A cotninuación, se imprime, en primer lugar, la cantidad de ***tokens*** considerando ***stop words***. Luego de ello, se muestra la cantidad de ***tokens*** sin considerar ***stop words***. En ese sentido, es factible argumentar que la eliminación de ***stop words*** ha reducido casi a la mitad la cantidad de ***tokens*** que quedan por analizar. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFJCi6hPbHph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4d5fcb5e-1dcb-4c2c-f86f-5e8f1ec63490"
      },
      "source": [
        "print(len(tokens))\n",
        "print(len(tokens2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4688\n",
            "2368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_aelHMD9GDQ",
        "colab_type": "text"
      },
      "source": [
        "Continuando con el asunto, se muestra el grafico de las primeras ***30*** palabras que más se repiten o que poseen mayor frecuencia en el texto. Como se puede observar, aun existen palabras irrelevantes, tales como ***y***, ***a***, ***jugar***, etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOHwStOJbOdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "a0433c70-40fa-4a72-d5b1-3539322fb15a"
      },
      "source": [
        "freq = nltk.FreqDist(tokens2)\n",
        "freq.plot(30, cumulative = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ILf9da--hGC",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indican las palabras irrelevantes a considerar en un arreglo. Posteriormente, estas palabras son eliminadas del conjunto de ***tokens*** analizados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQY2U-MNbYFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "palabras_irrelavantes = ['y', 'a', 'o', 'de','jugar','juego','divertir','jugador','personaje','experiencia','sentir','acción','nivel','luchar','combatir',\n",
        "                         'the','parir','comer','gráfico','predator','e','doom','original','episodio','ofrecer','historia','unir','mundo','realmente',\n",
        "                         'personar','año','querer','armar','seriar','crear','franquicia','sobrar','simplemente','multijugador','entrar','golf','hora',\n",
        "                         'abrir','comenzar','generación','presentar','jrpg','parecer','secuela','literalmente','diseñar','tomar','elemento','entender',\n",
        "                         'seguir','probablemente','explorar','equipar']\n",
        "tokens = tokens2[:]\n",
        "for token in tokens2:\n",
        "  if token in palabras_irrelavantes:\n",
        "    tokens.remove(token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZHy64WK_H37",
        "colab_type": "text"
      },
      "source": [
        "Renaudando el tema, se muestra el grafico de las primeras ***30*** palabras que más se repiten o que poseen mayor frecuencia en el texto. Como se puede observar, muchas palabras irrelevantes han sido eliminadas y ya no se muestran en las ***30*** más frecuentes. Además, se procede a imprimir el numero de ***tokens*** restantes, luego de aplicadas las eliminaciones y tratamientos anteriores. En este caso, el numero que se imprime es ***1589***. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcipEXc2bnVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "6f6b4b5a-e1b3-42d0-b2d5-9a2e8d8b6cbb"
      },
      "source": [
        "freq = nltk.FreqDist(tokens)\n",
        "freq.plot(30, cumulative = False)\n",
        "print(\"Numero de tokens restantes:\", len(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Numero de tokens restantes: 1589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGK7yJXaAcH5",
        "colab_type": "text"
      },
      "source": [
        "##***5. Aplicación de Bag of Words***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7xirwUXBQbQ",
        "colab_type": "text"
      },
      "source": [
        "El codigo que se muestra a continuación posee como principal funcionalidad imprimir en pantalla los ***150 tokens*** más frecuentes en los textos analizados. Una vez imprimidas las palabras, estas son seleccionadas y agrupadas con el objetivo de crear ***tokens*** agrupadores, y construir un vector de caracteristicas para cada texto, a partir de ello. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7gXZvITf_fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a847648b-abf6-4c1f-9e20-ca385e616865"
      },
      "source": [
        "for t, val in freq.most_common(150):\n",
        "  print(str(t) + '\\t\\t' + str(val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "malo\t\t20\n",
            "mejorar\t\t18\n",
            "horrible\t\t13\n",
            "aburrir\t\t10\n",
            "esperar\t\t9\n",
            "error\t\t8\n",
            "increíble\t\t7\n",
            "cualquiera\t\t6\n",
            "completar\t\t6\n",
            "pobre\t\t6\n",
            "problema\t\t6\n",
            "calidad\t\t5\n",
            "grande\t\t5\n",
            "misterio\t\t5\n",
            "disfrutar\t\t5\n",
            "difícil\t\t5\n",
            "avanzar\t\t5\n",
            "mecánico\t\t5\n",
            "valer\t\t4\n",
            "penar\t\t4\n",
            "rápido\t\t4\n",
            "competitivo\t\t4\n",
            "demasiar\t\t4\n",
            "excelente\t\t4\n",
            "futuro\t\t4\n",
            "simulación\t\t4\n",
            "falto\t\t4\n",
            "comprar\t\t4\n",
            "terror\t\t4\n",
            "cortar\t\t4\n",
            "físico\t\t4\n",
            "correr\t\t4\n",
            "estrategia\t\t4\n",
            "asir\t\t4\n",
            "obtener\t\t4\n",
            "supervivencia\t\t4\n",
            "vestir\t\t4\n",
            "enemigo\t\t4\n",
            "completamente\t\t4\n",
            "terrible\t\t4\n",
            "mediocre\t\t4\n",
            "extremadamente\t\t4\n",
            "deber\t\t4\n",
            "pedir\t\t3\n",
            "vr\t\t3\n",
            "lleno\t\t3\n",
            "llenar\t\t3\n",
            "cargar\t\t3\n",
            "contener\t\t3\n",
            "persona\t\t3\n",
            "escuela\t\t3\n",
            "cambiar\t\t3\n",
            "disparo\t\t3\n",
            "nivelar\t\t3\n",
            "refinar\t\t3\n",
            "doceno\t\t3\n",
            "superar\t\t3\n",
            "fps\t\t3\n",
            "músico\t\t3\n",
            "principiar\t\t3\n",
            "rompecabezas\t\t3\n",
            "coser\t\t3\n",
            "vida\t\t3\n",
            "absoluto\t\t3\n",
            "aspecto\t\t3\n",
            "viejo\t\t3\n",
            "emoción\t\t3\n",
            "lanzamiento\t\t3\n",
            "rol\t\t3\n",
            "cercano\t\t3\n",
            "oscuro\t\t3\n",
            "aventurar\t\t3\n",
            "universo\t\t3\n",
            "guerra\t\t3\n",
            "atmósfera\t\t3\n",
            "real\t\t3\n",
            "impulsar\t\t3\n",
            "fanático\t\t3\n",
            "alto\t\t3\n",
            "volver\t\t3\n",
            "océano\t\t3\n",
            "papel\t\t3\n",
            "basar\t\t3\n",
            "tercero\t\t3\n",
            "stab\t\t3\n",
            "enfrentar\t\t3\n",
            "amigo\t\t3\n",
            "campar\t\t3\n",
            "principal\t\t3\n",
            "creer\t\t3\n",
            "importante\t\t3\n",
            "incluir\t\t3\n",
            "líneo\t\t3\n",
            "john\t\t3\n",
            "imagen\t\t3\n",
            "infierno\t\t3\n",
            "llegar\t\t3\n",
            "pasar\t\t3\n",
            "siquiera\t\t3\n",
            "of\t\t3\n",
            "arcade\t\t3\n",
            "repetitivo\t\t3\n",
            "actuación\t\t3\n",
            "voz\t\t3\n",
            "arruinar\t\t3\n",
            "malgastar\t\t3\n",
            "dinero\t\t3\n",
            "preciar\t\t3\n",
            "decepcionar\t\t3\n",
            "probar\t\t3\n",
            "iron\t\t2\n",
            "man\t\t2\n",
            "psvr\t\t2\n",
            "diversión\t\t2\n",
            "red\t\t2\n",
            "dead\t\t2\n",
            "ii\t\t2\n",
            "montaña\t\t2\n",
            "emocionar\t\t2\n",
            "narración\t\t2\n",
            "recomer\t\t2\n",
            "corazón\t\t2\n",
            "expansión\t\t2\n",
            "abordar\t\t2\n",
            "defecto\t\t2\n",
            "naturaleza\t\t2\n",
            "hitman\t\t2\n",
            "continuar\t\t2\n",
            "desafiar\t\t2\n",
            "jamás\t\t2\n",
            "royal\t\t2\n",
            "bellamente\t\t2\n",
            "rutina\t\t2\n",
            "cantidad\t\t2\n",
            "título\t\t2\n",
            "notable\t\t2\n",
            "selección\t\t2\n",
            "demonio\t\t2\n",
            "fantástico\t\t2\n",
            "sorprendente\t\t2\n",
            "nuevamente\t\t2\n",
            "fallo\t\t2\n",
            "imprescindible\t\t2\n",
            "puyo\t\t2\n",
            "altura\t\t2\n",
            "genial\t\t2\n",
            "palabra\t\t2\n",
            "consola\t\t2\n",
            "contrario\t\t2\n",
            "blazblue\t\t2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ8mqfiOCqAd",
        "colab_type": "text"
      },
      "source": [
        "A continuación, se definen apropiadamente los grupos de ***tokens***, los cuales van a representar columnas o ***caracteristicas*** en el conjunto de datos que se construira posteriormente. ***cambios***, ***gamefeats***, ***costos***, ***extremas***, ***buenas***, ***malas*** serán los nombres de las ***caracteristicas*** del conjunto de datos a construir, el cual servira para representar los textos y sus etiquetas respectivas. Cada uno de los grupos definidos representan un aspecto importante: ***cambios*** representa las palabras que indiquen que se debe cambiar algo, ***gamefeats*** hace referencia a las caracteristicas de un juego, ***costos*** representa palabras relacionadas con dinero, ***extremas*** se refiere a palabras que tratan de exaltar algo, ***buenas*** trata sobre palabras que indiquen cualidades buenas y ***malas*** aborda palabras sobre cualidades malas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLEyuSEd1N6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cambios = ['mejorar','avanzar','completar','cortar','contener','cambiar','superar','impulsar', 'refinar','incluir']\n",
        "gamefeats = ['mecánico','rápido','competitivo','difícil']\n",
        "costos = ['comprar','preciar','dinero']\n",
        "extremas = ['extremadamente','completamente','lleno','llenar','absoluto']\n",
        "buenas = ['increíble', 'grande', 'disfrutar', 'valer', 'excelente', 'emoción', 'alto', 'importante', 'bellamente', 'fantástico', 'sorprendente', \n",
        "          'imprescindible', 'altura', 'genial', 'diversión']\n",
        "malas = ['malo', 'horrible', 'aburrir', 'esperar', 'error', 'pobre', 'problema', 'difícil', 'falto', 'terrible', 'mediocre', 'viejo', 'siquiera',\n",
        "         'repetitivo', 'arruinar', 'malgastar', 'decepcionar', 'defecto', 'fallo']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y4wqRePFTjg",
        "colab_type": "text"
      },
      "source": [
        "Ahora bien, se procedera a la construcción del conjunto de datos planteado. Este conjunto servira para representar los ***150*** textos análizados. Cada texto estará representado por ***7*** columnas. Las primeras ***6*** columnas son las ***caracteristicas***, mientras que la ultima corresponde a la ***clase***. Cada columna ***caracteristica*** hace referencia a un grupo de ***tokens*** definido en el codigo anterior. Esto es así, ya que las columnas solo tendran ***2*** posibles valores ***(0 o 1)***. El valor debe ser ***0*** si el texto no contiene ninguna palabra del arreglo o grupo al que la columna hace referencia y ***1*** en caso contrario. La columna ***clase*** indica si el texto corresponde a una reseña ***positiva*** o ***negativa***. En el siguiente codigo, se definen los valores que tendra cada columna en el conjunto de datos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JJ0a2Z05yUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numi = len(X_cadenas)\n",
        "\n",
        "dcambios = [0 for i in range(numi)]\n",
        "dgamefeats = [0 for i in range(numi)]\n",
        "dcostos = [0 for i in range(numi)]\n",
        "dextremas = [0 for i in range(numi)]\n",
        "dbuenas = [0 for i in range(numi)]\n",
        "dmalas = [0 for i in range(numi)]\n",
        "dclase = [0 for i in range(numi)]\n",
        "\n",
        "for i in range(numi):\n",
        "  doc = nlp(X_cadenas[i])\n",
        "  for token in doc:\n",
        "    if token.lemma_ in cambios:\n",
        "      dcambios[i] = 1\n",
        "    if token.lemma_ in gamefeats:\n",
        "      dgamefeats[i] = 1\n",
        "    if token.lemma_ in costos:\n",
        "      dcostos[i] = 1\n",
        "    if token.lemma_ in extremas:\n",
        "      dextremas[i] = 1\n",
        "    if token.lemma_ in buenas:\n",
        "      dbuenas[i] = 1\n",
        "    if token.lemma_ in malas:\n",
        "      dmalas[i] = 1\n",
        "\n",
        "for i in range(numi):\n",
        "  if Y_cadena[i] == 'Positivo':\n",
        "    dclase[i] = 1\n",
        "  elif Y_cadena[i] == 'Negativo':\n",
        "    dclase[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtGpzVEOGsQk",
        "colab_type": "text"
      },
      "source": [
        "Por ultimo, se procede a la construcción final del conjunto de datos, representando el mismo como un ***Dataframe***. Asimismo, se imprimen los ***5*** primeros registros del conjunto resultante. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8cPGYrM-mQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b4f8903e-0f65-4b3c-cf32-0bc93b4daae2"
      },
      "source": [
        "dict = {'cambios': dcambios, 'gfeats': dgamefeats, 'costos': dcostos,'extremas': dextremas, 'buenas': dbuenas, 'malas': dmalas, 'clase': dclase}\n",
        "df = pd.DataFrame(dict) \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cambios</th>\n",
              "      <th>gfeats</th>\n",
              "      <th>costos</th>\n",
              "      <th>extremas</th>\n",
              "      <th>buenas</th>\n",
              "      <th>malas</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cambios  gfeats  costos  extremas  buenas  malas  clase\n",
              "0        0       0       0         0       0      0      1\n",
              "1        1       0       0         0       0      0      1\n",
              "2        0       0       0         0       1      1      1\n",
              "3        0       0       0         0       0      0      1\n",
              "4        0       0       0         0       0      0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BTeRWUlF3wS",
        "colab_type": "text"
      },
      "source": [
        "##***6. Etiquetado con Aprendizaje no supervisado (K-means)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfwhwkNBMv6_",
        "colab_type": "text"
      },
      "source": [
        "En esta parte, se plantea el uso de ***aprendizaje no supervisado*** para caracterizar el conjunto de datos. Se busca realizar el etiquetado de ***100*** textos. El algoritmo que se utilizará sera ***K-means***. En el siguiente codigo, se aplica la tecnica de mencionada sobre el conjunto de datos. Los datos son separados en caracteristicas y columna objetivo respectivamente. Con ***K-means*** se pueden generar grupos o clusters en los datos, es decir, se pueden separar los datos dados un numero de clusters a generar. En este caso, se indica la generación de ***2*** clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsTHz-IQBwhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "X = df.iloc[25:125,:-1].values #Caracteristicas\n",
        "Y = df.iloc[25:125,-1].values #Columna objetivo\n",
        "\n",
        "km = KMeans(n_clusters=2) #Aplicación de K-means\n",
        "km.fit(X)\n",
        "y_km = km.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlVlQPk2PS_V",
        "colab_type": "text"
      },
      "source": [
        "Ahora bien, en el siguiente codigo, se procede a comparar el etiquetado original de los datos con el etiquetado dado por ***K-means***. El primer arreglo impreso corresponde al etiquetado original, mientras que el ultimo corresponde al etiquetado dado por el algoritmo de ***aprendizaje no supervisado***. Es factible observar que, si bien hay varios valores que no coinciden, los grupos estimados por ***K-means*** se aproximan bastante a los originales. Cabe mencionar que ***1*** indica grupo de reseñas positivas y ***0*** indica grupo de reseñas negativas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBjTNYkKJA3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "fef1c413-212a-4edb-e0e4-c2e669308fae"
      },
      "source": [
        "print(Y)\n",
        "print(y_km)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anHeD-smSDkz",
        "colab_type": "text"
      },
      "source": [
        "Llegados a este punto, se indica la ***exactitud*** obtenida por el etiquetado de ***K-means***. En otras palabras, el valor que se indica a continuación se refiere al porcentaje de coincidencias alcanzadas, por el algoritmo de ***aprendizaje no supervisado***, respecto al total de textos etiquetados. Cabe mencionar que se trata de ***no supervisado***, es decir, no se tuvo referencia alguna sobre el etiquetado original de los datos. No obstante, a pesar de ello, se logro un porcentaje de exactitud relativamente alto. \n",
        "\n",
        "***Conclusión: El etiquetado de textos, en este caso, con K-means logro ser efectivo alcanzando una exactitude de 81%.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij1Ui1ILJ_my",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63ab83da-c19a-42b0-8040-2bf5b6b606bb"
      },
      "source": [
        "coinci = 0\n",
        "for i in Y==y_km:\n",
        "  if i == True:\n",
        "    coinci+=1\n",
        "print(\"Exactitud del etiquetado de K-means:\", coinci/len(y_km))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exactitud del etiquetado de K-means: 0.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugQEipPXTiOC",
        "colab_type": "text"
      },
      "source": [
        "Avanzando en el tema, se procede a mostrar un grafico con la ***clusterización*** dada por ***K-means***. En este caso, se trata de un gráfico de dispersión entre el atributo ***Buenas*** y el atributo ***Malas***. Notese que el gráfico no es del todo llamativo, puesto que las ***caracteristicas*** solo toman valores de ***0*** o ***1***. Sin embargo, la agrupación respecto a los colores es apreciable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siHKl8N5GPjd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "f9e5dfc8-20db-40e1-d781-ec41d89292a8"
      },
      "source": [
        "plt.scatter(X[:,4], X[:,5], c=y_km, s=50, cmap='viridis')\n",
        "plt.xlabel(\"Buenas\")\n",
        "plt.ylabel(\"Malas\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTuQiiXzLHJW",
        "colab_type": "text"
      },
      "source": [
        "#***II. Preprocesamiento de datos***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI8-nNmhWSQ7",
        "colab_type": "text"
      },
      "source": [
        "##***1. Transformación de datos***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3fPtZrNWYfF",
        "colab_type": "text"
      },
      "source": [
        "###***A. Evaluación para normalización o estandarización de datos***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzyWuBd0WfrT",
        "colab_type": "text"
      },
      "source": [
        "####***A.1. Aplicación de normalización***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJaHl7vHWlKy",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se aplica **normalización** sobre todos los datos del conjunto, excepto aquellos que correspondan a la columna clase. ***Esta parte del codigo no es del todo generica***, esto sucede, ya que se debe indicar el indice de la columna objetivo o clase. Luego de aplicar la tecnica, se imprime una descripción del conjunto de datos. ***Esta descripción muestra que todos los atributos poseen un rango de [0, 1]***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iriCDKENaCdz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "085d0f27-91af-4b34-a67b-44e0d63741c7"
      },
      "source": [
        "#Normalización de datos del dataset\n",
        "ind_clase = 6 #Se debe indicar el indice de la columna clase o objetivo\n",
        "names = df.columns.values #Guardando el nombre de las columnas del dataset en un arreglo\n",
        "dfn = df.copy()\n",
        "for i in range(len(names)):\n",
        "  if i != ind_clase:\n",
        "    dfn[names[i]] = (df[names[i]] - df[names[i]].min())/ (df[names[i]].max()-df[names[i]].min())\n",
        "dfn.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cambios</th>\n",
              "      <th>gfeats</th>\n",
              "      <th>costos</th>\n",
              "      <th>extremas</th>\n",
              "      <th>buenas</th>\n",
              "      <th>malas</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>152.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>152.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.111842</td>\n",
              "      <td>0.065789</td>\n",
              "      <td>0.092105</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>0.427632</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.441803</td>\n",
              "      <td>0.316214</td>\n",
              "      <td>0.248733</td>\n",
              "      <td>0.290130</td>\n",
              "      <td>0.409030</td>\n",
              "      <td>0.496371</td>\n",
              "      <td>0.501653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          cambios      gfeats      costos  ...      buenas       malas       clase\n",
              "count  152.000000  152.000000  152.000000  ...  152.000000  152.000000  152.000000\n",
              "mean     0.263158    0.111842    0.065789  ...    0.210526    0.427632    0.500000\n",
              "std      0.441803    0.316214    0.248733  ...    0.409030    0.496371    0.501653\n",
              "min      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "25%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "50%      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.500000\n",
              "75%      1.000000    0.000000    0.000000  ...    0.000000    1.000000    1.000000\n",
              "max      1.000000    1.000000    1.000000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULKyRomjXOIV",
        "colab_type": "text"
      },
      "source": [
        "####***A.2. Aplicación de estandarización***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7HKLurEXW34",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se aplica **estandarización** sobre todos los datos del conjunto, excepto aquellos que correspondan a la columna clase o objetivo. ***Esta parte del codigo no es del todo generica***, esto sucede, ya que se debe indicar el indice de la columna objetivo o clase. Luego de aplicar la tecnica, se imprime una descripción del conjunto de datos. ***Esta descripción muestra que todos los atributos, excepto el atributo clase o objetivo, poseen una media de aproximadamente 0.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkmtHtZKXWEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "b28347ab-0e39-4ce2-e2fe-bef63e2a671d"
      },
      "source": [
        "#Estandarización de datos del dataset\n",
        "ind_clase = 6 #Se debe indicar el indice de la columna clase o objetivo\n",
        "names = df.columns.values #Guardando el nombre de las columnas del dataset en un arreglo\n",
        "dfe = df.copy()\n",
        "for i in range(len(names)):\n",
        "  if i != ind_clase:\n",
        "    dfe[names[i]] = (df[names[i]] - df[names[i]].mean())/ df[names[i]].std()\n",
        "dfe.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cambios</th>\n",
              "      <th>gfeats</th>\n",
              "      <th>costos</th>\n",
              "      <th>extremas</th>\n",
              "      <th>buenas</th>\n",
              "      <th>malas</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.520000e+02</td>\n",
              "      <td>1.520000e+02</td>\n",
              "      <td>1.520000e+02</td>\n",
              "      <td>1.520000e+02</td>\n",
              "      <td>1.520000e+02</td>\n",
              "      <td>1.520000e+02</td>\n",
              "      <td>152.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.606902e-16</td>\n",
              "      <td>2.045148e-17</td>\n",
              "      <td>3.213803e-17</td>\n",
              "      <td>2.994681e-17</td>\n",
              "      <td>-1.314738e-17</td>\n",
              "      <td>-1.168656e-17</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.501653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-5.956452e-01</td>\n",
              "      <td>-3.536912e-01</td>\n",
              "      <td>-2.644981e-01</td>\n",
              "      <td>-3.174616e-01</td>\n",
              "      <td>-5.146963e-01</td>\n",
              "      <td>-8.615168e-01</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-5.956452e-01</td>\n",
              "      <td>-3.536912e-01</td>\n",
              "      <td>-2.644981e-01</td>\n",
              "      <td>-3.174616e-01</td>\n",
              "      <td>-5.146963e-01</td>\n",
              "      <td>-8.615168e-01</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-5.956452e-01</td>\n",
              "      <td>-3.536912e-01</td>\n",
              "      <td>-2.644981e-01</td>\n",
              "      <td>-3.174616e-01</td>\n",
              "      <td>-5.146963e-01</td>\n",
              "      <td>-8.615168e-01</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.667807e+00</td>\n",
              "      <td>-3.536912e-01</td>\n",
              "      <td>-2.644981e-01</td>\n",
              "      <td>-3.174616e-01</td>\n",
              "      <td>-5.146963e-01</td>\n",
              "      <td>1.153107e+00</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.667807e+00</td>\n",
              "      <td>2.808724e+00</td>\n",
              "      <td>3.755873e+00</td>\n",
              "      <td>3.129264e+00</td>\n",
              "      <td>1.930111e+00</td>\n",
              "      <td>1.153107e+00</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            cambios        gfeats  ...         malas       clase\n",
              "count  1.520000e+02  1.520000e+02  ...  1.520000e+02  152.000000\n",
              "mean   1.606902e-16  2.045148e-17  ... -1.168656e-17    0.500000\n",
              "std    1.000000e+00  1.000000e+00  ...  1.000000e+00    0.501653\n",
              "min   -5.956452e-01 -3.536912e-01  ... -8.615168e-01    0.000000\n",
              "25%   -5.956452e-01 -3.536912e-01  ... -8.615168e-01    0.000000\n",
              "50%   -5.956452e-01 -3.536912e-01  ... -8.615168e-01    0.500000\n",
              "75%    1.667807e+00 -3.536912e-01  ...  1.153107e+00    1.000000\n",
              "max    1.667807e+00  2.808724e+00  ...  1.153107e+00    1.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klUiqe9hXr2p",
        "colab_type": "text"
      },
      "source": [
        "####***A.3. Comparación y conclusión sobre la mejor técnica***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z54pqWTqXxeg",
        "colab_type": "text"
      },
      "source": [
        "Se debe determinar cual es la mejor tecnica para este caso, ***normalización o estandarización***. Para ello, se utilizara la función ***prove***. Dicha función imprime la exactitud  promedio de 3 clasificadores ***(KNN, Arbol de decisión y SVM)***, realizando un muestreo de ***cross validation estratificado con k folds***, sobre los datos dados. La función se define a continuación. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nbi_bPWXcsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from numpy import *\n",
        "\n",
        "def prove(df, nfols): #Función que desarrolla la prueba con clasificadores\n",
        "  X = df.iloc[:,:-1].values #Caracteristicas\n",
        "  Y = df.iloc[:,-1].values #Columna objetivo\n",
        "  skf = StratifiedKFold(n_splits=nfols)\n",
        "  knn = KNN(n_neighbors=5)\n",
        "  dtree = DecisionTreeClassifier()\n",
        "  svm = SVC()\n",
        "  models = [knn, dtree, svm]\n",
        "  scores = [0,0,0]\n",
        "  for train_index, test_index in skf.split(X, Y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "    for i in range(len(models)):\n",
        "      models[i].fit(X_train, Y_train)\n",
        "      predicciones = models[i].predict(X_test)\n",
        "      scores[i] += accuracy_score(Y_test, predicciones)\n",
        "  print(\"Puntuación total promedio: \", mean(scores)/nfols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEWJR9PeYEhT",
        "colab_type": "text"
      },
      "source": [
        "Ahora bien, se probaran los conjuntos de datos resultantes, despues de aplicadas las tecnicas de ***normalización o estandarización***. Para dicha prueba, se utilizara la función ***prove***, la cual se aplica sobre el conjunto de datos. Esto ultimo, nos permitira determinar con que tecnica se obtiene el conjunto de datos más apto para el proceso de clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe3BxS6FYRZN",
        "colab_type": "text"
      },
      "source": [
        "A continuación, se prueba el conjunto de datos obtenido, despues de aplicada la tecnica de ***normalización***, con un muestreo de ***cross validation estratificado con k folds***, sobre los datos dados. En este caso ***k=50***. Luego de ello, se imprime la exactitud  total promedio obtenida. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOHmY7DXXj51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2b13730c-8a2c-4c1a-8597-81776a7471b0"
      },
      "source": [
        "prove(dfn, 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Puntuación total promedio:  0.7722222222222223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzWRFqqKYdqR",
        "colab_type": "text"
      },
      "source": [
        "A continuación, se prueba el conjunto de datos obtenido, despues de aplicada la tecnica de ***estandarización***, con un muestreo de ***cross validation estratificado con k folds***, sobre los datos dados. En este caso ***k=50***. Luego de ello, se imprime la exactitud  total promedio obtenida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRFc7_LkXnhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "745c6a4a-37de-43c2-95ca-32883610f2e5"
      },
      "source": [
        "prove(dfe, 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Puntuación total promedio:  0.7700000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5jZcqhBYpBJ",
        "colab_type": "text"
      },
      "source": [
        "Con ***normalización***, se obtuvo un ***77.22%*** de exactitud  aproximadamente. Con ***estandarización***, se obtuvo un ***76.78%*** de exactitud aproximadamente. En ese sentido, es más conveniente trabajar con los datos ***normalizados***. A continuación, se asigna que el conjunto de datos a usar tendra los datos ***normalizados***.\n",
        "\n",
        "***Conclusión: La normalización de los datos, en este caso, permite obtener predicciones más exactas.*** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34YHcITZXrpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = dfn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLky2cm2X6hl",
        "colab_type": "text"
      },
      "source": [
        "##***2. Feature Selection***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo2ShAomZdcX",
        "colab_type": "text"
      },
      "source": [
        "A continuación, se aplicara una serie de tecnicas de selección de caracteristicas y/o reducción de dimensionalidad sobre el conjunto de datos. Luego de la aplicación de cada técnica, se imprime el conjunto de datos resultante con las ***caracteristicas seleccionadas y el atributo objetivo***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V69IiKNmZkQV",
        "colab_type": "text"
      },
      "source": [
        "###***A. Aplicación de Análisis de componentes principales (PCA)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD2UESw6ZprN",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se esta implementando la aplicación de el ***Análisis de componentes principales (PCA)***. La técnica de ***PCA*** aplicada no solo reduce la dimensionalidad de los datos, sino que busca el numero de ***componentes principales optimo***, con los que se maximice el performance de los clasificadores. ***Esta parte del codigo no es del todo generica, ya que se debe indicar el indice de la columna clase o objetivo***. La columna clase o objetivo debe ser especificada con el objetivo de que no entre en el proceso de ***reducción de dimensionalidad***. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1g5OLJyX9fd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1e8ff13c-4315-4d92-fd84-347fee822f82"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "def dtree_score(X, Y): #Arbol de decisión y cross-validation con k=10\n",
        "  dtree = DecisionTreeClassifier()\n",
        "  return cross_val_score(dtree, X, Y, cv=10).mean()\n",
        "\n",
        "def pca(df, clase): #Implementación de la técnica de pca\n",
        "  names = df.columns.values\n",
        "  y = df[names[clase]].values\n",
        "  x = df.drop(names[clase], 1).values\n",
        "  score = 0\n",
        "  optimo_n = 2\n",
        "  for n in range(len(names)-2, 1, -1): #Buscando el valor optimo para el numero de componentes principales de PCA\n",
        "    pca = PCA(n_components=n)\n",
        "    new_score = dtree_score(pca.fit_transform(x), y)\n",
        "    if (score <= new_score):\n",
        "      score = new_score\n",
        "      optimo_n = n\n",
        "  pca = PCA(n_components=optimo_n)\n",
        "  df_x = pd.DataFrame(pca.fit_transform(x))\n",
        "  df_y = df[names[clase]]\n",
        "  df = pd.concat([df_x,df_y],axis=1)\n",
        "  return df\n",
        "\n",
        "ind_clase = 6 #Se debe indicar el indice de la columna clase o objetivo\n",
        "pcadf = pca(df, ind_clase)\n",
        "pcadf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.308799</td>\n",
              "      <td>-0.448716</td>\n",
              "      <td>0.052600</td>\n",
              "      <td>-0.115884</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.645075</td>\n",
              "      <td>0.275791</td>\n",
              "      <td>-0.492755</td>\n",
              "      <td>0.102658</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.578009</td>\n",
              "      <td>0.445562</td>\n",
              "      <td>0.548866</td>\n",
              "      <td>-0.375948</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.308799</td>\n",
              "      <td>-0.448716</td>\n",
              "      <td>0.052600</td>\n",
              "      <td>-0.115884</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.308799</td>\n",
              "      <td>-0.448716</td>\n",
              "      <td>0.052600</td>\n",
              "      <td>-0.115884</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  clase\n",
              "0 -0.308799 -0.448716  0.052600 -0.115884      1\n",
              "1 -0.645075  0.275791 -0.492755  0.102658      1\n",
              "2  0.578009  0.445562  0.548866 -0.375948      1\n",
              "3 -0.308799 -0.448716  0.052600 -0.115884      1\n",
              "4 -0.308799 -0.448716  0.052600 -0.115884      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t46HeiGyZ3pJ",
        "colab_type": "text"
      },
      "source": [
        "###***B. Aplicación de Método de filtrado con correlación de Pearson***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2hk7ArgZ9zM",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se esta implementando una técnica de ***Filtering***. Dicha tecnica corresponde a la aplicación de el ***Método de filtrado con correlación de Pearson***. ***Esta parte del codigo no es del todo generica, ya que se debe indicar el indice de la columna clase o objetivo***. La columna clase o objetivo debe ser especificada con el objetivo de que no entre en el proceso de ***selección de caracteristicas***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_hvq7pWYGJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d528a3ab-9ed8-4321-8eec-2fcdc587bbab"
      },
      "source": [
        "def filterpearson(df, clase): #Implementación de la técnica\n",
        "  names = df.columns.values\n",
        "  cor = df.corr()\n",
        "  cor_target = abs(cor[names[clase]])\n",
        "  peacols = []\n",
        "  for i in range(len(names)):\n",
        "    if (names[i] != names[clase] and cor_target[i] >= 0.22):\n",
        "      peacols += [names[i]]\n",
        "  df_x = df[peacols]\n",
        "  df_y = df[names[clase]]\n",
        "  df = pd.concat([df_x,df_y],axis=1)\n",
        "  return df\n",
        "\n",
        "ind_clase = 6 #Se debe indicar el indice de la columna clase o objetivo\n",
        "dffp = filterpearson(df, ind_clase)\n",
        "dffp.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>buenas</th>\n",
              "      <th>malas</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   buenas  malas  clase\n",
              "0     0.0    0.0      1\n",
              "1     0.0    0.0      1\n",
              "2     1.0    1.0      1\n",
              "3     0.0    0.0      1\n",
              "4     0.0    0.0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdmmXMTwaPQF",
        "colab_type": "text"
      },
      "source": [
        "###***C. Aplicación de Método Wrapper: Eliminación hacia atrás***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVNBqbJHaUik",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se esta implementando una técnica de ***Wrapper***. Dicha tecnica corresponde a la aplicación de el ***Método Wrapper: Eliminación hacia atrás***. ***Esta parte del codigo no es del todo generica, ya que se debe indicar el indice de la columna clase o objetivo***. La columna clase o objetivo debe ser especificada con el objetivo de que no entre en el proceso de ***selección de caracteristicas***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3IsNtztYVGQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eda635db-e759-4f79-a29d-3d3f551c5c70"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "#Eliminación hacia atras\n",
        "def backwrapper(df, clase):\n",
        "  X = df.drop(names[clase], 1) \n",
        "  Y = df[names[clase]]\n",
        "  cols = list(X.columns)\n",
        "  pmax = 1\n",
        "  while (len(cols)>0):\n",
        "    p= []\n",
        "    X_1 = X[cols]\n",
        "    X_1 = sm.add_constant(X_1)\n",
        "    model = sm.OLS(Y,X_1).fit()\n",
        "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
        "    pmax = max(p)\n",
        "    feature_with_p_max = p.idxmax()\n",
        "    if(pmax>0.05): cols.remove(feature_with_p_max)\n",
        "    else: break\n",
        "  becols = cols\n",
        "  df_x = df[becols]\n",
        "  df_y = df[names[clase]]\n",
        "  df = pd.concat([df_x,df_y],axis=1)\n",
        "  return df\n",
        "\n",
        "ind_clase = 6 #Se debe indicar el indice de la columna clase o objetivo\n",
        "dfbe = backwrapper(df, ind_clase)\n",
        "dfbe.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gfeats</th>\n",
              "      <th>buenas</th>\n",
              "      <th>malas</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gfeats  buenas  malas  clase\n",
              "0     0.0     0.0    0.0      1\n",
              "1     0.0     0.0    0.0      1\n",
              "2     0.0     1.0    1.0      1\n",
              "3     0.0     0.0    0.0      1\n",
              "4     0.0     0.0    0.0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Vhn82TahmJ",
        "colab_type": "text"
      },
      "source": [
        "###***D. Aplicación de Método Wrapper: Eliminación de Característica Recursiva***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgvQ-fzAatgP",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se esta implementando una técnica de ***Wrapper***. Dicha tecnica corresponde a la aplicación de el ***Método Wrapper: Eliminación de Característica Recursiva***. ***Esta parte del codigo no es del todo generica, ya que se debe indicar el indice de la columna clase o objetivo***. La columna clase o objetivo debe ser especificada con el objetivo de que no entre en el proceso de ***reducción de dimensionalidad***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe840GpLYaSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "73725fff-370e-4633-8aab-ea11a1910770"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "def recursivewrapper(df, clase): #Implementación de la técnica\n",
        "  names = df.columns.values\n",
        "  X = df.drop(names[clase], 1) \n",
        "  Y = df[names[clase]]\n",
        "  high_score=0\n",
        "  nof=0\n",
        "  for i in range(len(X.columns)):\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3, random_state = 0)\n",
        "    model = LinearRegression()\n",
        "    rfe = RFE(model,i+1)\n",
        "    X_train_rfe = rfe.fit_transform(X_train,Y_train)\n",
        "    X_test_rfe = rfe.transform(X_test)\n",
        "    model.fit(X_train_rfe,Y_train)\n",
        "    score = model.score(X_test_rfe,Y_test)\n",
        "    if(score>high_score):\n",
        "      high_score = score\n",
        "      nof = i+1\n",
        "  model = LinearRegression()\n",
        "  rfe = RFE(model, nof)\n",
        "  X_rfe = rfe.fit_transform(X,Y)\n",
        "  model.fit(X_rfe,Y)\n",
        "  temp = pd.Series(rfe.support_,index = X.columns)\n",
        "  rfecols = temp[temp==True].index\n",
        "  df_x = df[rfecols]\n",
        "  df_y = df[names[clase]]\n",
        "  df = pd.concat([df_x,df_y],axis=1)\n",
        "  return df\n",
        "\n",
        "ind_clase = 6 #Se debe indicar el indice de la columna clase o objetivo\n",
        "wradf = recursivewrapper(df, ind_clase)\n",
        "wradf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cambios</th>\n",
              "      <th>gfeats</th>\n",
              "      <th>costos</th>\n",
              "      <th>extremas</th>\n",
              "      <th>buenas</th>\n",
              "      <th>malas</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cambios  gfeats  costos  extremas  buenas  malas  clase\n",
              "0      0.0     0.0     0.0       0.0     0.0    0.0      1\n",
              "1      1.0     0.0     0.0       0.0     0.0    0.0      1\n",
              "2      0.0     0.0     0.0       0.0     1.0    1.0      1\n",
              "3      0.0     0.0     0.0       0.0     0.0    0.0      1\n",
              "4      0.0     0.0     0.0       0.0     0.0    0.0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZYFolQha2_F",
        "colab_type": "text"
      },
      "source": [
        "###***E. Aplicación de Método embebido***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKnl3G_VbBBa",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se esta implementando una técnica de ***Embedded***. Dicha tecnica corresponde a la aplicación de el ***Método de embebido***. ***Esta parte del codigo no es del todo generica, ya que se debe indicar el indice de la columna clase o objetivo***. La columna clase o objetivo debe ser especificada con el objetivo de que no entre en el proceso de ***reducción de dimensionalidad***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-TS41yWYgRl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "874ddf2d-5101-4664-b98a-d834de256a84"
      },
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "def embebido(df, clase): #Implementación de la técnica\n",
        "  names = df.columns.values\n",
        "  X = df.drop(names[clase], 1) \n",
        "  Y = df[names[clase]]\n",
        "  reg = LassoCV()\n",
        "  reg.fit(X, Y)\n",
        "  coef = pd.Series(reg.coef_, index = X.columns)\n",
        "  embbcols = coef[abs(coef) > 0].index\n",
        "  df_x = df[embbcols]\n",
        "  df_y = df[names[clase]]\n",
        "  df = pd.concat([df_x,df_y],axis=1)\n",
        "  return df\n",
        "\n",
        "ind_clase = 6 #Se debe indicar el indice de la columna clase o objetivo\n",
        "emdf = embebido(df, ind_clase)\n",
        "emdf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cambios</th>\n",
              "      <th>gfeats</th>\n",
              "      <th>costos</th>\n",
              "      <th>extremas</th>\n",
              "      <th>buenas</th>\n",
              "      <th>malas</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cambios  gfeats  costos  extremas  buenas  malas  clase\n",
              "0      0.0     0.0     0.0       0.0     0.0    0.0      1\n",
              "1      1.0     0.0     0.0       0.0     0.0    0.0      1\n",
              "2      0.0     0.0     0.0       0.0     1.0    1.0      1\n",
              "3      0.0     0.0     0.0       0.0     0.0    0.0      1\n",
              "4      0.0     0.0     0.0       0.0     0.0    0.0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLqYLYSabFU0",
        "colab_type": "text"
      },
      "source": [
        "###***F. Aplicación de Árboles extremadamente aleatorizados (Extra Tree Classifier) para selección de caracteristicas***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI-sUUU2bPaO",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se esta implementando una técnica que corresponde a la aplicación de ***Árboles extremadamente aleatorizados (Extra Tree Classifier) para selección de caracteristicas***. ***Esta parte del codigo no es del todo generica, ya que se debe indicar el indice de la columna clase o objetivo***. La columna clase o objetivo debe ser especificada con el objetivo de que no entre en el proceso de ***selección de caracteristicas***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBFv8sgyYlM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "559d2fe7-7c82-4c68-de4d-0913123edb66"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "def xtreec(df, clase):\n",
        "  names = df.columns.values\n",
        "  X = df.drop(names[clase], 1) \n",
        "  Y = df[names[clase]]\n",
        "  model = ExtraTreesClassifier()\n",
        "  model.fit(X,Y)\n",
        "  feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "  ficols = feat_importances[feat_importances > 0.068].index\n",
        "  df_x = df[ficols]\n",
        "  df_y = df[names[clase]]\n",
        "  df = pd.concat([df_x,df_y],axis=1)\n",
        "  return df\n",
        "\n",
        "ind_clase = 6 #Se debe indicar el indice de la columna clase o objetivo\n",
        "xtdf = xtreec(df, ind_clase)\n",
        "xtdf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cambios</th>\n",
              "      <th>costos</th>\n",
              "      <th>buenas</th>\n",
              "      <th>malas</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cambios  costos  buenas  malas  clase\n",
              "0      0.0     0.0     0.0    0.0      1\n",
              "1      1.0     0.0     0.0    0.0      1\n",
              "2      0.0     0.0     1.0    1.0      1\n",
              "3      0.0     0.0     0.0    0.0      1\n",
              "4      0.0     0.0     0.0    0.0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OLzhQqubwDF",
        "colab_type": "text"
      },
      "source": [
        "###***G. Aplicación de Selección Univariante***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzou1W_5bz66",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se esta implementando una técnica que corresponde a la aplicación de ***Selección Univariante***. Las pruebas estadísticas se pueden usar para seleccionar aquellas características que tienen la relación más fuerte con la variable objetivo. Por ejemplo, el método ***ANOVA*** de valor ***F*** es apropiado para entradas numéricas y datos categóricos. ***Esta parte del codigo no es del todo generica, ya que se debe indicar el indice de la columna clase o objetivo***. La columna clase o objetivo debe ser especificada con el objetivo de que no entre en el proceso de ***reducción de dimensionalidad***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hshyFdeIYsjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d6a7a097-38b7-4034-e3b4-4550d996e378"
      },
      "source": [
        "from numpy import set_printoptions\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "import heapq\n",
        "\n",
        "def univar(df, clase): #Implementación de la tecnica\n",
        "  names = df.columns.values\n",
        "  X = df.drop(names[clase], 1) \n",
        "  Y = df[names[clase]]\n",
        "  test = SelectKBest(score_func=f_classif, k=4)\n",
        "  fit = test.fit(X, Y)\n",
        "  set_printoptions(precision=3)\n",
        "  scores = pd.Series(fit.scores_, index=X.columns)\n",
        "  ucols = scores[heapq.nlargest(5, range(len(scores)), scores.__getitem__)].index\n",
        "  df_x = df[ucols]\n",
        "  df_y = df[names[clase]]\n",
        "  df = pd.concat([df_x,df_y],axis=1)\n",
        "  return df\n",
        "\n",
        "ind_clase = 6 #Se debe indicar el indice de la columna clase o objetivo\n",
        "uvdf = univar(df, ind_clase)\n",
        "uvdf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>malas</th>\n",
              "      <th>buenas</th>\n",
              "      <th>costos</th>\n",
              "      <th>cambios</th>\n",
              "      <th>gfeats</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   malas  buenas  costos  cambios  gfeats  clase\n",
              "0    0.0     0.0     0.0      0.0     0.0      1\n",
              "1    0.0     0.0     0.0      1.0     0.0      1\n",
              "2    1.0     1.0     0.0      0.0     0.0      1\n",
              "3    0.0     0.0     0.0      0.0     0.0      1\n",
              "4    0.0     0.0     0.0      0.0     0.0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si2kUMK5axrL",
        "colab_type": "text"
      },
      "source": [
        "###***H. Comparación y Conclusión sobre la mejor técnica***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvIFp3mtbjfM",
        "colab_type": "text"
      },
      "source": [
        "En esta parte, se evaluara que tecnica de ***selección de caracteristicas*** tiene mejor efecto en la exactitud  de los clasificadores. Para dicha evaluación, se utilizara una función llamada ***prove***. Esta función promedia la exactitud de 3 clasificadores ***(KNN, Arbol de decisión y SVM)***, realizando un muestreo de ***cross validation estratificado con k folds***, sobre los datos dados. En este caso ***k=15***. La función ***prove*** sera aplicada sobre cada conjunto de datos obtenido con cada tecnica de selección. La tecnica que de mejores resultados sera utilizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5vUySc-cNWm",
        "colab_type": "text"
      },
      "source": [
        "A continuación, se imprime la exactitud obtenida, aplicando la tecnica de ***Analisis de Componenetes Principales (PCA)***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsYu5VcQYwFs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60c9f2e3-fc0a-4983-8d7d-fc0a0984ce6b"
      },
      "source": [
        "prove(pcadf, 15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Puntuación total promedio:  0.7597979797979799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J7two6LcS0D",
        "colab_type": "text"
      },
      "source": [
        "hora bien, se imprime la exactitud obtenida, aplicando la tecnica de ***Filtrado con correlación de Pearson***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs9ynw1nY1GZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24da747b-fbb1-496d-e56b-d6ac05331e40"
      },
      "source": [
        "prove(dffp,15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Puntuación total promedio:  0.7795959595959598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUahvFH2cYdc",
        "colab_type": "text"
      },
      "source": [
        "Se imprime la exactitud obtenida, aplicando la tecnica de ***Wrapper: Eliminación hacia atrás***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aOyOZeYY5Ee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b442532e-c8cd-4071-8751-175bd46aad35"
      },
      "source": [
        "prove(dfbe, 15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Puntuación total promedio:  0.7858585858585859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nXMSLtRceEf",
        "colab_type": "text"
      },
      "source": [
        "A continuación, se imprime la exactitud obtenida, aplicando la tecnica de ***Wrapper: Eliminación de Característica Recursiva***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVL9vlDpY72l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c95918e-7aca-49d1-e70a-f8bfee77bef0"
      },
      "source": [
        "prove(wradf, 15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Puntuación total promedio:  0.7575757575757577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfJCK90XckQH",
        "colab_type": "text"
      },
      "source": [
        "Con el siguiente codigo, se imprime la exactitud obtenida, aplicando el ***Método Embebido***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze1cbN6-ZAQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36cf4911-a5cb-4a37-e919-31332fabf2f7"
      },
      "source": [
        "prove(emdf, 15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Puntuación total promedio:  0.7575757575757577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rv5PSsGcqWJ",
        "colab_type": "text"
      },
      "source": [
        "Ahora bien, se imprime la exactitud obtenida, aplicando la tecnica de ***Árboles extremadamente aleatorizados (Extra Tree Classifier) para selección de caracteristicas***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI7UPf7bZDY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d4e3bbc-8cb1-480f-c6d8-04eb0d9eb3a3"
      },
      "source": [
        "prove(xtdf, 15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Puntuación total promedio:  0.8036363636363636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqmyGUhmcyR4",
        "colab_type": "text"
      },
      "source": [
        "Se imprime la exactitud obtenida, aplicando la tecnica de ***Selección Univariante***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFj0ITBHZHkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "615d8637-39d5-46fe-c0fb-9398ac895c7b"
      },
      "source": [
        "prove(uvdf, 15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Puntuación total promedio:  0.7842424242424244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnGPzz0Ac4Ai",
        "colab_type": "text"
      },
      "source": [
        "A continuación, se muestra una tabla con los resultados obtenidos para cada tecnica de ***selección de caracteristicas y/o reducción de dimensionalidad*** aplicada. \n",
        "\n",
        "![alt text](https://i.ibb.co/GxzSn6W/featselectab.png)\n",
        "\n",
        "Como se puede apreciar, el ***Método de Árboles extremadamente aleatorizados*** ha logrado obtener la mejor exactitud promedio dada la evaluación realizada. La exactitud promedio alacanzada es de ***80.36%*** aproximadamente. A continuación, se asigna que el conjunto de datos a usar tendra solo las **4 caracteristicas** seleccionadas por el ***Método de Árboles extremadamente aleatorizados***. Aparte de dichas caracteristicas, tambien se contara con la columna clase o objetivo. Se debe resaltar que las caracteristicas finales seleccionadas y más relevantes son ***cambios***, ***costos***, ***buenas*** y ***malas***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQiF9gbWZJJX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "73d3cd20-9696-4e13-c07c-12071134cfc0"
      },
      "source": [
        "df = xtdf\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cambios</th>\n",
              "      <th>costos</th>\n",
              "      <th>buenas</th>\n",
              "      <th>malas</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cambios  costos  buenas  malas  clase\n",
              "0      0.0     0.0     0.0    0.0      1\n",
              "1      1.0     0.0     0.0    0.0      1\n",
              "2      0.0     0.0     1.0    1.0      1\n",
              "3      0.0     0.0     0.0    0.0      1\n",
              "4      0.0     0.0     0.0    0.0      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Biyc0n6_OhTi",
        "colab_type": "text"
      },
      "source": [
        "#***III. Prueba con Clasificadores***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2rJs8zJduge",
        "colab_type": "text"
      },
      "source": [
        "##***1. Análisis de hiperparámetros con métricas de desempeño***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYZrguXicqSz",
        "colab_type": "text"
      },
      "source": [
        "En esta parte, se debe seleccionar ***5*** algoritmos de aprendizaje supervisado, los cuales seran utilizados para trabajar el conjunto de datos respectivo. Se evaluaran los diferentes valores que pueden tomar los hiperparametros de cada algoritmo de aprendizaje supervisado, con el objetivo de encontrar aquellos que maximizen el desempeño de clasificación. Para la evaluación, se utilizaran metricas de desempeño como ***exactitud, precisión, recall, F1, y las curvas ROC***. Asimismo, para el muestreo respecto a la selección de datos de prueba y entrenamiento, se aplicara ***cross-validation estratificado***. Ahora bien, los algoritmos seleccionados son ***K Vecinos más Cercanos (KNN), Árboles de Decisión, Random Forest, Regresión Logistica (Logistic Regression) y Redes Bayesianas Multinomiales (Multinomial Naive Bayes)***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dq0kCjdgQHy",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se implementa la función ***test_model***, la cual tiene como objetivo permitir probar un modelo de clasficación con el conjunto de datos dado. Esta evaluación se hace con ***cross-validation estratificado*** dado un numero de folds. La parte interesante de esta función es que retorna distintas metricas de evaluación, tales como ***exactitud, precisión, recall, F1 y Área bajo la curva ROC (AUC)***. En el caso de ***precisión***, ***recall*** y ***f1***, ***test_model*** permite obtener el valor de dichas metricas para ambas clases ***(Positivo y Negativo)***. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HpqjrAcP1Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def test_model(model, df, nfols): #Implementación de función para probar modelo con metricas\n",
        "  X = df.iloc[:,:-1].values #Caracteristicas\n",
        "  Y = df.iloc[:,-1].values #Columna objetivo\n",
        "  skf = StratifiedKFold(n_splits=nfols)\n",
        "  acuracym = 0 #Exactitud\n",
        "  precisionpm = 0 #Precisión Positiva\n",
        "  recallpm = 0 #Recall Positivo\n",
        "  f1pm = 0 #F1 Positivo\n",
        "  precisionnm = 0 #Precisión Negativo\n",
        "  recallnm = 0 #Recall Negativo\n",
        "  f1nm = 0 #F1 Negativo\n",
        "  aucm = 0 #Area bajo la curva ROC\n",
        "  for train_index, test_index in skf.split(X, Y): #Cross-validation estratificado con k folds\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "    model.fit(X_train, Y_train)\n",
        "    predicciones = model.predict(X_test)\n",
        "    acuracym += accuracy_score(Y_test, predicciones)\n",
        "    precisionp, recallp, f1p, support = precision_recall_fscore_support(Y_test, predicciones, pos_label=1, average='binary', zero_division=0)\n",
        "    precisionn, recalln, f1n, support = precision_recall_fscore_support(Y_test, predicciones, pos_label=0, average='binary', zero_division=0)\n",
        "    precisionpm += precisionp\n",
        "    recallpm += recallp\n",
        "    f1pm += f1p\n",
        "    precisionnm += precisionn\n",
        "    recallnm += recalln\n",
        "    f1nm += f1n\n",
        "    aucm += roc_auc_score(Y_test, model.predict_proba(X_test)[::,1])\n",
        "  return acuracym/nfols, precisionpm/nfols, recallpm/nfols, f1pm/nfols, precisionnm/nfols, recallnm/nfols, f1nm/nfols, aucm/nfols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbIUS2f8hZoK",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se implementa la función ***test_model_array***, la cual es una versión alternativa de la función ***test_model***. ***test_model_array*** tambien retorna distintas metricas de evaluación, tales como ***exactitud, precisión, recall, F1 y Área bajo la curva ROC (AUC)***. No obstante, no se retorna el valor promedio respectivo, sino se devuelve un arreglo con todos los valores obtenidos en el ***cross-validation***. En ese sentido, para ***exactitud***, por ejemplo, se obtendria un arreglo con todas las ***exactitudes*** obtenidas por cada subconjunto de la ***validación cruzada***. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz27gZfl3KRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model_array(model, df, nfols): #Implementación de función para probar modelo y retornar arreglos con resultados de cv\n",
        "  X = df.iloc[:,:-1].values #Caracteristicas\n",
        "  Y = df.iloc[:,-1].values #Columna objetivo\n",
        "  skf = StratifiedKFold(n_splits=nfols)\n",
        "  acuracya = [] #Exactitud\n",
        "  precisionpa = [] #Precisión Positiva\n",
        "  recallpa = [] #Recall Positivo\n",
        "  f1pa = [] #F1 Positivo\n",
        "  precisionna = [] #Precisión Negativo\n",
        "  recallna = [] #Recall Negativo\n",
        "  f1na = [] #F1 Negativo\n",
        "  auca = [] #Area bajo la curva ROC\n",
        "  for train_index, test_index in skf.split(X, Y): #Cross-validation estratificado con k folds\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "    model.fit(X_train, Y_train)\n",
        "    predicciones = model.predict(X_test)\n",
        "    acuracya.append(accuracy_score(Y_test, predicciones))\n",
        "    precisionp, recallp, f1p, support = precision_recall_fscore_support(Y_test, predicciones, pos_label=1, average='binary', zero_division=0)\n",
        "    precisionn, recalln, f1n, support = precision_recall_fscore_support(Y_test, predicciones, pos_label=0, average='binary', zero_division=0)\n",
        "    precisionpa.append(precisionp)\n",
        "    recallpa.append(recallp)\n",
        "    f1pa.append(f1p)\n",
        "    precisionna.append(precisionn)\n",
        "    recallna.append(recalln)\n",
        "    f1na.append(f1n)\n",
        "    auca.append(roc_auc_score(Y_test, model.predict_proba(X_test)[::,1]))\n",
        "  return acuracya, precisionpa, recallpa, f1pa, precisionna, recallna, f1na, auca"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJCrGqUmP87M",
        "colab_type": "text"
      },
      "source": [
        "###***A. K Vecinos más Cercanos (KNN)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFkjC1QAVh0-",
        "colab_type": "text"
      },
      "source": [
        "Se procedera a realizar el ajuste de hiperparametros para ***KNN*** con el conjunto de datos dado. Con respecto a dicho ajuste, nos enfocaremos en ***3 hiperparametros*** principalmente, los cuales son ***Numero de vecinos (n_neighbors), Pesos (weights) y Algoritmo (algorithm)***. Estos seran ajustados, ya que son considerados los más importantes. Se tratara de buscar la combinación de estos ***hiperparametros*** que maximize la performance de clasficación. Se aplicara ***cross-validation estratificado con K=50*** para el muestreo. La evaluación de cada combinación de ***hiperparametros*** se realizá con la función ***test_model***. Llegados a este punto, se procedera a describir a los ***hiperparametros***:\n",
        "\n",
        "* ***Numero de vecinos (n_neighbors): Número de vecinos a usar por defecto para consultas de vecinos.***\n",
        "\n",
        "* ***Pesos (weights): Función de peso utilizada en predicción, la cual puede ser Uniforme (uniform) o de Distancia (distance).***\n",
        "\n",
        "* ***Algoritmo (algorithm): Algoritmo utilizado para calcular los vecinos más cercanos. Este algoritmo puede ser Ball tree, KD tree, Fuerza bruta (brute) y Automatico (auto).***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkYu55DCjkLb",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, respecto a la busqueda de los mejores hiperparametros, no se estan evaluando todas las posibilidades. Esto ultimo ocurre principalmente con el ***Numero de vecinos (n_neighbors)***. En este caso, lo que se propone es primero realizar una búsqueda general rápida, con el objetivo de ubicar, aproximadamente, el rango en el que se podría encontrar el ***hiperparametro*** óptimo. Una vez ubicado dicho rango, proceder con una búsqueda exhaustiva. Además, se almacena el ***promedio de las metricas*** obtenidas, por cada combinación de ***hiperparametros*** evaluada, en un arreglo. Con dicho promedio, se logra considerar la optimización de todas las metricas en la busqueda de los ***hiperparametros***. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhlNT58dP7_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "\n",
        "#Hiperparametros:\n",
        "n_neigbs = [2, 10, 30, 50, 70, 100] \n",
        "weigs = ['uniform', 'distance']\n",
        "algort = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "\n",
        "knnallp = [] #Arreglo para guardar el promedio de todas las metricas\n",
        "knnmods = [] #Arreglo para guardar los modelos ajustados\n",
        "\n",
        "for n in n_neigbs: #Busqueda de hiperparametros\n",
        "  for w in weigs:\n",
        "    for al in algort:\n",
        "      knn = KNN(n_neighbors=n, weights=w, algorithm=al)\n",
        "      acc, prep, recp, f1p, pren, recn, f1n, auc = test_model(knn, df, 50)\n",
        "      knnallp.append((acc+prep+recp+f1p+pren+recn+f1n+auc)/8)\n",
        "      knnmods.append(knn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDjI8TXIkx0b",
        "colab_type": "text"
      },
      "source": [
        "Con la evaluación ***test_model***, se consideran una serie de metricas, las cuales son promediadas y almacenadas durante la busqueda. En el siguiente codigo, se indica el máximo ***promedio de metricas*** obtenido en la busqueda. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho promedio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHVJLb-qszJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7c93f3a9-ea68-4e43-913f-335f48db8021"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "idx = np.array(knnallp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = knnmods[idx]\n",
        "print(\"Mejor promedio de metricas obtenido en la busqueda: \", knnallp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de vecinos (n_neighbors): \", bestmodel.get_params()['n_neighbors'])\n",
        "print(\"Pesos (weights): \", bestmodel.get_params()['weights'])\n",
        "print(\"Algoritmo (algorithm): \", bestmodel.get_params()['algorithm'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor promedio de metricas obtenido en la busqueda:  0.8014791666666667\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de vecinos (n_neighbors):  30\n",
            "Pesos (weights):  uniform\n",
            "Algoritmo (algorithm):  brute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mjRbAHolYsG",
        "colab_type": "text"
      },
      "source": [
        "De acuerdo a lo obtenido anteriormente, con respecto a el ***Numero de vecinos (n_neighbors)***, se logra identificar que el mejor valor para dicho ***hiperparametro*** es cercano a ***30***. En ese sentido, se reducira el rango a **[5, 55]**, y se procedera a realizar una busqueda exhaustiva. Cabe mencionar que se almacenan las metricas obtenidas y el promedio de dichas metricas, por cada combinación de ***hiperparametros*** evaluada, en arreglos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqchmgVJ7qeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hiperparametros: \n",
        "n_neigbs = [i for i in range(5,55)]\n",
        "weigs = ['uniform', 'distance']\n",
        "algort = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "\n",
        "knnacc = [] #Arreglo para guardar exactitudes\n",
        "knnprep = [] #Arreglo para guardar precisiones positivas\n",
        "knnrecp = [] #Arreglo para guardar recalls positivos\n",
        "knnf1p = [] #Arreglo para guardar F1s positivos\n",
        "knnpren = [] #Arreglo para guardar precisiones negativas\n",
        "knnrecn = [] #Arreglo para guardar recalls negativos\n",
        "knnf1n = [] #Arreglo para guardar F1s negativos\n",
        "knnauc = [] #Arreglo para guardar AUCs\n",
        "knnallp = [] #Arreglo para guardar el promedio de todas las metricas\n",
        "knnmods = [] #Arreglo para guardar los modelos ajustados\n",
        "\n",
        "for n in n_neigbs: #Busqueda de hiperparametros\n",
        "  for w in weigs:\n",
        "    for al in algort:\n",
        "      knn = KNN(n_neighbors=n, weights=w, algorithm=al)\n",
        "      acc, prep, recp, f1p, pren, recn, f1n, auc = test_model(knn, df, 50)\n",
        "      knnacc.append(acc)\n",
        "      knnprep.append(prep)\n",
        "      knnrecp.append(recp)\n",
        "      knnf1p.append(f1p)\n",
        "      knnpren.append(pren)\n",
        "      knnrecn.append(recn)\n",
        "      knnf1n.append(f1n)\n",
        "      knnauc.append(auc)\n",
        "      knnallp.append((acc+prep+recp+f1p+pren+recn+f1n+auc)/8)\n",
        "      knnmods.append(knn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPk7GZbOoJZG",
        "colab_type": "text"
      },
      "source": [
        "####***A.1. Mejores hiperparametros según Promedio de métricas***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUgauj35_0dF",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***promedio de metricas*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho promedio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LLKo8wKAEM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a4b042ef-d156-4fb6-bab4-299cb687510e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "idx = np.array(knnallp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = knnmods[idx]\n",
        "print(\"Mejor promedio de metricas obtenido en la busqueda: \", knnallp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de vecinos (n_neighbors): \", bestmodel.get_params()['n_neighbors'])\n",
        "print(\"Pesos (weights): \", bestmodel.get_params()['weights'])\n",
        "print(\"Algoritmo (algorithm): \", bestmodel.get_params()['algorithm'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor promedio de metricas obtenido en la busqueda:  0.8014791666666667\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de vecinos (n_neighbors):  30\n",
            "Pesos (weights):  uniform\n",
            "Algoritmo (algorithm):  brute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XoBB1f_m2mi",
        "colab_type": "text"
      },
      "source": [
        "Ahora bien, considerando el promedio de todas las metricas evaluadas, se logra definir los ***hiperparametros*** señalados anteriormente como los mejores. No obstante, ello puede cambiar si se analiza desde la perspectiva de cada metrica. Por lo tanto, se procedera a indicar el maximo valor obtenido de cada metrica, durante la busqueda, y los ***hiperparametros*** que permiten alcanzar dicho valor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkbuSa2rA8AM",
        "colab_type": "text"
      },
      "source": [
        "####***A.2. Mejores hiperparametros según metrica de Exactitud (Accuracy)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3sITl6pPom",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Exactitud (Accuracy)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***exactitudes*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBujVDT17I3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "d360cabe-d46e-41a8-dfc4-afab12c34622"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "idx = np.array(knnacc).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = knnmods[idx]\n",
        "print(\"Mejor Exactitud (Accuracy) promedio obtenida en la busqueda: \", knnacc[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de vecinos (n_neighbors): \", bestmodel.get_params()['n_neighbors'])\n",
        "print(\"Pesos (weights): \", bestmodel.get_params()['weights'])\n",
        "print(\"Algoritmo (algorithm): \", bestmodel.get_params()['algorithm'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de exactitudes obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=acca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Exactitud (Accuracy) promedio obtenida en la busqueda:  0.815\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de vecinos (n_neighbors):  14\n",
            "Pesos (weights):  uniform\n",
            "Algoritmo (algorithm):  ball_tree\n",
            "\n",
            "Boxplot de exactitudes obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521d471828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hF5IVXSI6A6",
        "colab_type": "text"
      },
      "source": [
        "####***A.3. Mejores hiperparametros según metrica de Precisión (precision)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWZHR9vJrQAc",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Precisión (precision) para Positivo (clase positiva)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***precisiones (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2JOEKJPJCXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "245506bc-7d69-41b1-9298-ccab82f84ef3"
      },
      "source": [
        "idx = np.array(knnprep).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = knnmods[idx]\n",
        "print(\"Mejor Precisión (precision) para Positivo (clase positiva) promedio obtenida en la busqueda: \", knnprep[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de vecinos (n_neighbors): \", bestmodel.get_params()['n_neighbors'])\n",
        "print(\"Pesos (weights): \", bestmodel.get_params()['weights'])\n",
        "print(\"Algoritmo (algorithm): \", bestmodel.get_params()['algorithm'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=prepa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Precisión (precision) para Positivo (clase positiva) promedio obtenida en la busqueda:  0.8133333333333335\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de vecinos (n_neighbors):  15\n",
            "Pesos (weights):  uniform\n",
            "Algoritmo (algorithm):  brute\n",
            "\n",
            "Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521d0592e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPQElEQVR4nO3df2xdZ33H8bd9c8sEDqxyHdaGlP5Y/R3TSCtTqAaUiR/tULRNaBsMbywVTEPZplQDKjEm0VWgwpCqISE8JSvblK7gSWOIdlOAadUEa7VpFCUbv/JN1KZNlrSLZUqWjLY4194fPqmM49rn2icc59H7JUX33uc+956PkujjR4/PPXdgbm4OSVJ5BtsOIEk6Pyx4SSqUBS9JhbLgJalQFrwkFWpD2wEqLwBeDTwB9FrOIkkXig5wKfB14NnFT66Xgn818K9th5CkC9SNwIOLB9dLwT8B8NRT/8fsrOflS1Idg4MDXHzxi6Dq0MXWS8H3AGZn5yx4Serfklvb/pJVkgplwUtSoSx4SSrUinvwEXEX8GvAFcArM/NbS8zpAJ8C3grMAX+amZ9pNqokqR91VvBfBN4APL7MnN8Cfhq4Bvh54I6IuGLN6SRJq7ZiwWfmg5l5dIVpvwHcnZmzmTnF/A+FtzcRUJK0Ok2dJnk5P7rCPwJsaei9f2zuuuvjHD78SNsx1oUzZ87Q651pO4bWmU5nAxs2rJezq9t15ZVXc9ttH2o7xrLW1b/U8PBQq8c/efJ7PP300zC4rv5a2jE3C34ZjBaZnesx0/P/BbNnOHnye4yMbGw7ybKaarIjwMuZvx4CnLuir2V6+nSrH3QaGnoxnRf+kBe+/M2tZZC0/v3g8QcYGnoxU1OnWs0xODiw7MK4qYL/O+B3I+ILwDDwNuavjSBJasmKv2SNiE9FxH8DLwP+OSK+XY3vjYjrq2l/AzwKHAL+HfhIZh4+T5klSTWsuILPzFuBW5cY37bgfg/4vWajSZLWwk+ySlKhLHhJKpQFL0mFsuAlqVAWvCQVyoKXpEJZ8JJUKAtekgplwUtSoSx4SSqUBS9JhbLgJalQFrwkFcqCl6RCWfCSVCgLXpIKZcFLUqEseEkqlAUvSYWy4CWpUBa8JBVqQ51JETEK7AGGgWlge2YeWjTnp4DdwJVAF7gzM+9tNq4kqa66K/hdwERmjgITzBf5Yn8GPJyZW4E3AB+LiC3NxJQk9WvFgo+ITcAYMFkNTQJjETGyaOq1wJcBMnMK2A+8o7mokqR+1Nmi2QIcy8weQGb2IuJ4NT61YN43gHdGxMPAFcBrgcf6CTM8PNTP9MZ1u51Wjy/pwtHtdhgZ2dh2jGXV2oOv6QPAJ5lfuR8BHgDO9PMG09OnmZ2dazBSf2Zmeq0dW9KFZWamx9TUqVYzDA4OLLswrlPwR4HNEdGpVu8d4LJq/DnVtsy7zj6OiL3Ad1aVWpK0ZivuwWfmCeZX5ePV0Diwryr050TEcERsqO6/CXgl8Llm40qS6qp7Fs0OYGdEHAR2Vo+JiL0RcX015zXAdyPiAPAR4Jcz8wdNB5Yk1VNrDz4zDwA3LDG+bcH9LwHXNBdNkrQWfpJVkgplwUtSoSx4SSqUBS9JhbLgJalQFrwkFcqCl6RCWfCSVCgLXpIKZcFLUqEseEkqlAUvSYWy4CWpUBa8JBXKgpekQlnwklQoC16SCmXBS1KhLHhJKpQFL0mFqvWl2xExCuwBhoFpYHtmHlo0ZxPw18AWoAv8C3BrZp5pNLEkqZa6K/hdwERmjgITwO4l5vwx8N3M3ApsBV4F/GojKSVJfVux4KuV+RgwWQ1NAmMRMbJo6hywMSIGgRcAFwHHGswqSepDnRX8FuBYZvYAqtvj1fhCHwVGgSeAJ4GvZOZDDWaVJPWh1h58TW8H/gt4M7AR+FJE/Hpmfr7uGwwPDzUYp3/dbqfV40u6cHS7HUZGNrYdY1l1Cv4osDkiOpnZi4gOcFk1vtBO4D2ZOQucjIj7gDcCtQt+evo0s7Nzdac3bmam19qxJV1YZmZ6TE2dajXD4ODAsgvjFbdoMvMEsB8Yr4bGgX2ZObVo6mHgrQARcRHwFuBbq8gsSWpA3bNodgA7I+Ig8yv1HQARsTcirq/m/CFwY0R8k/kfCAeBuxvOK0mqqdYefGYeAG5YYnzbgvuPADc1F02StBZ+klWSCmXBS1KhLHhJKpQFL0mFsuAlqVAWvCQVyoKXpEJZ8JJUKAtekgplwUtSoSx4SSqUBS9JhbLgJalQFrwkFcqCl6RCWfCSVCgLXpIKZcFLUqEseEkqlAUvSYWy4CWpUBvqTIqIUWAPMAxMA9sz89CiOfcAWxcMbQXelpn3N5RVktSHuiv4XcBEZo4CE8DuxRMyc3tmXpeZ1wG3AE8BX2ksqSSpLysWfERsAsaAyWpoEhiLiJFlXvY7wGcz89m1R5QkrUadFfwW4Fhm9gCq2+PV+Dki4iLgN4G/aiqkJKl/tfbg+/Q24Ehm7u/3hcPDQ+chTn3dbqfV40u6cHS7HUZGNrYdY1l1Cv4osDkiOpnZi4gOcFk1vpT3sMrV+/T0aWZn51bz0kbMzPRaO7akC8vMTI+pqVOtZhgcHFh2YbziFk1mngD2A+PV0DiwLzOnFs+NiJcBNwKfXVVaSVJj6p5FswPYGREHgZ3VYyJib0Rcv2DeLcA/ZOZTzcaUJPWr1h58Zh4AblhifNuix3c2lEuStEZ+klWSCmXBS1KhLHhJKpQFL0mFsuAlqVAWvCQVyoKXpEJZ8JJUKAtekgplwUtSoSx4SSqUBS9JhbLgJalQFrwkFcqCl6RCWfCSVCgLXpIKZcFLUqEseEkqlAUvSYWy4CWpUBvqTIqIUWAPMAxMA9sz89AS894BfBgYAOaAt2Tm/zQXV5JUV90V/C5gIjNHgQlg9+IJEXE9cAdwU2b+HPB64GRDOSVJfVqx4CNiEzAGTFZDk8BYRIwsmvo+4K7MfBIgM09m5jNNhpUk1Vdni2YLcCwzewCZ2YuI49X41IJ5PwscjoivAUPAF4A7M3Oubpjh4aHawc+HbrfT6vElXTi63Q4jIxvbjrGsWnvwNXWArcBNwEXAl4EjwD1132B6+jSzs7V/HjRuZqbX2rElXVhmZnpMTZ1qNcPg4MCyC+M6e/BHgc0R0QGobi+rxhc6Anw+M5/NzFPAfcBrVpVakrRmKxZ8Zp4A9gPj1dA4sC8zpxZN/Rxwc0QMREQXeDPwn02GlSTVV/csmh3Azog4COysHhMRe6uzZwD+FjgBfIf5HwjfBv6y2biSpLpq7cFn5gHghiXGty24Pwu8v/ojSWqZn2SVpEJZ8JJUKAtekgplwUtSoSx4SSqUBS9JhbLgJalQFrwkFcqCl6RCWfCSVCgLXpIKZcFLUqEseEkqlAUvSYWy4CWpUBa8JBXKgpekQlnwklQoC16SCmXBS1Khan3pdkSMAnuAYWAa2J6ZhxbNuQP4feB4NfRQZv5Bc1ElSf2oVfDALmAiM++NiHcBu4E3LTHvnsy8rbF0kqRVW3GLJiI2AWPAZDU0CYxFxMj5DCZJWps6K/gtwLHM7AFkZi8ijlfjU4vmvjMibgaeBP4kM/+t0bQ/Br1nvs8PHn+g7RhaJ2bPPAPA4IafaDmJ1pPeM98HLmk7xorqbtHUsQu4MzNnIuIm4L6IeEVmTtd9g+HhoQbj9C/iGrrdTqsZtL48+uijAFx11UtbTqL15aVcddVVjIxsbDvIsgbm5uaWnVBt0RwEhqvVe4f5X7Rek5mLV/ALX/cN4P2Z+dUaOa4ADk9Pn2Z2dvk80o/TJz7xUQA++MEPt5xEOtfg4MDZhfGVwGPnPL/SG2TmCWA/MF4NjQP7Fpd7RGxecP865ks7V5lbkrRGdbdodgB7IuJ24ClgO0BE7AVuz8yHgY9FxKuAHvBD4Lcz88nzkFmSVEOtgs/MA8ANS4xvW3D/lgZzSZLWyE+ySlKhLHhJKpQFL0mFsuAlqVAWvCQVyoKXpEJZ8JJUKAtekgplwUtSoSx4SSqUBS9JhbLgJalQFrwkFcqCl6RCWfCSVCgLXpIKZcFLUqEseEkqlAUvSYWy4CWpUBa8JBVqQ51JETEK7AGGgWlge2Yeep65AewD/jwzb2sqqCSpP3VX8LuAicwcBSaA3UtNiohO9dwXm4knSVqtFQs+IjYBY8BkNTQJjEXEyBLT/wj4R+BgYwklSatSZwW/BTiWmT2A6vZ4Nf6ciLgW+EXgk02HlCT1r9Ye/Eoiogv8BfDuzOzNb8P3b3h4qIk4UmO63Q4AIyMbW04i9a9OwR8FNkdEpyrvDnBZNX7WpcDVwN6q3H8SGIiIF2fme+uGmZ4+zezsXP300nk2M9MDYGrqVMtJpHMNDg4suzBeseAz80RE7AfGgXur232ZObVgzhHgkrOPI+IOYMizaCSpPXXPotkB7IyIg8DO6jERsTcirj9f4SRJq1drDz4zDwA3LDG+7Xnm37G2WJKktfKTrJJUKAtekgplwUtSoSx4SSqUBS9JhbLgJalQFrwkFcqCl6RCWfCSVCgLXpIKZcFLUqEseEkqlAUvSYUamJtbF1+wcQVw2C/8WD8eeuhrPPjgV9uO0bojRx4H4PLLX95ykvXh9a//BV73uje0HUOVBV/4cSXw2OLnG/nKPqlUL3nJS9qOIK2aK3hJukCttIJ3D16SCmXBS1KhLHhJKpQFL0mFsuAlqVC1TpOMiFFgDzAMTAPbM/PQojnvBt4HzAId4O7M/FSzcSVJddVdwe8CJjJzFJgAdi8x5++BazPzOuC1wAciYmszMSVJ/VpxBR8Rm4Ax4KZqaBL4dESMZObU2XmZ+b8LXvZCoAvUPam9A/PndEqS6lnQmZ2lnq+zRbMFOJaZPYDM7EXE8Wp8auHEiPgV4OPA1cCHMvObNXNeCnDxxS+qOV2StMClwCOLBxu9VEFm3g/cHxGXA1+MiL2ZmTVe+nXgRuAJoNdkJkkqWIf5cv/6Uk/WKfijwOaI6FSr9w5wWTW+pMw8EhH/AfwSUKfgnwUerDFPkvSjzlm5n7XiL1kz8wSwHxivhsaBfQv33wEi4hUL7l8CvBGou0UjSWpY3S2aHcCeiLgdeArYDhARe4HbM/Nh4L0RcTMwAwwAn87MfzoPmSVJNayXq0lKkhrmJ1klqVAWvCQVyoKXpEJZ8JJUKL+TVVpGnQvtSeuVK3hpeXUutCetSxa89DwWXGhvshqaBMYiYqS9VFJ9Frz0/M650B5w9kJ70rpnwUtSoSx46fk9d6E9gDoX2pPWEwteeh51L7QnrVdei0ZaRkT8DPOnSV5MdaG9mt9xILXOgpekQrlFI0mFsuAlqVAWvCQVyoKXpEJZ8JJUKAtekgplwUtSoSx4SSrU/wPIVtVXosRGFgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-GANqP3sbBh",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Precisión (precision) para Negativo (clase negativa)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***precisiones (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVysvZyePfgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "94aa2480-df5d-4abd-c668-de9f098e184b"
      },
      "source": [
        "idx = np.array(knnpren).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = knnmods[idx]\n",
        "print(\"Mejor Precisión (precision) para Negativo (clase negativa) promedio obtenida en la busqueda: \", knnpren[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de vecinos (n_neighbors): \", bestmodel.get_params()['n_neighbors'])\n",
        "print(\"Pesos (weights): \", bestmodel.get_params()['weights'])\n",
        "print(\"Algoritmo (algorithm): \", bestmodel.get_params()['algorithm'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=prena)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Precisión (precision) para Negativo (clase negativa) promedio obtenida en la busqueda:  0.7933333333333333\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de vecinos (n_neighbors):  15\n",
            "Pesos (weights):  uniform\n",
            "Algoritmo (algorithm):  brute\n",
            "\n",
            "Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521ceb2780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YCK8L09PyzR",
        "colab_type": "text"
      },
      "source": [
        "####***A.4. Mejores hiperparametros según metrica de Recall***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37EHY3HntGZo",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***Recall para Positivo (clase positiva)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***recalls (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mzCWPALSQJHr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "7174e6eb-aa7c-435d-890d-de799f6515fe"
      },
      "source": [
        "idx = np.array(knnrecp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = knnmods[idx]\n",
        "print(\"Mejor Recall para Positivo (clase positiva) promedio obtenido en la busqueda: \", knnrecp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de vecinos (n_neighbors): \", bestmodel.get_params()['n_neighbors'])\n",
        "print(\"Pesos (weights): \", bestmodel.get_params()['weights'])\n",
        "print(\"Algoritmo (algorithm): \", bestmodel.get_params()['algorithm'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=recpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Recall para Positivo (clase positiva) promedio obtenido en la busqueda:  0.97\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de vecinos (n_neighbors):  15\n",
            "Pesos (weights):  uniform\n",
            "Algoritmo (algorithm):  kd_tree\n",
            "\n",
            "Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521d4845c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gkxztUmtit7",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***Recall para Negativo (clase negativa)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***recalls (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6W8tDW4RSH3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "e0815dee-0558-4d69-acc3-60c15c51a76b"
      },
      "source": [
        "idx = np.array(knnrecn).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = knnmods[idx]\n",
        "print(\"Mejor Recall para Negativo (clase negativa) promedio obtenido en la busqueda: \", knnrecn[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de vecinos (n_neighbors): \", bestmodel.get_params()['n_neighbors'])\n",
        "print(\"Pesos (weights): \", bestmodel.get_params()['weights'])\n",
        "print(\"Algoritmo (algorithm): \", bestmodel.get_params()['algorithm'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=recna)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Recall para Negativo (clase negativa) promedio obtenido en la busqueda:  0.72\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de vecinos (n_neighbors):  19\n",
            "Pesos (weights):  uniform\n",
            "Algoritmo (algorithm):  brute\n",
            "\n",
            "Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521d6fad68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmkd_tK4YadJ",
        "colab_type": "text"
      },
      "source": [
        "####***A.5. Mejores hiperparametros según metrica de F1***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sIfu90vuerZ",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***F1 para Positivo (clase positiva)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***f1s (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipRwfezvYfkp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "f1df136c-22e3-4e65-b59f-516d9f4b3735"
      },
      "source": [
        "idx = np.array(knnf1p).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = knnmods[idx]\n",
        "print(\"Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda: \", knnf1p[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de vecinos (n_neighbors): \", bestmodel.get_params()['n_neighbors'])\n",
        "print(\"Pesos (weights): \", bestmodel.get_params()['weights'])\n",
        "print(\"Algoritmo (algorithm): \", bestmodel.get_params()['algorithm'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda:  0.8519999999999999\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de vecinos (n_neighbors):  14\n",
            "Pesos (weights):  uniform\n",
            "Algoritmo (algorithm):  ball_tree\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521d75f860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BJ-M3CRu5px",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***F1 para Negativo (clase negativa)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***f1s (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8n0xu7KZK-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "363d77ac-ccdb-4b8f-d38c-1865c5736b85"
      },
      "source": [
        "idx = np.array(knnf1n).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = knnmods[idx]\n",
        "print(\"Mejor F1 para Negativo (clase negativa) promedio obtenido en la busqueda: \", knnf1n[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de vecinos (n_neighbors): \", bestmodel.get_params()['n_neighbors'])\n",
        "print(\"Pesos (weights): \", bestmodel.get_params()['weights'])\n",
        "print(\"Algoritmo (algorithm): \", bestmodel.get_params()['algorithm'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=f1na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor F1 para Negativo (clase negativa) promedio obtenido en la busqueda:  0.7293333333333334\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de vecinos (n_neighbors):  14\n",
            "Pesos (weights):  uniform\n",
            "Algoritmo (algorithm):  brute\n",
            "\n",
            "Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521da34cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym8x_XDzZ9Q6",
        "colab_type": "text"
      },
      "source": [
        "####***A.6. Mejores hiperparametros según metrica de Área bajo la curva ROC (AUC)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXuOz6LCvo4A",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Área bajo la curva ROC (AUC)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***AUCs*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hmwnZy2taeYf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "430996ff-870f-4447-a4de-b2c11fa6ad59"
      },
      "source": [
        "idx = np.array(knnauc).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = knnmods[idx]\n",
        "print(\"Mejor AUC promedio obtenido en la busqueda: \", knnauc[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de vecinos (n_neighbors): \", bestmodel.get_params()['n_neighbors'])\n",
        "print(\"Pesos (weights): \", bestmodel.get_params()['weights'])\n",
        "print(\"Algoritmo (algorithm): \", bestmodel.get_params()['algorithm'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de AUCs obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=auca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor AUC promedio obtenido en la busqueda:  0.8725\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de vecinos (n_neighbors):  28\n",
            "Pesos (weights):  uniform\n",
            "Algoritmo (algorithm):  brute\n",
            "\n",
            "Boxplot de AUCs obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f522917be80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfE2njGJx9ex",
        "colab_type": "text"
      },
      "source": [
        "####***A.7. Comparación y Síntesis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue4F3YWSyJdF",
        "colab_type": "text"
      },
      "source": [
        "En esta parte, se procedera a realizar la síntesis o resumen de los resultados obtenidos. Se empleara una comparación entre los mismos, con el objetivo de formular conclusiones apropiadas. La evaluación se desarrolla en base a distintas metricas. Entre ellas, cabe mencionar ***Exactitud, Precisión, Recall, F1 y Área bajo la curva ROC (AUC)***. Asimismo, tambien se usa el ***Promedio de métricas***, el cual constituye el promedio de los valores de todas las metricas mencionadas. Dicho promedio fue planteado con el objetivo de considerar la maximización de todas las metricas en la busqueda de los mejores hiperparametros. En la siguiente tabla, se presentan los ***hiperparametros*** que maximizan los valores de cada metrica. En ese sentido, ello permite identificar los mejores ***hiperparametros*** en base a que medida se desee optimizar. \n",
        "\n",
        "![alt text](https://i.ibb.co/xf4krzh/knntab.png)\n",
        "\n",
        "De acuerdo a lo observado en la tabla anterior, es posible concluir que el mejor valor para el ***hiperparametro Pesos*** es ***Uniform***, ya que este logro ser el mejor para todas las métricas consideradas. Asimismo, respecto a ***Numero de vecinos***, no hay un valor mayoritario como en el caso anterior. No obstante, en este tipo de casos, es importante elegir un metrica para basarse en ella y analizar lo obtenido respecto a ***boxplots*** y otros elementos estadisticos. En este caso, se selecciona ***F1*** como metrica de mayor relevancia. El ***Boxplot*** de ***F1*** para ***Positivo***, es decir para la clase positiva, posee sus valores distribuidos en valores altos, siendo su limite inferior ***0.5***. Igualmente, el ***Boxplot*** de ***F1*** para ***Negativo***, es decir para la clase negativa, tambien posee sus valores distribuidos en valores altos. El valor promedio de ***F1*** para ***Negativo*** no es tan alto, ya que presenta ***outliers*** en ***0.0***. Considerando la información dada anteriormente, se concluye que ***F1***, en este caso, es un metrica de decisión apropiada. ***14*** logro ser el mejor valor para el ***hiperparametro Numero de vecinos***, en el caso de ***F1*** para ***Positivo*** y ***F1*** para ***Negativo***. Por ultimo, para el ***hiperparametro Algoritmo***, se logra determinar ***Brute*** como el valor optimo, ya que este funciona mejor para la mayoria de metricas consideradas. Por lo tanto, se concluye que los ***hiperparametros*** que logran maximizar las metricas de forma conjunta y funcionan mejor con los datos son:\n",
        "\n",
        "* ***Numero de vecinos (n_neighbors): 14***\n",
        "* ***Pesos (weights): Uniform***\n",
        "* ***Algoritmo (algorithm): Brute***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vkXijatIiBxP"
      },
      "source": [
        "###***B. Árbol de Decisión***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "okZMbC92iBxQ"
      },
      "source": [
        "Se procedera a realizar el ajuste de hiperparametros para ***Arbol de Decisión*** con el conjunto de datos dado. Con respecto a dicho ajuste, nos enfocaremos en ***4 hiperparametros*** principalmente, los cuales son ***Maxima profundidad (max_depth), min_samples_split, min_samples_leaf y max_features***. Estos seran ajustados, ya que son considerados los más importantes. Se tratara de buscar la combinación de estos ***hiperparametros*** que maximize la performance de clasficación. Se aplicara ***cross-validation estratificado con K=50*** para el muestreo. La evaluación de cada combinación de ***hiperparametros*** se realizá con la función ***test_model***. Llegados a este punto, se procedera a describir a los ***hiperparametros***:\n",
        "\n",
        "* ***Maxima profundidad (max_depth): La profundidad máxima del árbol.***\n",
        "\n",
        "* ***min_samples_split: El número mínimo de muestras requeridas para dividir un nodo interno.***\n",
        "\n",
        "* ***min_samples_leaf: El número mínimo de muestras necesarias para estar en un nodo hoja.***\n",
        "\n",
        "* ***max_features: La cantidad de características a considerar cuando se busca la mejor división. Entre las posibilidades, se cuenta con Raíz (sqrt), Logaritmo (log2) y Ninguno de los anteriores (None).***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se2gSOc4NLDd",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, respecto a la busqueda de los mejores hiperparametros, no se estan evaluando todas las posibilidades. En este caso, lo que se propone es primero realizar una búsqueda general rápida, con el objetivo de ubicar, aproximadamente, el rango en el que se podría encontrar el ***hiperparametro*** óptimo. Una vez ubicado dicho rango, proceder con una búsqueda exhaustiva. Además, se almacena el ***promedio de las metricas*** obtenidas, por cada combinación de ***hiperparametros*** evaluada, en un arreglo. Con dicho promedio, se logra considerar la optimización de todas las metricas en la busqueda de los ***hiperparametros***. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AUO6i7vGiBxR",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#Hiperparametros:\n",
        "maxdepts = [5, 10, 30, 50, 100,200]\n",
        "mssplits = [2, 0.1, 0.3, 0.6, 0.8]\n",
        "msleafs = [0.1, 0.3, 0.5]\n",
        "mfeats = ['sqrt','log2',None]\n",
        "\n",
        "dtcallp = [] #Arreglo para guardar el promedio de todas las metricas\n",
        "dtcmods = [] #Arreglo para guardar los modelos ajustados\n",
        "\n",
        "for d in maxdepts: #Busqueda de hiperparametros\n",
        "  for s in mssplits:\n",
        "    for l in msleafs:\n",
        "      for f in mfeats: \n",
        "        dtc = DecisionTreeClassifier(max_depth=d, min_samples_split=s, min_samples_leaf=l, max_features=f)\n",
        "        acc, prep, recp, f1p, pren, recn, f1n, auc = test_model(dtc, df, 50)\n",
        "        dtcallp.append((acc+prep+recp+f1p+pren+recn+f1n+auc)/8)\n",
        "        dtcmods.append(dtc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch5KtxgmN_eu",
        "colab_type": "text"
      },
      "source": [
        "Con la evaluación ***test_model***, se consideran una serie de metricas, las cuales son promediadas y almacenadas durante la busqueda. En el siguiente codigo, se indica el máximo ***promedio de metricas*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho promedio. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GM-HwHOoiBxV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d7b136fc-b732-4e4f-c7ca-a85a2bfe5570"
      },
      "source": [
        "idx = np.array(dtcallp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor promedio de metricas obtenido en la busqueda: \", dtcallp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Maxima profundidad (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"min_samples_split: \", bestmodel.get_params()['min_samples_split'])\n",
        "print(\"min_samples_leaf: \", bestmodel.get_params()['min_samples_leaf'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor promedio de metricas obtenido en la busqueda:  0.8002083333333332\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Maxima profundidad (max_depth):  30\n",
            "min_samples_split:  0.6\n",
            "min_samples_leaf:  0.1\n",
            "max_features:  sqrt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdiLIn4QOEQC",
        "colab_type": "text"
      },
      "source": [
        "De acuerdo a lo obtenido anteriormente, con respecto a la ***Maxima profundidad (max_depth)***, se logra identificar que el mejor valor para dicho ***hiperparametro*** es cercano a ***30***. En ese sentido, se reducira el rango a **[20, 40]**. Ahora bien, con respecto a ***min_samples_split***, el mejor valor se aproxima a ***0.6***. Por lo tanto, el rango, en este caso, sera reducido a **[0.5, 0.7]**. Igualmente, el mejor valor para ***min_samples_leaf*** es cercano a ***0.1***, por lo que el rango respectivo sera reducido a **[0, 0.2]**. Teniendo en cuento estos rangos, se procedera a realizar una busqueda exhaustiva. Cabe mencionar que se almacenan las metricas obtenidas y el promedio de dichas metricas, por cada combinación de ***hiperparametros*** evaluada, en arreglos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "19K8fM4XiBxf",
        "colab": {}
      },
      "source": [
        "#Hiperparametros:\n",
        "maxdepts = [i for i in range(20,40)]\n",
        "mssplits = [i*0.01 for i in range(50, 70, 2)]\n",
        "msleafs = [i*0.01 for i in range(1, 20, 2)]\n",
        "mfeats = ['sqrt','log2',None]\n",
        "\n",
        "dtcacc = [] #Arreglo para guardar exactitudes\n",
        "dtcprep = [] #Arreglo para guardar precisiones positivas\n",
        "dtcrecp = [] #Arreglo para guardar recalls positivos\n",
        "dtcf1p = [] #Arreglo para guardar F1s positivos\n",
        "dtcpren = [] #Arreglo para guardar precisiones negativas\n",
        "dtcrecn = [] #Arreglo para guardar recalls negativos\n",
        "dtcf1n = [] #Arreglo para guardar F1s negativos\n",
        "dtcauc = [] #Arreglo para guardar AUCs\n",
        "dtcallp = [] #Arreglo para guardar el promedio de todas las metricas\n",
        "dtcmods = [] #Arreglo para guardar los modelos ajustados\n",
        "\n",
        "for d in maxdepts: #Busqueda de hiperparametros\n",
        "  for s in mssplits:\n",
        "    for l in msleafs:\n",
        "      for f in mfeats: \n",
        "        dtc = DecisionTreeClassifier(max_depth=d, min_samples_split=s, min_samples_leaf=l, max_features=f)\n",
        "        acc, prep, recp, f1p, pren, recn, f1n, auc = test_model(dtc, df, 50)\n",
        "        dtcacc.append(acc)\n",
        "        dtcprep.append(prep)\n",
        "        dtcrecp.append(recp)\n",
        "        dtcf1p.append(f1p)\n",
        "        dtcpren.append(pren)\n",
        "        dtcrecn.append(recn)\n",
        "        dtcf1n.append(f1n)\n",
        "        dtcauc.append(auc)\n",
        "        dtcallp.append((acc+prep+recp+f1p+pren+recn+f1n+auc)/8)\n",
        "        dtcmods.append(dtc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cZY3IL6riBxj"
      },
      "source": [
        "####***B.1. Mejores hiperparametros según Promedio de métricas***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-XWRejIQTMR",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***promedio de metricas*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho promedio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NMfXwDL8iBxk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "76dab10f-6921-4afe-9935-dd0604882f64"
      },
      "source": [
        "idx = np.array(dtcallp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor promedio de metricas obtenido en la busqueda: \", dtcallp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Maxima profundidad (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"min_samples_split: \", bestmodel.get_params()['min_samples_split'])\n",
        "print(\"min_samples_leaf: \", bestmodel.get_params()['min_samples_leaf'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor promedio de metricas obtenido en la busqueda:  0.8311249999999999\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Maxima profundidad (max_depth):  32\n",
            "min_samples_split:  0.66\n",
            "min_samples_leaf:  0.15\n",
            "max_features:  sqrt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFUzvmJDQkXo",
        "colab_type": "text"
      },
      "source": [
        "Ahora bien, considerando el promedio de todas las metricas evaluadas, se logra definir los ***hiperparametros*** señalados anteriormente como los mejores. No obstante, ello puede cambiar si se analiza desde la perspectiva de cada metrica. Por lo tanto, se procedera a indicar el maximo valor obtenido de cada metrica, durante la busqueda, y los ***hiperparametros*** que permiten alcanzar dicho valor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y9NIvFwCiBxo"
      },
      "source": [
        "####***B.2. Mejores hiperparametros según metrica de Exactitud (Accuracy)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA9HvzyvSO2X",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Exactitud (Accuracy)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***exactitudes*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KNjqmPtjiBxp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "586d6660-f64c-4843-ad74-f3fd24218955"
      },
      "source": [
        "idx = np.array(dtcacc).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Exactitud (Accuracy) promedio obtenida en la busqueda: \", dtcacc[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Maxima profundidad (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"min_samples_split: \", bestmodel.get_params()['min_samples_split'])\n",
        "print(\"min_samples_leaf: \", bestmodel.get_params()['min_samples_leaf'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de exactitudes obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=acca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Exactitud (Accuracy) promedio obtenida en la busqueda:  0.8299999999999998\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Maxima profundidad (max_depth):  32\n",
            "min_samples_split:  0.66\n",
            "min_samples_leaf:  0.15\n",
            "max_features:  sqrt\n",
            "\n",
            "Boxplot de exactitudes obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521d47db00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XoeAGvXGVUWz"
      },
      "source": [
        "####***B.3. Mejores hiperparametros según metrica de Precisión (precision)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZDm445_vVUW8"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Precisión (precision) para Positivo (clase positiva)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***precisiones (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WfxTYa33iBxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "37e00376-b350-4cba-9c41-b0a0e560d052"
      },
      "source": [
        "idx = np.array(dtcprep).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Precisión (precision) para Positivo (clase positiva) promedio obtenida en la busqueda: \", dtcprep[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Maxima profundidad (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"min_samples_split: \", bestmodel.get_params()['min_samples_split'])\n",
        "print(\"min_samples_leaf: \", bestmodel.get_params()['min_samples_leaf'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=prepa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Precisión (precision) para Positivo (clase positiva) promedio obtenida en la busqueda:  0.8366666666666667\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Maxima profundidad (max_depth):  32\n",
            "min_samples_split:  0.66\n",
            "min_samples_leaf:  0.15\n",
            "max_features:  sqrt\n",
            "\n",
            "Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521cc29e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8uwqOaw3VUXG"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Precisión (precision) para Negativo (clase negativa)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***precisiones (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rhBQ1AHZiBxx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "79e146b2-00af-4fd1-a54f-80a107894478"
      },
      "source": [
        "idx = np.array(dtcpren).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Precisión (precision) para Negativo (clase negativa) promedio obtenida en la busqueda: \", dtcpren[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Maxima profundidad (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"min_samples_split: \", bestmodel.get_params()['min_samples_split'])\n",
        "print(\"min_samples_leaf: \", bestmodel.get_params()['min_samples_leaf'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=prena)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Precisión (precision) para Negativo (clase negativa) promedio obtenida en la busqueda:  0.8333333333333333\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Maxima profundidad (max_depth):  32\n",
            "min_samples_split:  0.66\n",
            "min_samples_leaf:  0.15\n",
            "max_features:  sqrt\n",
            "\n",
            "Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521cbfb240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "li_qs4sCVUXL"
      },
      "source": [
        "####***B.4. Mejores hiperparametros según metrica de Recall***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8CAwdnuHVUXL"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***Recall para Positivo (clase positiva)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***recalls (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yj-i6gFFiBx5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "04f4e1ee-e841-49b8-cc15-e0146996e800"
      },
      "source": [
        "idx = np.array(dtcrecp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Recall para Positivo (clase positiva) promedio obtenido en la busqueda: \", dtcrecp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Maxima profundidad (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"min_samples_split: \", bestmodel.get_params()['min_samples_split'])\n",
        "print(\"min_samples_leaf: \", bestmodel.get_params()['min_samples_leaf'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=recpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Recall para Positivo (clase positiva) promedio obtenido en la busqueda:  0.96\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Maxima profundidad (max_depth):  32\n",
            "min_samples_split:  0.6\n",
            "min_samples_leaf:  0.01\n",
            "max_features:  sqrt\n",
            "\n",
            "Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521cbcd860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zo2K5N_UVUXS"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***Recall para Negativo (clase negativa)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***recalls (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l8R_cgXEiBx-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "41bcd9ae-bddf-41de-a44e-9a03da1f8389"
      },
      "source": [
        "idx = np.array(dtcrecn).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Recall para Negativo (clase negativa) promedio obtenido en la busqueda: \", dtcrecn[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Maxima profundidad (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"min_samples_split: \", bestmodel.get_params()['min_samples_split'])\n",
        "print(\"min_samples_leaf: \", bestmodel.get_params()['min_samples_leaf'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=recna)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Recall para Negativo (clase negativa) promedio obtenido en la busqueda:  0.83\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Maxima profundidad (max_depth):  31\n",
            "min_samples_split:  0.68\n",
            "min_samples_leaf:  0.15\n",
            "max_features:  sqrt\n",
            "\n",
            "Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521cb0ceb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Msph_GcLVUXX"
      },
      "source": [
        "####***B.5. Mejores hiperparametros según metrica de F1***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1BW4moaoVUXX"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***F1 para Positivo (clase positiva)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***f1s (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TC16fz7_iByC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "a3f49bb6-a4e5-4ccb-f1ab-0e2ebbd0e00b"
      },
      "source": [
        "idx = np.array(dtcf1p).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda: \", dtcf1p[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Maxima profundidad (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"min_samples_split: \", bestmodel.get_params()['min_samples_split'])\n",
        "print(\"min_samples_leaf: \", bestmodel.get_params()['min_samples_leaf'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda:  0.8426666666666667\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Maxima profundidad (max_depth):  32\n",
            "min_samples_split:  0.6\n",
            "min_samples_leaf:  0.01\n",
            "max_features:  sqrt\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521ca669b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y4FQa-wXVUXb"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***F1 para Negativo (clase negativa)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***f1s (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bh9Fx02PiByG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "c6d77e53-b837-479d-8ef1-4cc0dcc1c46c"
      },
      "source": [
        "idx = np.array(dtcf1n).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor F1 para Negativo (clase negativa) promedio obtenido en la busqueda: \", dtcf1n[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Maxima profundidad (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"min_samples_split: \", bestmodel.get_params()['min_samples_split'])\n",
        "print(\"min_samples_leaf: \", bestmodel.get_params()['min_samples_leaf'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=f1na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor F1 para Negativo (clase negativa) promedio obtenido en la busqueda:  0.7959999999999998\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Maxima profundidad (max_depth):  36\n",
            "min_samples_split:  0.6\n",
            "min_samples_leaf:  0.13\n",
            "max_features:  sqrt\n",
            "\n",
            "Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521ca3ff60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANkklEQVR4nO3db2id53mA8Us6Uf40dpxMlSH2FKes1T3GkoEWL4SmLSXNFvJlZW3WqWWGDQLeB4duDDoKKaFh0LB+ClWxm47htotWmpUUhrfCQlmXQFnH7PXPltte6liOncwHLVbtBQf5SPugN+NUlqX3SCd+j59ePwjSefRYugnJpdeP3qMztLS0hCSpPMNNDyBJensYeEkqlIGXpEIZeEkqlIGXpEJd0/QAleuA3cCrQKfhWSTpatECbgW+D7y58oODEvjdwD83PYQkXaXeBzy/cnFQAv8qwOuv/y+Li96XL0l1DA8PccstN0LV0JUGJfAdgMXFJQMvSb1b9WjbH7JKUqEMvCQVysBLUqHWPYOPiM8DHwFuB+7IzB+tsqcFPAk8ACwBn8vML/d3VElSL+pcwT8LvB84scaeTwDvBt4D3AM8FhG3b3o6SdKGrRv4zHw+M0+us+1jwFOZuZiZbZa/KTzUjwElSRvTr9skb+Nnr/BngfE+fe4r5umnv8LJk2v9ReXnx/z8Webn55seQwNm27ZtbNt2c9NjDITx8V18/ON7mh5jTYNyHzwAo6NbGv36r732Cnnsv2hd73/AixcvsHRxoekxNGAu/M952j+92PQYjetcOMvISIuxsa1Nj7KmfgV+FtjF8u9DgEuv6GuZmzvf6BOdFhY6tK6/mXfsuq+xGSQNvjdOPMfCQod2+1yjcwwPD615YdyvwH8DeDgivgmMAh9m+XcjSJIasu4PWSPiyYh4BfhF4B8j4sfV+qGIuKva9lXgJ8Ax4HvAZzPz+Ns0sySphnWv4DPzEeCRVdYf7Hq/A/xRf0eTJG2Gz2SVpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEJdU2dTREwAB4FRYA7Yk5nHVuzZDvwVMA6MAN8BHsnMi32dWJJUS90r+P3AdGZOANPAgVX2fBr4z8y8E7gT+HXgd/oypSSpZ+sGvroynwRmqqUZYDIixlZsXQK2RsQwcB1wLXCqj7NKknpQ54hmHDiVmR2AzOxExOlqvd2173Hgb4FXgRuBL2TmC70MMzq6pZftfTcy0mr060u6eoyMtBgb29r0GGuqdQZf00PAD4D7gK3A30fERzPzmbqfYG7uPIuLS30cqTcLC53Gvrakq8vCQod2+1yjMwwPD615YVznDP4ksDMiWgDV2x3Verd9wF9n5mJmzgPfAj64oaklSZu2buAz8wxwBJiqlqaAw5nZXrH1OPAAQERcC3wI+FH/RpUk9aLuXTR7gX0RcZTlK/W9ABFxKCLuqvZ8EnhfRPyQ5W8IR4Gn+jyvJKmmWmfwmfkicPcq6w92vf8ScH//RpMkbYbPZJWkQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSpUrRfd/nkxP3+WzoWzvHHiuaZHkTTAOhfOMj8/+Pn0Cl6SCjX434KuoG3bbqb904u8Y9d9TY8iaYC9ceI5tm27uekx1uUVvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVqtZ98BExARwERoE5YE9mHltl3+8CjwJDwBLwocz87/6NK0mqq+4V/H5gOjMngGngwMoNEXEX8Bhwf2b+KnAvMN+nOSVJPVo38BGxHZgEZqqlGWAyIsZWbP1j4POZ+RpAZs5n5oV+DitJqq/OEc04cCozOwCZ2YmI09V6u2vfrwDHI+K7wBbgm8CfZ+ZSn2eWJNXQz99F0wLuBO4HrgX+AZgFvlL3E4yObunjOL0bGWk1+vUlXT1GRlqMjW1teow11Qn8SWBnRLSqq/cWsKNa7zYLPJOZbwJvRsS3gN+gh8DPzZ1ncbG5C/6FhU5jX1vS1WVhoUO7fa7RGYaHh9a8MF73DD4zzwBHgKlqaQo4nJntFVufBn4zIoYiYgS4D/j3DU0tSdq0unfR7AX2RcRRYF/1mIg4VN09A/A3wBngP1j+hvBj4C/7O64kqa5aZ/CZ+SJw9yrrD3a9vwj8SfWPJKlhPpNVkgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUP18yb4idC6c5Y0TzzU9hgbE4sXl140fvub6hifRIOlcOAu8s+kx1mXgu4yP72p6BA2Y2dkTANw2Pvj/M+tKeudV0YuhpaXmXgO1y+3A8aZfk1Va6YknHgfgU596tOFJpEt1vSbru4CXL/n4lR5IknRlGHhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKlSt3wcfERPAQWAUmAP2ZOaxy+wN4DDwxcz8034NKknqTd0r+P3AdGZOANPAgdU2RUSr+tiz/RlPkrRR6wY+IrYDk8BMtTQDTEbE2Crb/wz4O+Bo3yaUJG1InSOaceBUZnYAMrMTEaer9fZbmyLi14DfAj4IbOjlb6pXJpEGxshIC4Cxsa0NTyL1ri+vyRoRI8CXgD+ovgFs6PP4kn0aNAsLHQDa7XMNTyJdqusl+1b/eI3PcRLYWZ2vv3XOvqNaf8utwC8BhyLiZeCTwMMR8aWNjS1J2qx1r+Az80xEHAGmgK9Vbw9nZrtrzyzw/y87HxGPAVu8i0aSmlP3Lpq9wL6IOArsqx4TEYci4q63azhJ0sbVOoPPzBeBu1dZf/Ay+x/b3FiSpM3ymaySVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFuqbOpoiYAA4Co8AcsCczj63Y8yjwe0AHWAA+nZnf7u+4kqS66l7B7wemM3MCmAYOrLLnX4DdmXkn8IfA1yPihv6MKUnq1bqBj4jtwCQwUy3NAJMRMda9LzO/nZlvVA9/AAyxfMUvSWpAnSv4ceBUZnYAqrenq/XL2QO8lJmvbH5ESdJG1DqD70VEfAB4HLi/1z87Orql3+NImzIy0gJgbGxrw5NIvasT+JPAzohoZWYnIlrAjmr9Z0TEPcDXgN/OzOx1mLm58ywuLvX6x6S3zcJCB4B2+1zDk0iXGh4eWvPCeN0jmsw8AxwBpqqlKeBwZra790XEbuDrwEcz8982PLEkqS/qHtHsBQ5GxGeA11k+YyciDgGfycx/Bb4I3AAciIi3/tzvZ+YP+zuyJKmOWoHPzBeBu1dZf7Dr/d19nEuStEk+k1WSCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCnVNnU0RMQEcBEaBOWBPZh5bsacFPAk8ACwBn8vML/d3XElSXXWv4PcD05k5AUwDB1bZ8wng3cB7gHuAxyLi9n4MKUnq3bpX8BGxHZgE7q+WZoAvRMRYZra7tn4MeCozF4F2RDwLPAT8RZ9n1hXwwgvf5fnn/6npMRo3O3sCgCeeeLzhSQbDvfd+gPe+9/1Nj6Ga6hzRjAOnMrMDkJmdiDhdrXcH/jbgRNfj2WpPbaOjW3rZrrfRTTfdwMhIq+kxGjc6+gsA/ruo3HTTDYyNbW16DNVU6wz+SpmbO8/i4lLTYwi4447d3HHH7qbH0ABqt881PYIqw8NDa14Y1zmDPwnsrH6I+tYPU3dU691mgV1dj29bZY8k6QpZN/CZeQY4AkxVS1PA4RXn7wDfAB6OiOGIGAM+DDzTz2ElSfXVvYtmL7AvIo4C+6rHRMShiLir2vNV4CfAMeB7wGcz83if55Uk1TS0tDQQZ963A8c9g5ek+rrO4N8FvHzJx6/0QJKkK8PAS1KhDLwkFWpQ7oNvwfJ5kiSpnq5mrvpMvEEJ/K0At9xyY9NzSNLV6FbgpZWLg3IXzXXAbuBVoNPwLJJ0tWixHPfvA2+u/OCgBF6S1Gf+kFWSCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCjUoz2SVBlJETAAHgVFgDtiTmceanUqqxyt4aW37genMnACmgQMNzyPVZuCly4iI7cAkMFMtzQCT1UtSSgPPwEuXNw6cyswOQPX2dLUuDTwDL0mFMvDS5Z0EdkZEC6B6u6NalwaegZcuIzPPAEeAqWppCjicme3mppLq89cFS2uIiF9m+TbJW4DXWb5NMpudSqrHwEtSoTyikaRCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKtT/AfHfDCi8ZGaMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WvRSoS3gVUXh"
      },
      "source": [
        "####***B.6. Mejores hiperparametros según metrica de Área bajo la curva ROC (AUC)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gem3_TUvVUXi"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Área bajo la curva ROC (AUC)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***AUCs*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "10tgItyliByM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "46f6e3b2-6fe9-4fa6-b84c-fcdcbb1dd0fe"
      },
      "source": [
        "idx = np.array(dtcauc).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor AUC promedio obtenido en la busqueda: \", dtcauc[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Maxima profundidad (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"min_samples_split: \", bestmodel.get_params()['min_samples_split'])\n",
        "print(\"min_samples_leaf: \", bestmodel.get_params()['min_samples_leaf'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de AUCs obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=auca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor AUC promedio obtenido en la busqueda:  0.855\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Maxima profundidad (max_depth):  22\n",
            "min_samples_split:  0.5\n",
            "min_samples_leaf:  0.05\n",
            "max_features:  log2\n",
            "\n",
            "Boxplot de AUCs obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521ca1beb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANkklEQVR4nO3db2id53mA8Us6Vv40dpxMlSH2FKes1T3GkoEWL4SmLSXNFvJlZWvWqWWGDQLeB4duDDoKKaFh0LB+ClWxm47htotWmpUWirfCwliXQFnH7PXPltte6liOncwHLVbtBQf5SPugN+NUlqX3SCd+j59dPwjSefRYugnJpdeP3qMztLS0hCSpPMNNDyBJensYeEkqlIGXpEIZeEkqlIGXpEJtaXqAyvXAHuBVoNPwLJJ0rWgBtwHfB95c+cFBCfwe4J+aHkKSrlHvA55fuTgogX8V4PXX/4fFRe/Ll6Q6hoeHuPXWm6Bq6EqDEvgOwOLikoGXpN6terTtD1klqVAGXpIKZeAlqVDrnsFHxOeA3wbuAO7MzB+tsqcFPAU8CCwBn83ML/V3VElSL+pcwX8TeD9wco09HwfeDbwHuBd4PCLu2PR0kqQNWzfwmfl8Zp5aZ9tHgaczczEz2yx/U3i4HwNKkjamX7dJ3s7PXuHPAuN9+txXzTPPfJlTp9b6i8r/H/Pz55ifn296DA2Y7du3s337LU2PMRDGx3fzsY/tbXqMNQ3KffAAjI5ubfTrv/baK+Tx/6R1g/8BL166yNKlhabH0IC5+N8XaP/0UtNjNK5z8RwjIy3GxrY1Pcqa+hX4WWA3y78PAS6/oq9lbu5Co090Wljo0LrhFt6x+/7GZpA0+N44+RwLCx3a7fONzjE8PLTmhXG/Av914JGI+AYwCnyY5d+NIElqyLo/ZI2IpyLiFeDngb+PiB9X64cj4u5q21eAnwDHge8Bn8nME2/TzJKkGta9gs/MR4FHV1l/qOv9DvCH/R1NkrQZPpNVkgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgpl4CWpUAZekgq1pc6miJgADgGjwBywNzOPr9izA/hLYBwYAf4BeDQzL/V1YklSLXWv4A8A05k5AUwDB1fZ8yngPzLzLuAu4FeB3+rLlJKknq0b+OrKfBKYqZZmgMmIGFuxdQnYFhHDwPXAdcDpPs4qSepBnSOaceB0ZnYAMrMTEWeq9XbXvieAvwFeBW4CPp+ZL/QyzOjo1l62993ISKvRry/p2jEy0mJsbFvTY6yp1hl8TQ8DPwDuB7YBfxsRH8nMZ+t+grm5CywuLvVxpN4sLHQa+9qSri0LCx3a7fONzjA8PLTmhXGdM/hTwK6IaAFUb3dW6932A3+VmYuZOQ98C/jghqaWJG3auoHPzLPAUWCqWpoCjmRme8XWE8CDABFxHfAh4Ef9G1WS1Iu6d9HsA/ZHxDGWr9T3AUTE4Yi4u9rzCeB9EfFDlr8hHAOe7vO8kqSaap3BZ+aLwD2rrD/U9f5LwAP9G02StBk+k1WSCmXgJalQBl6SCtXP++CvefPz5+hcPMcbJ59rehRJA6xz8Rzz84OfT6/gJalQg/8t6Cravv0W2j+9xDt239/0KJIG2Bsnn2P79luaHmNdXsFLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVakudTRExARwCRoE5YG9mHl9l3+8AjwFDwBLwocz8r/6NK0mqq+4V/AFgOjMngGng4MoNEXE38DjwQGb+MnAfMN+nOSVJPVo38BGxA5gEZqqlGWAyIsZWbP0j4HOZ+RpAZs5n5sV+DitJqq/OEc04cDozOwCZ2YmIM9V6u2vfLwEnIuK7wFbgG8CfZeZSn2eWJNVQ6wy+phZwF/AAcB3wd8As8OW6n2B0dGsfx+ndyEir0a8v6doxMtJibGxb02OsqU7gTwG7IqJVXb23gJ3VerdZ4NnMfBN4MyK+BfwaPQR+bu4Ci4vNXfAvLHQa+9qSri0LCx3a7fONzjA8PLTmhfG6Z/CZeRY4CkxVS1PAkcxsr9j6DPDrETEUESPA/cC/bWhqSdKm1b2LZh+wPyKOAfurx0TE4eruGYC/Bs4C/87yN4QfA3/R33ElSXXVOoPPzBeBe1ZZf6jr/UXgj6t/JEkN85msklQoAy9JhTLwklQoAy9JhTLwklQoAy9JhTLwklQoAy9JhTLwklQoAy9JhTLwklQoAy9JhTLwklQoAy9JhernS/YVoXPxHG+cfK7pMTQgFi8tv2788JYbGp5Eg6Rz8RzwzqbHWJeB7zI+vrvpETRgZmdPAnD7+OD/z6yr6Z3XRC+Glpaaew3ULncAJ5p+TVZppSeffAKAT37ysYYnkS7X9Zqs7wJevuzjV3sgSdLVYeAlqVAGXpIKZeAlqVAGXpIKZeAlqVAGXpIKZeAlqVAGXpIKZeAlqVAGXpIKZeAlqVAGXpIKZeAlqVC1fh98REwAh4BRYA7Ym5nHr7A3gCPAFzLzT/o1qCSpN3Wv4A8A05k5AUwDB1fbFBGt6mPf7M94kqSNWjfwEbEDmARmqqUZYDIixlbZ/qfAt4FjfZtQkrQhdY5oxoHTmdkByMxORJyp1ttvbYqIXwF+A/ggsKGXv6lemUQaGCMjLQDGxrY1PInUu768JmtEjABfBH6/+gawoc/jS/Zp0CwsdABot883PIl0ua6X7Fv94zU+xylgV3W+/tY5+85q/S23Ab8AHI6Il4FPAI9ExBc3NrYkabPWvYLPzLMRcRSYAr5avT2Sme2uPbPA/73sfEQ8Dmz1LhpJak7du2j2Afsj4hiwv3pMRByOiLvfruEkSRtX6ww+M18E7lll/aEr7H98c2NJkjbLZ7JKUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVakudTRExARwCRoE5YG9mHl+x5zHgd4EOsAB8KjO/099xJUl11b2CPwBMZ+YEMA0cXGXPPwN7MvMu4A+Ar0XEjf0ZU5LUq3UDHxE7gElgplqaASYjYqx7X2Z+JzPfqB7+ABhi+YpfktSAOlfw48DpzOwAVG/PVOtXshd4KTNf2fyIkqSNqHUG34uI+ADwBPBAr392dHRrv8eRNmVkpAXA2Ni2hieRelcn8KeAXRHRysxORLSAndX6z4iIe4GvAr+ZmdnrMHNzF1hcXOr1j0lvm4WFDgDt9vmGJ5EuNzw8tOaF8bpHNJl5FjgKTFVLU8CRzGx374uIPcDXgI9k5r9ueGJJUl/UPaLZBxyKiE8Dr7N8xk5EHAY+nZn/AnwBuBE4GBFv/bnfy8wf9ndkSVIdtQKfmS8C96yy/lDX+3v6OJckaZN8JqskFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFWpLnU0RMQEcAkaBOWBvZh5fsacFPAU8CCwBn83ML/V3XElSXXWv4A8A05k5AUwDB1fZ83Hg3cB7gHuBxyPijn4MKUnq3bpX8BGxA5gEHqiWZoDPR8RYZra7tn4UeDozF4F2RHwTeBj48z7PrKvghRe+y/PP/2PTYzRudvYkAE8++UTDkwyG++77AO997/ubHkM11TmiGQdOZ2YHIDM7EXGmWu8O/O3Aya7Hs9We2kZHt/ayXW+jm2++kZGRVtNjNG509OcA/HdRufnmGxkb29b0GKqp1hn81TI3d4HFxaWmxxBw5517uPPOPU2PoQHUbp9vegRVhoeH1rwwrnMGfwrYVf0Q9a0fpu6s1rvNAru7Ht++yh5J0lWybuAz8yxwFJiqlqaAIyvO3wG+DjwSEcMRMQZ8GHi2n8NKkuqrexfNPmB/RBwD9lePiYjDEXF3tecrwE+A48D3gM9k5ok+zytJqmloaWkgzrzvAE54Bi9J9XWdwb8LePmyj1/tgSRJV4eBl6RCGXhJKtSg3AffguXzJElSPV3NXPWZeIMS+NsAbr31pqbnkKRr0W3ASysXB+UumuuBPcCrQKfhWSTpWtFiOe7fB95c+cFBCbwkqc/8IaskFcrAS1KhDLwkFcrAS1KhDLwkFcrAS1KhDLwkFWpQnskqDaSImAAOAaPAHLA3M483O5VUj1fw0toOANOZOQFMAwcbnkeqzcBLVxARO4BJYKZamgEmq5eklAaegZeubBw4nZkdgOrtmWpdGngGXpIKZeClKzsF7IqIFkD1dme1Lg08Ay9dQWaeBY4CU9XSFHAkM9vNTSXV568LltYQEb/I8m2StwKvs3ybZDY7lVSPgZekQnlEI0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVKj/BR1jDCj0+hg2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ARhJwD2YYZD",
        "colab_type": "text"
      },
      "source": [
        "####***B.7. Comparación y Síntesis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaD1k9y6Ri-Q",
        "colab_type": "text"
      },
      "source": [
        "En esta parte, se procedera a realizar la síntesis o resumen de los resultados obtenidos. Se empleara una comparación entre los mismos, con el objetivo de formular conclusiones apropiadas. La evaluación se desarrolla en base a distintas metricas. Entre ellas, cabe mencionar ***Exactitud, Precisión, Recall, F1 y Área bajo la curva ROC (AUC)***. Asimismo, tambien se usa el ***Promedio de métricas***, el cual constituye el promedio de los valores de todas las metricas mencionadas. Dicho promedio fue planteado con el objetivo de considerar la maximización de todas las metricas en la busqueda de los mejores hiperparametros. En la siguiente tabla, se presentan los ***hiperparametros*** que maximizan los valores de cada metrica. En ese sentido, ello permite identificar los mejores ***hiperparametros*** en base a que medida se desee optimizar. \n",
        "\n",
        "![alt text](https://i.ibb.co/m451XKs/dtctab.png)\n",
        "\n",
        "De acuerdo a lo observado en la tabla anterior, es posible concluir que el mejor valor para el ***hiperparametro Maxima profundidad*** es ***32***, ya que este logro ser el mejor para la mayoria de metricas consideradas. Asimismo, respecto a ***min samples split***, no hay un valor mayoritario como en el caso anterior. No obstante, en este tipo de casos, es importante elegir un metrica para basarse en ella y analizar lo obtenido respecto a ***boxplots*** y otros elementos estadisticos. En este caso, se selecciona ***F1*** como metrica de mayor relevancia. El ***Boxplot*** de ***F1*** para ***Positivo***, es decir para la clase positiva, posee sus valores distribuidos en valores altos, con una mediana de ***0.8*** y presencia de ***outliers*** en ***0.0***. Igualmente, el ***Boxplot*** de ***F1*** para ***Negativo***, es decir para la clase negativa, tambien posee sus valores distribuidos en valores relativamente altos, si bien presenta su limite inferior en ***0.0***. Considerando la información dada anteriormente, se concluye que ***F1***, en este caso, es un metrica de decisión apropiada. ***0.6*** logro ser el mejor valor para el ***hiperparametro min samples split***, en el caso de ***F1*** para ***Positivo*** y ***F1*** para ***Negativo***. Asimismo, para los ***hiperparametros min samples leaf*** y ***max features***, se logra determinar ***0.15*** y ***Raíz*** como los mejores valores respectivamente, ya que estos funcionan mejor para la mayoria de metricas consideradas. Por lo tanto, se concluye que los ***hiperparametros*** que logran maximizar las metricas de forma conjunta y funcionan mejor con los datos son:\n",
        "\n",
        "* ***Maxima profundidad (max_depth): 32***\n",
        "* ***min_samples_split: 0.6***\n",
        "* ***min_samples_leaf: 0.15***\n",
        "* ***max_features: Raíz (sqrt)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WbHpD8-5GwnH"
      },
      "source": [
        "###***C. Random Forest***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gTIMiWl0GwnN"
      },
      "source": [
        "Se procedera a realizar el ajuste de hiperparametros para ***Random Forest*** con el conjunto de datos dado. Con respecto a dicho ajuste, nos enfocaremos en ***4 hiperparametros*** principalmente, los cuales son ***Numero de estimadores (n_estimators), Profundidad maxima (max_depth), max_features y bootstrap***. Estos seran ajustados, ya que son considerados los más importantes. Se tratara de buscar la combinación de estos ***hiperparametros*** que maximize la performance de clasficación. Se aplicara ***cross-validation estratificado con K=10*** para el muestreo. La evaluación de cada combinación de ***hiperparametros*** se realizá con la función ***test_model***. Llegados a este punto, se procedera a describir a los ***hiperparametros***:\n",
        "\n",
        "* ***Numero de estimadores (n_estimators): El número de árboles en el bosque.***\n",
        "\n",
        "* ***Profundidad maxima (max_depth): Número máximo de niveles en cada árbol de decisión.***\n",
        "\n",
        "* ***max_features: Número máximo de características consideradas para dividir un nodo. Entre los posibles valores a considerar, tenemos Automatico (auto), Raíz (sqrt) y Logaritmo (log2).***\n",
        "\n",
        "* ***bootstrap: Si las muestras de bootstrap se usan al construir árboles. Este hiperparametro puede tomar el valor de Verdadero (True) o Falso (False). Si es falso, todo el conjunto de datos se usa para construir cada árbol.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEVJjf_O5DN2",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, respecto a la busqueda de los mejores hiperparametros, no se estan evaluando todas las posibilidades. En este caso, lo que se propone es primero realizar una búsqueda general rápida, con el objetivo de ubicar, aproximadamente, el rango en el que se podría encontrar el ***hiperparametro*** óptimo. Una vez ubicado dicho rango, proceder con una búsqueda exhaustiva. Además, se almacena el ***promedio de las metricas*** obtenidas, por cada combinación de ***hiperparametros*** evaluada, en un arreglo. Con dicho promedio, se logra considerar la optimización de todas las metricas en la busqueda de los ***hiperparametros***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iswCdJRaGwnP",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "\n",
        "#Hiperparametros:\n",
        "nestims = [10, 50, 100, 200]\n",
        "mdepts = [5, 10, 30, 50, 100]\n",
        "mfeats = ['auto', 'sqrt', 'log2']\n",
        "boots = [True, False]\n",
        "\n",
        "rfcallp = [] #Arreglo para guardar el promedio de todas las metricas\n",
        "rfcmods = [] #Arreglo para guardar los modelos ajustados\n",
        "\n",
        "for ne in nestims: #Busqueda de hiperparametros\n",
        "  for md in mdepts:\n",
        "    for mf in mfeats:\n",
        "      for b in boots:\n",
        "        rfc = RFC(n_estimators=ne, max_depth=md, max_features=mf, bootstrap=b)\n",
        "        acc, prep, recp, f1p, pren, recn, f1n, auc = test_model(rfc, df, 50)\n",
        "        rfcallp.append((acc+prep+recp+f1p+pren+recn+f1n+auc)/8)\n",
        "        rfcmods.append(rfc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYQya4kP5df3",
        "colab_type": "text"
      },
      "source": [
        "Con la evaluación ***test_model***, se consideran una serie de metricas, las cuales son promediadas y almacenadas durante la busqueda. En el siguiente codigo, se indica el máximo ***promedio de metricas*** obtenido en la busqueda. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho promedio. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tVRcUjk0GwnX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1a50ba48-cba9-472b-953d-c46b9aa0c89d"
      },
      "source": [
        "idx = np.array(rfcallp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = rfcmods[idx]\n",
        "print(\"Mejor promedio de metricas obtenido en la busqueda: \", rfcallp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de estimadores (n_estimators): \", bestmodel.get_params()['n_estimators'])\n",
        "print(\"Profundidad maxima (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "print(\"bootstrap: \", bestmodel.get_params()['bootstrap'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor promedio de metricas obtenido en la busqueda:  0.7953541666666667\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de estimadores (n_estimators):  10\n",
            "Profundidad maxima (max_depth):  5\n",
            "max_features:  auto\n",
            "bootstrap:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAM3z1zG5xW7",
        "colab_type": "text"
      },
      "source": [
        "De acuerdo a lo obtenido anteriormente, con respecto al ***Numero de estimadores (n_estimators)***, se logra identificar que el mejor valor para dicho ***hiperparametro*** es cercano a ***10***. En ese sentido, se reducirá el rango a **[5, 15]**. Asimismo, el valor optimo para ***Profundidad maxima (max_depth)*** se aproxima a ***5***, por lo que se reducirá el rango a **[2,11]**. Continuando con el asunto, se procedera a realizar una busqueda exhaustiva. Cabe mencionar que se almacenan las metricas obtenidas y el promedio de dichas metricas, por cada combinación de ***hiperparametros*** evaluada, en arreglos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YdH51HGIGwne",
        "colab": {}
      },
      "source": [
        "#Hiperparametros:\n",
        "nestims = [i for i in range(5, 15)]\n",
        "mdepts = [i for i in range(2, 11)]\n",
        "mfeats = ['auto', 'sqrt', 'log2']\n",
        "boots = [True, False]\n",
        "\n",
        "rfcacc = [] #Arreglo para guardar exactitudes\n",
        "rfcprep = [] #Arreglo para guardar precisiones positivas\n",
        "rfcrecp = [] #Arreglo para guardar recalls positivos\n",
        "rfcf1p = [] #Arreglo para guardar F1s positivos\n",
        "rfcpren = [] #Arreglo para guardar precisiones negativas\n",
        "rfcrecn = [] #Arreglo para guardar recalls negativos\n",
        "rfcf1n = [] #Arreglo para guardar F1s negativos\n",
        "rfcauc = [] #Arreglo para guardar AUCs\n",
        "rfcallp = [] #Arreglo para guardar el promedio de todas las metricas\n",
        "rfcmods = [] #Arreglo para guardar los modelos ajustados\n",
        "\n",
        "for ne in nestims: #Busqueda de hiperparametros\n",
        "  for md in mdepts:\n",
        "    for mf in mfeats:\n",
        "      for b in boots:\n",
        "        rfc = RFC(n_estimators=ne, max_depth=md, max_features=mf, bootstrap=b)\n",
        "        acc, prep, recp, f1p, pren, recn, f1n, auc = test_model(rfc, df, 50)\n",
        "        rfcacc.append(acc)\n",
        "        rfcprep.append(prep)\n",
        "        rfcrecp.append(recp)\n",
        "        rfcf1p.append(f1p)\n",
        "        rfcpren.append(pren)\n",
        "        rfcrecn.append(recn)\n",
        "        rfcf1n.append(f1n)\n",
        "        rfcauc.append(auc)\n",
        "        rfcallp.append((acc+prep+recp+f1p+pren+recn+f1n+auc)/8)\n",
        "        rfcmods.append(rfc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pb_L4EPwGwni"
      },
      "source": [
        "####***C.1. Mejores hiperparametros según Promedio de métricas***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_M0TCv26OC9",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***promedio de metricas*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho promedio. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qvYtMKEuGwni",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2f9e55d8-9f83-4c10-c1a8-567661560901"
      },
      "source": [
        "idx = np.array(rfcallp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = rfcmods[idx]\n",
        "print(\"Mejor promedio de metricas obtenido en la busqueda: \", rfcallp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de estimadores (n_estimators): \", bestmodel.get_params()['n_estimators'])\n",
        "print(\"Profundidad maxima (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "print(\"bootstrap: \", bestmodel.get_params()['bootstrap'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor promedio de metricas obtenido en la busqueda:  0.8035625\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de estimadores (n_estimators):  6\n",
            "Profundidad maxima (max_depth):  2\n",
            "max_features:  log2\n",
            "bootstrap:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvhvj_ft6Z3N",
        "colab_type": "text"
      },
      "source": [
        "Ahora bien, considerando el promedio de todas las metricas evaluadas, se logra definir los ***hiperparametros*** señalados anteriormente como los mejores. No obstante, ello puede cambiar si se analiza desde la perspectiva de cada metrica. Por lo tanto, se procedera a indicar el maximo valor obtenido de cada metrica, durante la busqueda, y los ***hiperparametros*** que permiten alcanzar dicho valor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HkuEkR6B7SIH"
      },
      "source": [
        "####***C.2. Mejores hiperparametros según metrica de Exactitud (Accuracy)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OUUBwfE17SIK"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Exactitud (Accuracy)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***exactitudes*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u0UxYzQ3Gwnn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "b804e1b4-0a66-4b39-99d0-df3e09a53acd"
      },
      "source": [
        "idx = np.array(rfcacc).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = rfcmods[idx]\n",
        "print(\"Mejor Exactitud (Accuracy) promedio obtenida en la busqueda: \", rfcacc[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de estimadores (n_estimators): \", bestmodel.get_params()['n_estimators'])\n",
        "print(\"Profundidad maxima (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "print(\"bootstrap: \", bestmodel.get_params()['bootstrap'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de exactitudes obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=acca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Exactitud (Accuracy) promedio obtenida en la busqueda:  0.815\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de estimadores (n_estimators):  12\n",
            "Profundidad maxima (max_depth):  9\n",
            "max_features:  sqrt\n",
            "bootstrap:  True\n",
            "\n",
            "Boxplot de exactitudes obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521c246c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZomLrM0x7SIT"
      },
      "source": [
        "####***C.3. Mejores hiperparametros según metrica de Precisión (precision)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mkxiy-ue7SIT"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Precisión (precision) para Positivo (clase positiva)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***precisiones (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gf48q9eTGwnu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "911a4e2e-c58c-4a32-ee49-c8d6b11a6b68"
      },
      "source": [
        "idx = np.array(rfcprep).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = rfcmods[idx]\n",
        "print(\"Mejor Precisión (precision) para Positivo (clase positiva) promedio obtenida en la busqueda: \", rfcprep[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de estimadores (n_estimators): \", bestmodel.get_params()['n_estimators'])\n",
        "print(\"Profundidad maxima (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "print(\"bootstrap: \", bestmodel.get_params()['bootstrap'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=prepa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Precisión (precision) para Positivo (clase positiva) promedio obtenida en la busqueda:  0.8066666666666668\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de estimadores (n_estimators):  10\n",
            "Profundidad maxima (max_depth):  2\n",
            "max_features:  sqrt\n",
            "bootstrap:  True\n",
            "\n",
            "Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521c2957b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2wOrtU_D7SIY"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Precisión (precision) para Negativo (clase negativa)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***precisiones (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z6yBh-_RGwny",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "70b8cf5a-e8ec-409c-93dd-59f7b30ca74d"
      },
      "source": [
        "idx = np.array(rfcpren).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = rfcmods[idx]\n",
        "print(\"Mejor Precisión (precision) para Negativo (clase negativa) promedio obtenida en la busqueda: \", rfcpren[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de estimadores (n_estimators): \", bestmodel.get_params()['n_estimators'])\n",
        "print(\"Profundidad maxima (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "print(\"bootstrap: \", bestmodel.get_params()['bootstrap'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=prena)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Precisión (precision) para Negativo (clase negativa) promedio obtenida en la busqueda:  0.7833333333333333\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de estimadores (n_estimators):  6\n",
            "Profundidad maxima (max_depth):  2\n",
            "max_features:  log2\n",
            "bootstrap:  True\n",
            "\n",
            "Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521c365080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ov-zaDVW7SIe"
      },
      "source": [
        "####***C.4. Mejores hiperparametros según metrica de Recall***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DVaU2mCy7SIf"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***Recall para Positivo (clase positiva)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***recalls (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GTRU0dMZGwn2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "ddf1b4ef-ede0-49fc-f24a-07a088bde3e5"
      },
      "source": [
        "idx = np.array(rfcrecp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = rfcmods[idx]\n",
        "print(\"Mejor Recall para Positivo (clase positiva) promedio obtenido en la busqueda: \", rfcrecp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de estimadores (n_estimators): \", bestmodel.get_params()['n_estimators'])\n",
        "print(\"Profundidad maxima (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "print(\"bootstrap: \", bestmodel.get_params()['bootstrap'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=recpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Recall para Positivo (clase positiva) promedio obtenido en la busqueda:  0.97\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de estimadores (n_estimators):  11\n",
            "Profundidad maxima (max_depth):  8\n",
            "max_features:  auto\n",
            "bootstrap:  True\n",
            "\n",
            "Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521c2d3d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dToKGmGA7SIj"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***Recall para Negativo (clase negativa)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***recalls (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xr9EUJDMGwn5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "34583b16-9700-4f4a-9114-1643a62e0f94"
      },
      "source": [
        "idx = np.array(rfcrecn).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = rfcmods[idx]\n",
        "print(\"Mejor Recall para Negativo (clase negativa) promedio obtenido en la busqueda: \", rfcrecn[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de estimadores (n_estimators): \", bestmodel.get_params()['n_estimators'])\n",
        "print(\"Profundidad maxima (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "print(\"bootstrap: \", bestmodel.get_params()['bootstrap'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=recna)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Recall para Negativo (clase negativa) promedio obtenido en la busqueda:  0.72\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de estimadores (n_estimators):  5\n",
            "Profundidad maxima (max_depth):  2\n",
            "max_features:  auto\n",
            "bootstrap:  False\n",
            "\n",
            "Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521c404278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GRHwkLGB7SIo"
      },
      "source": [
        "####***C.5. Mejores hiperparametros según metrica de F1***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cIw3XKmz7SIo"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***F1 para Positivo (clase positiva)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***f1s (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jQuj6XMPGwn_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "f40c0120-ae38-4e2a-a15a-950e8297347d"
      },
      "source": [
        "idx = np.array(rfcf1p).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = rfcmods[idx]\n",
        "print(\"Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda: \", rfcf1p[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de estimadores (n_estimators): \", bestmodel.get_params()['n_estimators'])\n",
        "print(\"Profundidad maxima (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "print(\"bootstrap: \", bestmodel.get_params()['bootstrap'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda:  0.8519999999999999\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de estimadores (n_estimators):  5\n",
            "Profundidad maxima (max_depth):  6\n",
            "max_features:  log2\n",
            "bootstrap:  True\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521c4bcba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "msLK3DH87SIv"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***F1 para Negativo (clase negativa)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***f1s (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mfz3C8M6GwoC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "29ae4063-e112-4067-8cf5-97c0dfbc5238"
      },
      "source": [
        "idx = np.array(rfcf1n).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = rfcmods[idx]\n",
        "print(\"Mejor F1 para Negativo (clase negativa) promedio obtenido en la busqueda: \", rfcf1n[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de estimadores (n_estimators): \", bestmodel.get_params()['n_estimators'])\n",
        "print(\"Profundidad maxima (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "print(\"bootstrap: \", bestmodel.get_params()['bootstrap'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=f1na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor F1 para Negativo (clase negativa) promedio obtenido en la busqueda:  0.7260000000000001\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de estimadores (n_estimators):  6\n",
            "Profundidad maxima (max_depth):  2\n",
            "max_features:  log2\n",
            "bootstrap:  True\n",
            "\n",
            "Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521c1f7080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "09Ldhq5G7SIz"
      },
      "source": [
        "####***C.6. Mejores hiperparametros según metrica de Área bajo la curva ROC (AUC)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nJ5qZ6ec7SI0"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Área bajo la curva ROC (AUC)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***AUCs*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hsp1qAbSGwoI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "161d92aa-bb7b-483a-8368-08646aa2a2d7"
      },
      "source": [
        "idx = np.array(rfcauc).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = rfcmods[idx]\n",
        "print(\"Mejor AUC promedio obtenido en la busqueda: \", rfcauc[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"Numero de estimadores (n_estimators): \", bestmodel.get_params()['n_estimators'])\n",
        "print(\"Profundidad maxima (max_depth): \", bestmodel.get_params()['max_depth'])\n",
        "print(\"max_features: \", bestmodel.get_params()['max_features'])\n",
        "print(\"bootstrap: \", bestmodel.get_params()['bootstrap'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de AUCs obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=auca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor AUC promedio obtenido en la busqueda:  0.8825\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "Numero de estimadores (n_estimators):  10\n",
            "Profundidad maxima (max_depth):  8\n",
            "max_features:  auto\n",
            "bootstrap:  True\n",
            "\n",
            "Boxplot de AUCs obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f521c28c4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNu70OCv9RoH",
        "colab_type": "text"
      },
      "source": [
        "####***C.7. Comparación y Analisis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeCS4HH8JxQh",
        "colab_type": "text"
      },
      "source": [
        "En esta parte, se procedera a realizar la síntesis o resumen de los resultados obtenidos. Se empleara una comparación entre los mismos, con el objetivo de formular conclusiones apropiadas. La evaluación se desarrolla en base a distintas metricas. Entre ellas, cabe mencionar ***Exactitud, Precisión, Recall, F1 y Área bajo la curva ROC (AUC)***. Asimismo, tambien se usa el ***Promedio de métricas***, el cual constituye el promedio de los valores de todas las metricas mencionadas. Dicho promedio fue planteado con el objetivo de considerar la maximización de todas las metricas en la busqueda de los mejores hiperparametros. En la siguiente tabla, se presentan los ***hiperparametros*** que maximizan los valores de cada metrica. En ese sentido, ello permite identificar los mejores ***hiperparametros*** en base a que medida se desee optimizar. \n",
        "\n",
        "![alt text](https://i.ibb.co/vPtDN45/rftab.png)\n",
        "\n",
        "De acuerdo a lo observado en la tabla anterior, es posible concluir que el mejor valor para el ***hiperparametro bootstrap*** es ***True***, ya que este logro ser el mejor para la mayoria de metricas consideradas. Asimismo, respecto al ***Numero de estimadores*** y ***max features***, no hay un valor mayoritario como en el caso anterior. No obstante, en este tipo de casos, es importante elegir un metrica para basarse en ella y analizar lo obtenido respecto a ***boxplots*** y otros elementos estadisticos. En este caso, se selecciona ***F1*** como metrica de mayor relevancia. Tanto el ***Boxplot*** de ***F1*** para ***Positivo*** como el ***Boxplot*** de ***F1*** para ***Negativo***, es decir para la clase positiva y negativa respectivamente, poseen sus valores distribuidos en valores altos, con su limite inferior en ***0.5*** aproximadamente y presencia de ***outliers*** en ***0.0***. Considerando la información dada anteriormente, se concluye que ***F1***, en este caso, es una metrica de decisión apropiada. ***Logaritmo*** logro ser el mejor valor para el ***hiperparametro max features***, en el caso de ***F1*** para ***Positivo*** y ***F1*** para ***Negativo***. Ahora bien, ***F1*** para ***Positivo*** sera más prioritaria que ***F1*** para ***Negativo***, ya que se desea enfocar la optimización de desempeño en la clasificación de reseñas ***positivas***. En consecuencia, el mejor valor para ***Numero de estimadores*** es ***5***, ya que funciona mejor con ***F1*** para ***Positivo***. Además, para el ***hiperparametro Profundidad maxima***, se logra determinar ***2*** como el mejor valor, ya que este funciona mejor para la mayoria de metricas consideradas. Por lo tanto, se concluye que los ***hiperparametros*** que logran maximizar las metricas de forma conjunta y funcionan mejor con los datos son:\n",
        "\n",
        "* ***Numero de estimadores (n_estimators):  5***\n",
        "* ***Profundidad maxima (max_depth):  2***\n",
        "* ***max_features:  Logaritmo (log2)***\n",
        "* ***bootstrap:  True***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "012gNyou2GmL",
        "colab_type": "text"
      },
      "source": [
        "### ***D. Regresión Logistica (Logistic Regression)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C578Tdl2S3Td"
      },
      "source": [
        "Se procedera a realizar el ajuste de hiperparametros para ***Regresión Logistica (Logistic Regression)*** con el conjunto de datos dado. Con respecto a dicho ajuste, nos enfocaremos en ***3 hiperparametros*** principalmente, los cuales son ***C (parametro de regularización), class_weight y Solucionador (solver)***. Estos seran ajustados, ya que son considerados los más importantes. Se tratara de buscar la combinación de estos ***hiperparametros*** que maximize la performance de clasficación. Se aplicara ***cross-validation estratificado con K=50*** para el muestreo. La evaluación de cada combinación de ***hiperparametros*** se realizá con la función ***test_model***. Llegados a este punto, se procedera a describir a los ***hiperparametros***:\n",
        "\n",
        "* ***C: Parametro de regularización inverso de la fuerza de regularización; debe ser un valor positivo. Al igual que en las máquinas de vectores de soporte (SVM), los valores más pequeños especifican una regularización más fuerte.***\n",
        "\n",
        "* ***class_weight: Pesos asociados con clases. Si no se especifica, se supone que todas las clases tienen un peso uno. Entre los posibles valores que se pueden tomar, tenemos Ninguno (none) o Balanceado (balanced).***\n",
        "\n",
        "* ***Solucionador (solver): Indica el algoritmo a utilizar en el problema de optimización. El algoritmo puede ser newton-cg, lbfgs, liblinear, sag o saga.***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DKyw86342cgQ"
      },
      "source": [
        "En el siguiente codigo, respecto a la busqueda de los mejores hiperparametros, no se estan evaluando todas las posibilidades. En este caso, lo que se propone es primero realizar una búsqueda general rápida, con el objetivo de ubicar, aproximadamente, el rango en el que se podría encontrar el ***hiperparametro*** óptimo. Una vez ubicado dicho rango, proceder con una búsqueda exhaustiva. Además, se almacena el ***promedio de las metricas*** obtenidas, por cada combinación de ***hiperparametros*** evaluada, en un arreglo. Con dicho promedio, se logra considerar la optimización de todas las metricas en la busqueda de los ***hiperparametros***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icv5S6zz4M5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestlr = LR(C=245, class_weight='balanced', solver='liblinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgnwb_5o39BQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "outputId": "0d7b8d9b-fa8a-4f3f-bb73-a1808dff13a4"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "\n",
        "#Hiperparametros:\n",
        "C = [100, 200, 250, 300, 400]\n",
        "class_weight = ['balanced', None]\n",
        "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "\n",
        "dtcallp = [] #Arreglo para guardar el promedio de todas las metricas\n",
        "dtcmods = [] #Arreglo para guardar los modelos ajustados\n",
        "\n",
        "for c in C: #Busqueda de hiperparametros\n",
        "  for w in class_weight:\n",
        "    for s in solver:\n",
        "      bestlr = LR(C=c, class_weight=w, solver=s)\n",
        "      acc, prep, recp, f1p, pren, recn, f1n, auc = test_model(bestlr, df, 50)\n",
        "      dtcallp.append((acc+prep+recp+f1p+pren+recn+f1n+auc)/8)\n",
        "      dtcmods.append(bestlr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o9dZryN4M2cG"
      },
      "source": [
        "Con la evaluación ***test_model***, se consideran una serie de metricas, las cuales son promediadas y almacenadas durante la busqueda. En el siguiente codigo, se indica el máximo ***promedio de metricas*** obtenido en la busqueda. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho promedio. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IKA1PhF2Mxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "fe1eabcd-76ea-4da3-a8a7-6f10fe4de74a"
      },
      "source": [
        "idx = np.array(dtcallp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor promedio de metricas obtenido en la busqueda: \", dtcallp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"C (parametro de regularización): \", bestmodel.get_params()['C'])\n",
        "print(\"class_weight - Balanceado (balanced): \", bestmodel.get_params()['class_weight'])\n",
        "print(\"solver: \", bestmodel.get_params()['solver'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor promedio de metricas obtenido en la busqueda:  0.7885625\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "C (parametro de regularización):  100\n",
            "class_weight - Balanceado (balanced):  balanced\n",
            "solver:  newton-cg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h8Azhk1s2cgn"
      },
      "source": [
        "De acuerdo a lo obtenido anteriormente, con respecto a ***El parametro de regularización C***, se logra identificar que el mejor valor para dicho ***hiperparametro*** es cercano a ***100***. En ese sentido, se reducirá el rango a **[200, 300]** para estar seguro de obtener los mejores resultados. Para los hiperparametros ***class_weight*** y ***solver*** se usaran los arreglos con los mismos valores que en la prueba anterior. Continuando con el asunto, se procedera a realizar una busqueda exhaustiva. Cabe mencionar que se almacenan las metricas obtenidas y el promedio de dichas metricas, por cada combinación de ***hiperparametros*** evaluada, en arreglos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNox2JoC3vLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb83ec38-83d8-40a1-d7e0-c5f61c670d43"
      },
      "source": [
        "#Hiperparametros:\n",
        "C = [i for i in range(200,300)]\n",
        "class_weight = ['balanced', None]\n",
        "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "\n",
        "dtcacc = [] #Arreglo para guardar exactitudes\n",
        "dtcprep = [] #Arreglo para guardar precisiones positivas\n",
        "dtcrecp = [] #Arreglo para guardar recalls positivos\n",
        "dtcf1p = [] #Arreglo para guardar F1s positivos\n",
        "dtcpren = [] #Arreglo para guardar precisiones negativas\n",
        "dtcrecn = [] #Arreglo para guardar recalls negativos\n",
        "dtcf1n = [] #Arreglo para guardar F1s negativos\n",
        "dtcauc = [] #Arreglo para guardar AUCs\n",
        "dtcallp = [] #Arreglo para guardar el promedio de todas las metricas\n",
        "dtcmods = [] #Arreglo para guardar los modelos ajustados\n",
        "\n",
        "for c in C: #Busqueda de hiperparametros\n",
        "  for w in class_weight:\n",
        "    for s in solver:\n",
        "      bestlr = LR(C=c, class_weight=w, solver=s)\n",
        "      acc, prep, recp, f1p, pren, recn, f1n, auc = test_model(bestlr, df, 50)\n",
        "      dtcacc.append(acc)\n",
        "      dtcprep.append(prep)\n",
        "      dtcrecp.append(recp)\n",
        "      dtcf1p.append(f1p)\n",
        "      dtcpren.append(pren)\n",
        "      dtcrecn.append(recn)\n",
        "      dtcf1n.append(f1n)\n",
        "      dtcauc.append(auc)\n",
        "      dtcallp.append((acc+prep+recp+f1p+pren+recn+f1n+auc)/8)\n",
        "      dtcmods.append(bestlr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V2kqeprI7klz"
      },
      "source": [
        "####***D.1. Mejores hiperparametros según Promedio de métricas***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZMeIt-MU2cgu"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***promedio de metricas*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho promedio. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFPmHs4i9zb5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "45d4b544-a524-4e95-c289-17eab86489d5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "idx = np.array(dtcallp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor promedio de metricas obtenido en la busqueda: \", dtcallp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"C (parametro de regularización): \", bestmodel.get_params()['C'])\n",
        "print(\"class_weight: \", bestmodel.get_params()['class_weight'])\n",
        "print(\"solver: \", bestmodel.get_params()['solver'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor promedio de metricas obtenido en la busqueda:  0.7885625\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "C (parametro de regularización):  203\n",
            "class_weight:  balanced\n",
            "solver:  sag\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AjybYXuy2cgz"
      },
      "source": [
        "Ahora bien, considerando el promedio de todas las metricas evaluadas, se logra definir los ***hiperparametros*** señalados anteriormente como los mejores. No obstante, ello puede cambiar si se analiza desde la perspectiva de cada metrica. Por lo tanto, se procedera a indicar el maximo valor obtenido de cada metrica, durante la busqueda, y los ***hiperparametros*** que permiten alcanzar dicho valor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f9g9_yWA2cg1"
      },
      "source": [
        "####***D.2. Mejores hiperparametros según metrica de Exactitud (Accuracy)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6J5LUwM32cg1"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Exactitud (Accuracy)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***exactitudes*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A05SZg6_eza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "17b6372b-7e81-459d-c7ff-c95f1250a79b"
      },
      "source": [
        "idx = np.array(dtcacc).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Exactitud (Accuracy) promedio obtenida en la busqueda: \", dtcacc[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"C (parametro de regularización): \", bestmodel.get_params()['C'])\n",
        "print(\"class_weight: \", bestmodel.get_params()['class_weight'])\n",
        "print(\"solver: \", bestmodel.get_params()['solver'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de exactitudes obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=acca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Exactitud (Accuracy) promedio obtenida en la busqueda:  0.7900000000000001\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "C (parametro de regularización):  203\n",
            "class_weight:  balanced\n",
            "solver:  sag\n",
            "\n",
            "Boxplot de exactitudes obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a85e83ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7BJBES_j2cg5"
      },
      "source": [
        "####***D.3. Mejores hiperparametros según metrica de Precisión (precision)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z6smJXIu2cg6"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Precisión (precision) para Positivo (clase positiva)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***precisiones (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfldrEj-AB0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "cb0328a3-06fa-4c4d-9f72-38830e564a71"
      },
      "source": [
        "idx = np.array(dtcprep).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Precisión (precision) para Positivo (clase positiva) promedio obtenida en la busqueda: \", dtcprep[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"C (parametro de regularización): \", bestmodel.get_params()['C'])\n",
        "print(\"class_weight: \", bestmodel.get_params()['class_weight'])\n",
        "print(\"solver: \", bestmodel.get_params()['solver'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=prepa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Precisión (precision) para Positivo (clase positiva) promedio obtenida en la busqueda:  0.7900000000000001\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "C (parametro de regularización):  203\n",
            "class_weight:  balanced\n",
            "solver:  sag\n",
            "\n",
            "Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a85e4f3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANUElEQVR4nO3dbWid53nA8b8kK1ka25CpMsSe80JbXWMsGXjxQmjaUtJsIV9WtmadKTNsEPA+OHQj0K2QEhrGGpZPoSp20zG8dvNKs5LCcFdYGesSKOuYvb5suWxSx3btbD6oqXGWl8lH2gc9HqosS4/kEz/HF/8fBOncui1dOMlfD7eeozMyPz+PJKme0a4HkCS9PQy8JBVl4CWpKAMvSUUZeEkqakPXAzSuB3YCrwD9jmeRpGvFGHAz8B3graUfHJbA7wT+ueshJOka9T7g+aWLwxL4VwBeffV/mJvzvnxJamN0dISbbroRmoYuNSyB7wPMzc0beElau2WPtv0hqyQVZeAlqSgDL0lFrXoGHxFPAb8J3AbckZnfX2bPGPA08AAwD3wmM78w2FElSWvR5gr+OeD9wIkV9nwMeDfwHuAe4PGIuO2Kp5Mkrduqgc/M5zPz1CrbPgo8k5lzmdlj4ZvCQ4MYUJK0PoO6TfIWfvoK/ySwfUCf+6p56qk/5fjxl7oeYyhcuHCBfv9C12NoyIyNbWDDhmG5u7pbt9/+Lh599I+7HmNFQ/VvamJiY6df/9y5H/PGG2/A6FD9tXRjfg58MRgtMTffZ7bvfxfMXeDcuR8zObmp60lWNKiSnQRuZeH3IcClV/StzMy81ukTnTZu3MzYO/6Xd9x6X2czSBp+r5/4Jhs3bqbXO9/pHKOjIyteGA8q8F8BHo6IrwITwIdZ+N0IkqSOrPpD1oh4OiJ+BPwc8A8R8YNm/VBE3NVs+yLwQ+AY8G3g05l5/G2aWZLUwqpX8Jn5CPDIMusPLnq/D/z+YEeTJF0Jn8kqSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFbWhzaaImAIOABPADLA7M48t2bMF+AtgOzAO/CPwSGZeGOjEkqRW2l7B7wOmM3MKmAb2L7Pnk8B/ZuadwJ3ALwO/MZApJUlrtmrgmyvzHcDBZukgsCMiJpdsnQc2RcQocD1wHXB6gLNKktagzRHNduB0ZvYBMrMfEWea9d6ifU8Afwu8AtwIfDYzX1jLMBMTG9eyfeDGx8c6/fqSrh3j42NMTm7qeowVtTqDb+kh4LvAfcAm4OsR8ZHMfLbtJ5iZeY25ufkBjrQ2s7P9zr62pGvL7GyfXu98pzOMjo6seGHc5gz+FLAtIsYAmrdbm/XF9gJ/lZlzmXkO+BrwwXVNLUm6YqsGPjPPAkeAXc3SLuBwZvaWbD0OPAAQEdcBHwK+P7hRJUlr0fYumj3A3og4ysKV+h6AiDgUEXc1ez4OvC8ivsfCN4SjwDMDnleS1FKrM/jMfBG4e5n1Bxe9/xJw/+BGkyRdCZ/JKklFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekoja02RQRU8ABYAKYAXZn5rFl9v0W8BgwAswDH8rM/x7cuJKkttpewe8DpjNzCpgG9i/dEBF3AY8D92fmLwL3AucGNKckaY1WDXxEbAF2AAebpYPAjoiYXLL1D4CnMvO/ADLzXGa+OchhJUnttTmi2Q6czsw+QGb2I+JMs95btO8XgOMR8S1gI/BV4E8yc37AM0uSWmh1Bt/SGHAncD9wHfD3wEngL9t+gomJjQMcZ+3Gx8c6/fqSrh3j42NMTm7qeowVtQn8KWBbRIw1V+9jwNZmfbGTwLOZ+RbwVkR8DfgV1hD4mZnXmJvr7oJ/drbf2deWdG2Zne3T653vdIbR0ZEVL4xXPYPPzLPAEWBXs7QLOJyZvSVb/xr41YgYiYhx4D7g39c1tSTpirW9i2YPsDcijgJ7m8dExKHm7hmAvwHOAv/BwjeEHwB/PthxJUlttTqDz8wXgbuXWX9w0ftzwB82/0iSOuYzWSWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJU1CBfsq+E/ps/4fUT3+x6DA2JuQsLrxs/uuFnOp5Ew6T/5k+Ad3Y9xqoM/CLbt9/a9QgaMidPngDglu3D/z+zrqZ3XhO9GJmf7+41UBe5DTje9WuySks9+eQTAHziE491PIl0qUWvyXo78PIlH7/aA0mSrg4DL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVFSr3wcfEVPAAWACmAF2Z+axy+wN4DDwucx8dFCDSpLWpu0V/D5gOjOngGlg/3KbImKs+dhzgxlPkrReqwY+IrYAO4CDzdJBYEdETC6z/Y+AvwOODmxCSdK6tDmi2Q6czsw+QGb2I+JMs967uCkifgn4NeCDwLpe/qZ5ZRJpaIyPjwEwObmp40mktRvIa7JGxDjweeB3m28A6/o8vmSfhs3sbB+AXu98x5NIl1r0kn3Lf7zF5zgFbGvO1y+es29t1i+6GXgXcCgiXgY+DjwcEZ9f39iSpCu16hV8Zp6NiCPALuBLzdvDmdlbtOck8P8vOx8RjwMbvYtGkrrT9i6aPcDeiDgK7G0eExGHIuKut2s4SdL6tTqDz8wXgbuXWX/wMvsfv7KxJElXymeySlJRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpqA1tNkXEFHAAmABmgN2ZeWzJnseA3wb6wCzwycz8xmDHlSS11fYKfh8wnZlTwDSwf5k9/wLszMw7gd8DvhwRNwxmTEnSWq0a+IjYAuwADjZLB4EdETG5eF9mfiMzX28efhcYYeGKX5LUgTZX8NuB05nZB2jenmnWL2c38FJm/ujKR5QkrUerM/i1iIgPAE8A96/1z05MbBz0ONIVGR8fA2ByclPHk0hr1ybwp4BtETGWmf2IGAO2Nus/JSLuAb4E/Hpm5lqHmZl5jbm5+bX+MeltMzvbB6DXO9/xJNKlRkdHVrwwXvWIJjPPAkeAXc3SLuBwZvYW74uIncCXgY9k5r+te2JJ0kC0PaLZAxyIiE8Br7Jwxk5EHAI+lZn/CnwOuAHYHxEX/9zvZOb3BjuyJKmNVoHPzBeBu5dZf3DR+zsHOJck6Qr5TFZJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpqA1tNkXEFHAAmABmgN2ZeWzJnjHgaeABYB74TGZ+YbDjSpLaansFvw+YzswpYBrYv8yejwHvBt4D3AM8HhG3DWJISdLarXoFHxFbgB3A/c3SQeCzETGZmb1FWz8KPJOZc0AvIp4DHgL+bMAz6yp44YVv8fzz/9T1GJ07efIEAE8++UTHkwyHe+/9AO997/u7HkMttTmi2Q6czsw+QGb2I+JMs7448LcAJxY9PtnsaW1iYuNatutttHnzDYyPj3U9RucmJn4WwL+LxubNNzA5uanrMdRSqzP4q2Vm5jXm5ua7HkPAHXfs5I47dnY9hoZQr3e+6xHUGB0dWfHCuM0Z/ClgW/ND1Is/TN3arC92Erh10eNbltkjSbpKVg18Zp4FjgC7mqVdwOEl5+8AXwEejojRiJgEPgw8O8hhJUnttb2LZg+wNyKOAnubx0TEoYi4q9nzReCHwDHg28CnM/P4gOeVJLU0Mj8/FGfetwHHPYOXpPYWncHfDrx8ycev9kCSpKvDwEtSUQZekooalvvgx2DhPEmS1M6iZi77TLxhCfzNADfddGPXc0jStehm4KWli8NyF831wE7gFaDf8SySdK0YYyHu3wHeWvrBYQm8JGnA/CGrJBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVNSwPJNVGkoRMQUcACaAGWB3Zh7rdiqpHa/gpZXtA6YzcwqYBvZ3PI/UmoGXLiMitgA7gIPN0kFgR/OSlNLQM/DS5W0HTmdmH6B5e6ZZl4aegZekogy8dHmngG0RMQbQvN3arEtDz8BLl5GZZ4EjwK5maRdwODN73U0lteevC5ZWEBE/z8JtkjcBr7Jwm2R2O5XUjoGXpKI8opGkogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVNT/Ad6P9KFZtmAvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x7xO_PQu2cg_"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Precisión (precision) para Negativo (clase negativa)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***precisiones (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooJjNNK3AJDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "cf446e20-26b8-4ea3-8ce9-93645df8fd41"
      },
      "source": [
        "idx = np.array(dtcpren).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Precisión (precision) para Negativo (clase negativa) promedio obtenida en la busqueda: \", dtcpren[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"C (parametro de regularización): \", bestmodel.get_params()['C'])\n",
        "print(\"class_weight: \", bestmodel.get_params()['class_weight'])\n",
        "print(\"solver: \", bestmodel.get_params()['solver'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=prena)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Precisión (precision) para Negativo (clase negativa) promedio obtenida en la busqueda:  0.7533333333333333\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "C (parametro de regularización):  203\n",
            "class_weight:  balanced\n",
            "solver:  sag\n",
            "\n",
            "Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a85d7e128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cI5fZB-o2chE"
      },
      "source": [
        "####***D.4. Mejores hiperparametros según metrica de Recall***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mDEn6nGQ2chF"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***Recall para Positivo (clase positiva)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***recalls (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glE7TW3EAQs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "eb5688ac-73ee-463e-c63f-4c6624135184"
      },
      "source": [
        "idx = np.array(dtcrecp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Recall para Positivo (clase positiva) promedio obtenido en la busqueda: \", dtcrecp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"C (parametro de regularización): \", bestmodel.get_params()['C'])\n",
        "print(\"class_weight: \", bestmodel.get_params()['class_weight'])\n",
        "print(\"solver: \", bestmodel.get_params()['solver'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=recpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Recall para Positivo (clase positiva) promedio obtenido en la busqueda:  0.9\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "C (parametro de regularización):  299\n",
            "class_weight:  None\n",
            "solver:  saga\n",
            "\n",
            "Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a85d5ddd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cUWfQ3AL2chM"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***Recall para Negativo (clase negativa)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***recalls (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k57uNdc6Adcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "26442ebc-7f06-47e3-da73-a4b9b48c1671"
      },
      "source": [
        "idx = np.array(dtcrecn).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Recall para Negativo (clase negativa) promedio obtenido en la busqueda: \", dtcrecn[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"C (parametro de regularización): \", bestmodel.get_params()['C'])\n",
        "print(\"class_weight: \", bestmodel.get_params()['class_weight'])\n",
        "print(\"solver: \", bestmodel.get_params()['solver'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=recna)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Recall para Negativo (clase negativa) promedio obtenido en la busqueda:  0.69\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "C (parametro de regularización):  203\n",
            "class_weight:  balanced\n",
            "solver:  sag\n",
            "\n",
            "Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a85cab128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANUElEQVR4nO3dbWid53nA8b8kK1ka25CpMsSe80JbXWMsGXjxQmjaUtJsIV9WtmadKTNsEPA+OHQj0K2QEhrGGpZPoSp20zG8dvNKs5LCcFdYGesSKOuYvb5suWxSx3btbD6oqXGWl8lH2gc9HqosS4/kEz/HF/8fBOncui1dOMlfD7eeozMyPz+PJKme0a4HkCS9PQy8JBVl4CWpKAMvSUUZeEkqakPXAzSuB3YCrwD9jmeRpGvFGHAz8B3graUfHJbA7wT+ueshJOka9T7g+aWLwxL4VwBeffV/mJvzvnxJamN0dISbbroRmoYuNSyB7wPMzc0beElau2WPtv0hqyQVZeAlqSgDL0lFrXoGHxFPAb8J3AbckZnfX2bPGPA08AAwD3wmM78w2FElSWvR5gr+OeD9wIkV9nwMeDfwHuAe4PGIuO2Kp5Mkrduqgc/M5zPz1CrbPgo8k5lzmdlj4ZvCQ4MYUJK0PoO6TfIWfvoK/ySwfUCf+6p56qk/5fjxl7oeYyhcuHCBfv9C12NoyIyNbWDDhmG5u7pbt9/+Lh599I+7HmNFQ/VvamJiY6df/9y5H/PGG2/A6FD9tXRjfg58MRgtMTffZ7bvfxfMXeDcuR8zObmp60lWNKiSnQRuZeH3IcClV/StzMy81ukTnTZu3MzYO/6Xd9x6X2czSBp+r5/4Jhs3bqbXO9/pHKOjIyteGA8q8F8BHo6IrwITwIdZ+N0IkqSOrPpD1oh4OiJ+BPwc8A8R8YNm/VBE3NVs+yLwQ+AY8G3g05l5/G2aWZLUwqpX8Jn5CPDIMusPLnq/D/z+YEeTJF0Jn8kqSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFbWhzaaImAIOABPADLA7M48t2bMF+AtgOzAO/CPwSGZeGOjEkqRW2l7B7wOmM3MKmAb2L7Pnk8B/ZuadwJ3ALwO/MZApJUlrtmrgmyvzHcDBZukgsCMiJpdsnQc2RcQocD1wHXB6gLNKktagzRHNduB0ZvYBMrMfEWea9d6ifU8Afwu8AtwIfDYzX1jLMBMTG9eyfeDGx8c6/fqSrh3j42NMTm7qeowVtTqDb+kh4LvAfcAm4OsR8ZHMfLbtJ5iZeY25ufkBjrQ2s7P9zr62pGvL7GyfXu98pzOMjo6seGHc5gz+FLAtIsYAmrdbm/XF9gJ/lZlzmXkO+BrwwXVNLUm6YqsGPjPPAkeAXc3SLuBwZvaWbD0OPAAQEdcBHwK+P7hRJUlr0fYumj3A3og4ysKV+h6AiDgUEXc1ez4OvC8ivsfCN4SjwDMDnleS1FKrM/jMfBG4e5n1Bxe9/xJw/+BGkyRdCZ/JKklFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekoja02RQRU8ABYAKYAXZn5rFl9v0W8BgwAswDH8rM/x7cuJKkttpewe8DpjNzCpgG9i/dEBF3AY8D92fmLwL3AucGNKckaY1WDXxEbAF2AAebpYPAjoiYXLL1D4CnMvO/ADLzXGa+OchhJUnttTmi2Q6czsw+QGb2I+JMs95btO8XgOMR8S1gI/BV4E8yc37AM0uSWmh1Bt/SGHAncD9wHfD3wEngL9t+gomJjQMcZ+3Gx8c6/fqSrh3j42NMTm7qeowVtQn8KWBbRIw1V+9jwNZmfbGTwLOZ+RbwVkR8DfgV1hD4mZnXmJvr7oJ/drbf2deWdG2Zne3T653vdIbR0ZEVL4xXPYPPzLPAEWBXs7QLOJyZvSVb/xr41YgYiYhx4D7g39c1tSTpirW9i2YPsDcijgJ7m8dExKHm7hmAvwHOAv/BwjeEHwB/PthxJUlttTqDz8wXgbuXWX9w0ftzwB82/0iSOuYzWSWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJU1CBfsq+E/ps/4fUT3+x6DA2JuQsLrxs/uuFnOp5Ew6T/5k+Ad3Y9xqoM/CLbt9/a9QgaMidPngDglu3D/z+zrqZ3XhO9GJmf7+41UBe5DTje9WuySks9+eQTAHziE491PIl0qUWvyXo78PIlH7/aA0mSrg4DL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVFSr3wcfEVPAAWACmAF2Z+axy+wN4DDwucx8dFCDSpLWpu0V/D5gOjOngGlg/3KbImKs+dhzgxlPkrReqwY+IrYAO4CDzdJBYEdETC6z/Y+AvwOODmxCSdK6tDmi2Q6czsw+QGb2I+JMs967uCkifgn4NeCDwLpe/qZ5ZRJpaIyPjwEwObmp40mktRvIa7JGxDjweeB3m28A6/o8vmSfhs3sbB+AXu98x5NIl1r0kn3Lf7zF5zgFbGvO1y+es29t1i+6GXgXcCgiXgY+DjwcEZ9f39iSpCu16hV8Zp6NiCPALuBLzdvDmdlbtOck8P8vOx8RjwMbvYtGkrrT9i6aPcDeiDgK7G0eExGHIuKut2s4SdL6tTqDz8wXgbuXWX/wMvsfv7KxJElXymeySlJRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpqA1tNkXEFHAAmABmgN2ZeWzJnseA3wb6wCzwycz8xmDHlSS11fYKfh8wnZlTwDSwf5k9/wLszMw7gd8DvhwRNwxmTEnSWq0a+IjYAuwADjZLB4EdETG5eF9mfiMzX28efhcYYeGKX5LUgTZX8NuB05nZB2jenmnWL2c38FJm/ujKR5QkrUerM/i1iIgPAE8A96/1z05MbBz0ONIVGR8fA2ByclPHk0hr1ybwp4BtETGWmf2IGAO2Nus/JSLuAb4E/Hpm5lqHmZl5jbm5+bX+MeltMzvbB6DXO9/xJNKlRkdHVrwwXvWIJjPPAkeAXc3SLuBwZvYW74uIncCXgY9k5r+te2JJ0kC0PaLZAxyIiE8Br7Jwxk5EHAI+lZn/CnwOuAHYHxEX/9zvZOb3BjuyJKmNVoHPzBeBu5dZf3DR+zsHOJck6Qr5TFZJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVJSBl6SiDLwkFWXgJakoAy9JRRl4SSrKwEtSUQZekooy8JJUlIGXpKIMvCQVZeAlqSgDL0lFGXhJKsrAS1JRBl6SijLwklSUgZekogy8JBVl4CWpqA1tNkXEFHAAmABmgN2ZeWzJnjHgaeABYB74TGZ+YbDjSpLaansFvw+YzswpYBrYv8yejwHvBt4D3AM8HhG3DWJISdLarXoFHxFbgB3A/c3SQeCzETGZmb1FWz8KPJOZc0AvIp4DHgL+bMAz6yp44YVv8fzz/9T1GJ07efIEAE8++UTHkwyHe+/9AO997/u7HkMttTmi2Q6czsw+QGb2I+JMs7448LcAJxY9PtnsaW1iYuNatutttHnzDYyPj3U9RucmJn4WwL+LxubNNzA5uanrMdRSqzP4q2Vm5jXm5ua7HkPAHXfs5I47dnY9hoZQr3e+6xHUGB0dWfHCuM0Z/ClgW/ND1Is/TN3arC92Erh10eNbltkjSbpKVg18Zp4FjgC7mqVdwOEl5+8AXwEejojRiJgEPgw8O8hhJUnttb2LZg+wNyKOAnubx0TEoYi4q9nzReCHwDHg28CnM/P4gOeVJLU0Mj8/FGfetwHHPYOXpPYWncHfDrx8ycev9kCSpKvDwEtSUQZekooalvvgx2DhPEmS1M6iZi77TLxhCfzNADfddGPXc0jStehm4KWli8NyF831wE7gFaDf8SySdK0YYyHu3wHeWvrBYQm8JGnA/CGrJBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVNSwPJNVGkoRMQUcACaAGWB3Zh7rdiqpHa/gpZXtA6YzcwqYBvZ3PI/UmoGXLiMitgA7gIPN0kFgR/OSlNLQM/DS5W0HTmdmH6B5e6ZZl4aegZekogy8dHmngG0RMQbQvN3arEtDz8BLl5GZZ4EjwK5maRdwODN73U0lteevC5ZWEBE/z8JtkjcBr7Jwm2R2O5XUjoGXpKI8opGkogy8JBVl4CWpKAMvSUUZeEkqysBLUlEGXpKKMvCSVNT/Ad6P9KFZtmAvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gHYL0Dga2chR"
      },
      "source": [
        "####***D.5. Mejores hiperparametros según metrica de F1***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uftNhTZ-2chS"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***F1 para Positivo (clase positiva)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***f1s (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkbk8P2WAppu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "6d7c176e-ad49-4cb1-fa79-25bdf0356189"
      },
      "source": [
        "idx = np.array(dtcf1p).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda: \", dtcf1p[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"C (parametro de regularización): \", bestmodel.get_params()['C'])\n",
        "print(\"class_weight: \", bestmodel.get_params()['class_weight'])\n",
        "print(\"solver: \", bestmodel.get_params()['solver'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda:  0.8133333333333332\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "C (parametro de regularización):  203\n",
            "class_weight:  balanced\n",
            "solver:  sag\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a85cba400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "16hpceVx2chV"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***F1 para Negativo (clase negativa)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***f1s (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkKdI3OTAvvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "244bb5a4-e891-494c-83ce-4260b53f17ba"
      },
      "source": [
        "idx = np.array(dtcf1p).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor F1 para Negativo (clase positiva) promedio obtenido en la busqueda: \", dtcf1p[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"C (parametro de regularización): \", bestmodel.get_params()['C'])\n",
        "print(\"class_weight: \", bestmodel.get_params()['class_weight'])\n",
        "print(\"solver: \", bestmodel.get_params()['solver'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda:  0.8133333333333332\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "C (parametro de regularización):  203\n",
            "class_weight:  balanced\n",
            "solver:  sag\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a85be2b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YOvQp_Di2chZ"
      },
      "source": [
        "####***D.6. Mejores hiperparametros según metrica de Área bajo la curva ROC (AUC)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-4cPq7mZ2cha"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Área bajo la curva ROC (AUC)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***AUCs*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jk__H6kHA6cr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "61b6bc49-200f-4c24-a66b-5b40fb9f2038"
      },
      "source": [
        "idx = np.array(dtcauc).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor AUC promedio obtenido en la busqueda: \", dtcauc[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"C (parametro de regularización): \", bestmodel.get_params()['C'])\n",
        "print(\"class_weight: \", bestmodel.get_params()['class_weight'])\n",
        "print(\"solver: \", bestmodel.get_params()['solver'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de AUCs obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=auca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor AUC promedio obtenido en la busqueda:  0.8725\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "C (parametro de regularización):  299\n",
            "class_weight:  None\n",
            "solver:  saga\n",
            "\n",
            "Boxplot de AUCs obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a85bbf198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LVlTMfhI2chg"
      },
      "source": [
        "####***D.7. Comparación y Analisis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vbhTaENRwowW"
      },
      "source": [
        "En esta parte, se procedera a realizar la síntesis o resumen de los resultados obtenidos. Se empleara una comparación entre los mismos, con el objetivo de formular conclusiones apropiadas. La evaluación se desarrolla en base a distintas metricas. Entre ellas, cabe mencionar ***Exactitud, Precisión, Recall, F1 y Área bajo la curva ROC (AUC)***. Asimismo, tambien se usa el ***Promedio de métricas***, el cual constituye el promedio de los valores de todas las metricas mencionadas. Dicho promedio fue planteado con el objetivo de considerar la maximización de todas las metricas en la busqueda de los mejores hiperparametros. En la siguiente tabla, se presentan los ***hiperparametros*** que maximizan los valores de cada metrica. En ese sentido, ello permite identificar los mejores ***hiperparametros*** en base a que medida se desee optimizar. \n",
        "\n",
        "![alt text](https://i.ibb.co/16RpNs3/02.png)\n",
        "\n",
        "De acuerdo a lo observado en la tabla anterior, es posible concluir que el mejor valor para el ***hiperparametro Pesos*** es ***Uniform***, ya que este logro ser el mejor para todas las métricas consideradas. Asimismo, respecto a ***Numero de vecinos***, no hay un valor mayoritario como en el caso anterior. No obstante, en este tipo de casos, es importante elegir un metrica para basarse en ella y analizar lo obtenido respecto a ***boxplots*** y otros elementos estadisticos. En este caso, se selecciona ***F1*** como metrica de mayor relevancia. El ***Boxplot*** de ***F1*** para ***Positivo***, es decir para la clase positiva, posee sus valores distribuidos en valores altos, siendo su limite inferior ***0.5***. Igualmente, el ***Boxplot*** de ***F1*** para ***Negativo***, es decir para la clase negativa, tambien posee sus valores distribuidos en valores altos. El valor promedio de ***F1*** para ***Negativo*** no es tan alto, ya que presenta ***outliers*** en ***0.0***. Considerando la información dada anteriormente, se concluye que ***F1***, en este caso, es un metrica de decisión apropiada. ***14*** logro ser el mejor valor para el ***hiperparametro Numero de vecinos***, en el caso de ***F1*** para ***Positivo*** y ***F1*** para ***Negativo***. Por ultimo, para el ***hiperparametro Algoritmo***, se logra determinar ***Brute*** como el valor optimo, ya que este funciona mejor para la mayoria de metricas consideradas. Por lo tanto, se concluye que los ***hiperparametros*** que logran maximizar las metricas de forma conjunta y funcionan mejor con los datos son:\n",
        "\n",
        "* ***C: Parametro de regularización: 203***\n",
        "* ***class_weight: balanced***\n",
        "* ***Solucionador (solver): sag***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xUaUOEFiKglI"
      },
      "source": [
        "###***E. Redes Bayesianas Multinomiales (Multinomial Naive Bayes)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XpdqhYmKKglK"
      },
      "source": [
        "Se procedera a realizar el ajuste de hiperparametros para ***Redes Bayesianas Multinomiales (Multinomial Naive Bayes)*** con el conjunto de datos dado. Con respecto a dicho ajuste, nos enfocaremos en ***2 hiperparametros*** principalmente, los cuales son ***alpha y fit_prior***. Estos seran ajustados, ya que son considerados los más importantes. Se tratara de buscar la combinación de estos ***hiperparametros*** que maximize la performance de clasficación. Se aplicara ***cross-validation estratificado con K=10*** para el muestreo. La evaluación de cada combinación de ***hiperparametros*** se realizá con la función ***test_model***. Llegados a este punto, se procedera a describir a los ***hiperparametros***:\n",
        "\n",
        "* ***alpha: Parámetro de suavizado aditivo (Laplace / Lidstone) (0 para no suavizado).***\n",
        "\n",
        "* ***fit_prior: Indica si se aprenden las probabilidades prioritarias de las clases o no. Este hiperparametro puede ser Verdadero (True) o Falso (False). Si es falso, se usará prioridades uniformes.***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4c4gqkhvKglL"
      },
      "source": [
        "En el siguiente codigo, respecto a la busqueda de los mejores hiperparametros, no se estan evaluando todas las posibilidades. En este caso, lo que se propone es primero realizar una búsqueda general rápida, con el objetivo de ubicar, aproximadamente, el rango en el que se podría encontrar el ***hiperparametro*** óptimo. Una vez ubicado dicho rango, proceder con una búsqueda exhaustiva. Además, se almacena el ***promedio de las metricas*** obtenidas, por cada combinación de ***hiperparametros*** evaluada, en un arreglo. Con dicho promedio, se logra considerar la optimización de todas las metricas en la busqueda de los ***hiperparametros***. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wpdwMCa1uvVb",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "bestmnb = MultinomialNB(alpha=0, fit_prior=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uzsU9_JyuvVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "674d001d-93de-49fc-8ee7-40dca69b0c55"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "\n",
        "#Hiperparametros:\n",
        "\n",
        "#Hiperparametros:\n",
        "alpha = [0, 0.25, 0.5, 0.75, 1]\n",
        "fit_prior = [True, False]\n",
        "\n",
        "dtcallp = [] #Arreglo para guardar el promedio de todas las metricas\n",
        "dtcmods = [] #Arreglo para guardar los modelos ajustados\n",
        "\n",
        "for a in alpha: #Busqueda de hiperparametros\n",
        "  for f in fit_prior:\n",
        "    bestmnb = MultinomialNB(alpha=a, fit_prior=f)\n",
        "    acc, prep, recp, f1p, pren, recn, f1n, auc = test_model(bestmnb, df, 50)\n",
        "    dtcallp.append((acc+prep+recp+f1p+pren+recn+f1n+auc)/8)\n",
        "    dtcmods.append(bestmnb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wiXuPZ40J1AE"
      },
      "source": [
        "Con la evaluación ***test_model***, se consideran una serie de metricas, las cuales son promediadas y almacenadas durante la busqueda. En el siguiente codigo, se indica el máximo ***promedio de metricas*** obtenido en la busqueda. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho promedio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GyJXeQBTuvV4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "c6e80b2e-5132-4632-963d-93666978d852"
      },
      "source": [
        "idx = np.array(dtcallp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor promedio de metricas obtenido en la busqueda: \", dtcallp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"alpha: \", bestmodel.get_params()['alpha'])\n",
        "print(\"fit_prior: \", bestmodel.get_params()['fit_prior'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor promedio de metricas obtenido en la busqueda:  0.7425208333333333\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "alpha:  1\n",
            "fit_prior:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I_E_SeLCJ4XQ"
      },
      "source": [
        "De acuerdo a lo obtenido anteriormente, con respecto a el ***Parámetro de suavizado aditivo alpha***, se logra identificar que el mejor valor para dicho ***hiperparametro*** es cercano a ***1***. En ese sentido, se reducira el rango a **[0.9, 1]**, y se procedera a realizar una busqueda exhaustiva. Cabe mencionar que se almacenan las metricas obtenidas y el promedio de dichas metricas, por cada combinación de ***hiperparametros*** evaluada, en arreglos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kYdbv2RNuvV-",
        "colab": {}
      },
      "source": [
        "#Hiperparametros:\n",
        "alpha = [0.9, 0.95, 1]\n",
        "fit_prior = [True, False]\n",
        "\n",
        "dtcacc = [] #Arreglo para guardar exactitudes\n",
        "dtcprep = [] #Arreglo para guardar precisiones positivas\n",
        "dtcrecp = [] #Arreglo para guardar recalls positivos\n",
        "dtcf1p = [] #Arreglo para guardar F1s positivos\n",
        "dtcpren = [] #Arreglo para guardar precisiones negativas\n",
        "dtcrecn = [] #Arreglo para guardar recalls negativos\n",
        "dtcf1n = [] #Arreglo para guardar F1s negativos\n",
        "dtcauc = [] #Arreglo para guardar AUCs\n",
        "dtcallp = [] #Arreglo para guardar el promedio de todas las metricas\n",
        "dtcmods = [] #Arreglo para guardar los modelos ajustados\n",
        "\n",
        "for a in alpha: #Busqueda de hiperparametros\n",
        "  for f in fit_prior:\n",
        "    bestmnb = MultinomialNB(alpha=a, fit_prior=f)\n",
        "    acc, prep, recp, f1p, pren, recn, f1n, auc = test_model(bestmnb, df, 50)\n",
        "    dtcacc.append(acc)\n",
        "    dtcprep.append(prep)\n",
        "    dtcrecp.append(recp)\n",
        "    dtcf1p.append(f1p)\n",
        "    dtcpren.append(pren)\n",
        "    dtcrecn.append(recn)\n",
        "    dtcf1n.append(f1n)\n",
        "    dtcauc.append(auc)\n",
        "    dtcallp.append((acc+prep+recp+f1p+pren+recn+f1n+auc)/8)\n",
        "    dtcmods.append(bestmnb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x3rAlCpFKaHK"
      },
      "source": [
        "####***E.1. Mejores hiperparametros según Promedio de métricas***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i6tVKnQ3KaHS"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***promedio de metricas*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho promedio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jL0G_2VNuvWH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "283ec574-7845-41d1-ff01-3a5b1c24150e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "idx = np.array(dtcallp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor promedio de metricas obtenido en la busqueda: \", dtcallp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"alpha: \", bestmodel.get_params()['alpha'])\n",
        "print(\"fit_prior: \", bestmodel.get_params()['fit_prior'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor promedio de metricas obtenido en la busqueda:  0.7425208333333333\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "alpha:  1\n",
            "fit_prior:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7BPxTokDKesD"
      },
      "source": [
        "####***E.2. Mejores hiperparametros según metrica de Exactitud (Accuracy)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OcKhm-VuKesN"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Exactitud (Accuracy)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***exactitudes*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_T5ZT6ycuvWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "e55b9eb4-587f-4cab-b036-6b1024d72ef4"
      },
      "source": [
        "idx = np.array(dtcacc).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Exactitud (Accuracy) promedio obtenida en la busqueda: \", dtcacc[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"alpha: \", bestmodel.get_params()['alpha'])\n",
        "print(\"fit_prior: \", bestmodel.get_params()['fit_prior'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de exactitudes obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=acca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Exactitud (Accuracy) promedio obtenida en la busqueda:  0.7116666666666669\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "alpha:  1\n",
            "fit_prior:  True\n",
            "\n",
            "Boxplot de exactitudes obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a8635b358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sbS2nuOXKjxW"
      },
      "source": [
        "####***E.3. Mejores hiperparametros según metrica de Precisión (precision)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iMZjh_9DKjxh"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Precisión (precision) para Positivo (clase positiva)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***precisiones (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RqXJZkvJuvWY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "06dbee9f-af0e-4f81-8c1b-3d104de0712a"
      },
      "source": [
        "idx = np.array(dtcprep).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Precisión (precision) para Positivo (clase positiva) promedio obtenida en la busqueda: \", dtcprep[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"alpha: \", bestmodel.get_params()['alpha'])\n",
        "print(\"fit_prior: \", bestmodel.get_params()['fit_prior'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=prepa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Precisión (precision) para Positivo (clase positiva) promedio obtenida en la busqueda:  0.72\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "alpha:  1\n",
            "fit_prior:  True\n",
            "\n",
            "Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a86228860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M-XArnEtKpvH"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Precisión (precision) para Negativo (clase negativa)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***precisiones (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "48oTcNv9uvWj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "4c004ddf-ad56-4b69-824a-4d5fb4ecd26b"
      },
      "source": [
        "idx = np.array(dtcpren).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Precisión (precision) para Negativo (clase negativa) promedio obtenida en la busqueda: \", dtcpren[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"alpha: \", bestmodel.get_params()['alpha'])\n",
        "print(\"fit_prior: \", bestmodel.get_params()['fit_prior'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=prena)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Precisión (precision) para Negativo (clase negativa) promedio obtenida en la busqueda:  0.7033333333333335\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "alpha:  1\n",
            "fit_prior:  True\n",
            "\n",
            "Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a86208898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANkUlEQVR4nO3db2id53mA8Us6Vv40dpxMlSH2FKes1T3GkoEWL4SmLSXNFvJlZWvWqWWGDQLeB4duDDoKKaFh0LB+ClWxm47htotWmpUWirfCwliXQFnH7PXPltte6liOncwHLVbtBQf5SPugN+NUlqX3SCd+j59dPwjSefRYugnJpcev3qMztLS0hCSpPMNNDyBJensYeEkqlIGXpEIZeEkqlIGXpEJtaXqAyvXAHuBVoNPwLJJ0rWgBtwHfB95c+cFBCfwe4J+aHkKSrlHvA55fuTgogX8V4PXX/4fFRe/Ll6Q6hoeHuPXWm6Bq6EqDEvgOwOLikoGXpN6temnbH7JKUqEMvCQVysBLUqHWvQYfEZ8Dfhu4A7gzM3+0yp4W8BTwILAEfDYzv9TfUSVJvahzgv8m8H7g5Bp7Pg68G3gPcC/weETcsenpJEkbtm7gM/P5zDy1zraPAk9n5mJmtln+pvBwPwaUJG1Mv26TvJ2fPeHPAuN9+txXzTPPfJlTp9b6i8r/H/Pz55ifn296DA2Y7du3s337LU2PMRDGx3fzsY/tbXqMNQ3KffAAjI5ubfTrv/baK+Tx/6R1g/8BL166yNKlhabH0IC5+N8XaP/0UtNjNK5z8RwjIy3GxrY1Pcqa+hX4WWA3y78PAS4/0dcyN3eh0Sc6LSx0aN1wC+/YfX9jM0gafG+cfI6FhQ7t9vlG5xgeHlrzYNyvwH8deCQivgGMAh9m+XcjSJIasu4PWSPiqYh4Bfh54O8j4sfV+uGIuLva9hXgJ8Bx4HvAZzLzxNs0sySphnVP8Jn5KPDoKusPdb3fAf6wv6NJkjbDZ7JKUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqG2ND3AIJmfP0fn4jneOPlc06NIGmCdi+eYnx/8fHqCl6RCDf63oKto+/ZbaP/0Eu/YfX/To0gaYG+cfI7t229peox1eYKXpELVOsFHxARwCBgF5oC9mXl8xZ4dwF8C48AI8A/Ao5l5qa8TS5JqqXuCPwBMZ+YEMA0cXGXPp4D/yMy7gLuAXwV+qy9TSpJ6tm7gq5P5JDBTLc0AkxExtmLrErAtIoaB64HrgNN9nFWS1IM6l2jGgdOZ2QHIzE5EnKnW2137ngD+BngVuAn4fGa+0Mswo6Nbe9nedyMjrUa/vqRrx8hIi7GxbU2PsaZ+3kXzMPAD4H5gG/C3EfGRzHy27ieYm7vA4uJSH0fqzcJCp7GvLenasrDQod0+3+gMw8NDax6M61yDPwXsiogWQPV2Z7XebT/wV5m5mJnzwLeAD25oaknSpq0b+Mw8CxwFpqqlKeBIZrZXbD0BPAgQEdcBHwJ+1L9RJUm9qHsXzT5gf0QcY/mkvg8gIg5HxN3Vnk8A74uIH7L8DeEY8HSf55Uk1VTrGnxmvgjcs8r6Q13vvwQ80L/RJEmb4TNZJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCmXgJalQBl6SCrWlzqaImAAOAaPAHLA3M4+vsu93gMeAIWAJ+FBm/lf/xpUk1VX3BH8AmM7MCWAaOLhyQ0TcDTwOPJCZvwzcB8z3aU5JUo/WDXxE7AAmgZlqaQaYjIixFVv/CPhcZr4GkJnzmXmxn8NKkuqrc4lmHDidmR2AzOxExJlqvd2175eAExHxXWAr8A3gzzJzqc8zS5JqqHUNvqYWcBfwAHAd8HfALPDlup9gdHRrH8fp3chIq9GvL+naMTLSYmxsW9NjrKlO4E8BuyKiVZ3eW8DOar3bLPBsZr4JvBkR3wJ+jR4CPzd3gcXF5g78Cwudxr62pGvLwkKHdvt8ozMMDw+teTBe9xp8Zp4FjgJT1dIUcCQz2yu2PgP8ekQMRcQIcD/wbxuaWpK0aXXvotkH7I+IY8D+6jERcbi6ewbgr4GzwL+z/A3hx8Bf9HdcSVJdta7BZ+aLwD2rrD/U9f4i8MfVP5KkhvlMVkkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEIZeEkqlIGXpEL18yX7itC5eI43Tj7X9BgaEIuXll83fnjLDQ1PokHSuXgOeGfTY6zLwHcZH9/d9AgaMLOzJwG4fXzw/2fW1fTOa6IXQ0tLzb0Gapc7gBNNvyartNKTTz4BwCc/+VjDk0iX63pN1ncBL1/28as9kCTp6jDwklQoAy9JhTLwklQoAy9JhTLwklQoAy9JhTLwklQoAy9JhTLwklQoAy9JhTLwklQoAy9JhTLwklSoWr8PPiImgEPAKDAH7M3M41fYG8AR4AuZ+Sf9GlSS1Ju6J/gDwHRmTgDTwMHVNkVEq/rYN/szniRpo9YNfETsACaBmWppBpiMiLFVtv8p8G3gWN8mlCRtSJ1LNOPA6czsAGRmJyLOVOvttzZFxK8AvwF8ENjQy99Ur0wiDYyRkRYAY2PbGp5E6l1fXpM1IkaALwK/X30D2NDn8SX7NGgWFjoAtNvnG55EulzXS/at/vEan+MUsKu6vv7Wdfad1fpbbgN+ATgcES8DnwAeiYgvbmxsSdJmrXuCz8yzEXEUmAK+Wr09kpntrj2zwP+97HxEPA5s9S4aSWpO3bto9gH7I+IYsL96TEQcjoi7367hJEkbV+safGa+CNyzyvpDV9j/+ObGkiRtls9klaRCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKpSBl6RCGXhJKtSWOpsiYgI4BIwCc8DezDy+Ys9jwO8CHWAB+FRmfqe/40qS6qp7gj8ATGfmBDANHFxlzz8DezLzLuAPgK9FxI39GVOS1Kt1Ax8RO4BJYKZamgEmI2Kse19mficz36ge/gAYYvnEL0lqQJ0T/DhwOjM7ANXbM9X6lewFXsrMVzY/oiRpI2pdg+9FRHwAeAJ4oNc/Ozq6td/jSJsyMtICYGxsW8OTSL2rE/hTwK6IaGVmJyJawM5q/WdExL3AV4HfzMzsdZi5uQssLi71+sekt83CQgeAdvt8w5NIlxseHlrzYLzuJZrMPAscBaaqpSngSGa2u/dFxB7ga8BHMvNfNzyxJKkv6l6i2QcciohPA6+zfI2diDgMfDoz/wX4AnAjcDAi3vpzv5eZP+zvyJKkOmoFPjNfBO5ZZf2hrvf39HEuSdIm+UxWSSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSqUgZekQhl4SSrUljqbImICOASMAnPA3sw8vmJPC3gKeBBYAj6bmV/q77iSpLrqnuAPANOZOQFMAwdX2fNx4N3Ae4B7gccj4o5+DClJ6t26J/iI2AFMAg9USzPA5yNiLDPbXVs/CjydmYtAOyK+CTwM/HmfZ9ZV8MIL3+X55/+x6TEaNzt7EoAnn3yi4UkGw333fYD3vvf9TY+hmupcohkHTmdmByAzOxFxplrvDvztwMmux7PVntpGR7f2sl1vo5tvvpGRkVbTYzRudPTnAPx3Ubn55hsZG9vW9BiqqdY1+Ktlbu4Ci4tLTY8h4M4793DnnXuaHkMDqN0+3/QIqgwPD615MK5zDf4UsKv6IepbP0zdWa13mwV2dz2+fZU9kqSrZN3AZ+ZZ4CgwVS1NAUdWXH8H+DrwSEQMR8QY8GHg2X4OK0mqr+5dNPuA/RFxDNhfPSYiDkfE3dWerwA/AY4D3wM+k5kn+jyvJKmmoaWlgbjmfQdwwmvwklRf1zX4dwEvX/bxqz2QJOnqMPCSVCgDL0mFGpT74FuwfD1JklRPVzNXfSbeoAT+NoBbb72p6Tkk6Vp0G/DSysVBuYvmemAP8CrQaXgWSbpWtFiO+/eBN1d+cFACL0nqM3/IKkmFMvCSVCgDL0mFMvCSVCgDL0mFMvCSVCgDL0mFGpRnskoDKSImgEPAKDAH7M3M481OJdXjCV5a2wFgOjMngGngYMPzSLUZeOkKImIHMAnMVEszwGT1kpTSwDPw0pWNA6czswNQvT1TrUsDz8BLUqEMvHRlp4BdEdECqN7urNalgWfgpSvIzLPAUWCqWpoCjmRmu7mppPr8dcHSGiLiF1m+TfJW4HWWb5PMZqeS6jHwklQoL9FIUqEMvCQVysBLUqEMvCQVysBLUqEMvCQVysBLUqEMvCQV6n8BvrsMKGVlelcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ky8FxAdyKt36"
      },
      "source": [
        "####***E.4. Mejores hiperparametros según metrica de Recall***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9H-90q91Kt4D"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***Recall para Positivo (clase positiva)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***recalls (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AJq6mRf3uvWp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "11ddcfa8-cbc5-4684-bdab-07cab89ff503"
      },
      "source": [
        "idx = np.array(dtcrecp).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Recall para Positivo (clase positiva) promedio obtenido en la busqueda: \", dtcrecp[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"alpha: \", bestmodel.get_params()['alpha'])\n",
        "print(\"fit_prior: \", bestmodel.get_params()['fit_prior'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=recpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Recall para Positivo (clase positiva) promedio obtenido en la busqueda:  0.7\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "alpha:  1\n",
            "fit_prior:  True\n",
            "\n",
            "Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a86166550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mI5ki0LxKzdi"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***Recall para Negativo (clase negativa)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***recalls (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kWorotbGuvWu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "764e9c71-b153-4040-8bac-b2dffa54b834"
      },
      "source": [
        "idx = np.array(dtcrecn).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor Recall para Negativo (clase negativa) promedio obtenido en la busqueda: \", dtcrecn[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"alpha: \", bestmodel.get_params()['alpha'])\n",
        "print(\"fit_prior: \", bestmodel.get_params()['fit_prior'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=recna)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor Recall para Negativo (clase negativa) promedio obtenido en la busqueda:  0.95\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "alpha:  1\n",
            "fit_prior:  False\n",
            "\n",
            "Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a86148668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yj2kM8xxK37s"
      },
      "source": [
        "####***E.5. Mejores hiperparametros según metrica de F1***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oZ6xpQolK37w"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***F1 para Positivo (clase positiva)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***f1s (clase positiva)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uvF5M-MEuvWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "e9b0ec8b-bd49-4a61-b169-111b273405d7"
      },
      "source": [
        "idx = np.array(dtcf1p).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda: \", dtcf1p[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"alpha: \", bestmodel.get_params()['alpha'])\n",
        "print(\"fit_prior: \", bestmodel.get_params()['fit_prior'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda:  0.6633333333333334\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "alpha:  1\n",
            "fit_prior:  True\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a860a26a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AMuru2s-K8pg"
      },
      "source": [
        "En el siguiente codigo, se indica el máximo ***F1 para Negativo (clase negativa)*** obtenido en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***f1s (clase negativa)*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zSq54iONuvW5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "94a1df74-d926-4f32-deaa-a85d45eb9cdd"
      },
      "source": [
        "idx = np.array(dtcf1p).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor F1 para Negativo (clase positiva) promedio obtenido en la busqueda: \", dtcf1p[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"alpha: \", bestmodel.get_params()['alpha'])\n",
        "print(\"fit_prior: \", bestmodel.get_params()['fit_prior'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor F1 para Positivo (clase positiva) promedio obtenido en la busqueda:  0.6633333333333334\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "alpha:  1\n",
            "fit_prior:  True\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a8607d908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Fr6pe_eK_QA"
      },
      "source": [
        "####***E.6. Mejores hiperparametros según metrica de Área bajo la curva ROC (AUC)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yglphFyRK_QJ"
      },
      "source": [
        "En el siguiente codigo, se indica la máxima ***Área bajo la curva ROC (AUC)*** obtenida en la busqueda anterior. Igualmente, se imprimen los ***hiperparametros*** con los que se logra alcanzar dicho valor. Por ultimo, se muestra el ***Boxplot*** de ***AUCs*** respectivo a la evaluación realizada con los ***hiperparametros*** especificados.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K91kSC9VuvW-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "8b1f7e1f-64ff-4f04-970f-e5f40e0284df"
      },
      "source": [
        "idx = np.array(dtcauc).argsort()[-1] #Indice del mejor modelo\n",
        "bestmodel = dtcmods[idx]\n",
        "print(\"Mejor AUC promedio obtenido en la busqueda: \", dtcauc[idx], end=\"\\n\\n\")\n",
        "print(\"Mejores Hiperparametros obtenidos en la busqueda:\")\n",
        "print(\"alpha: \", bestmodel.get_params()['alpha'])\n",
        "print(\"fit_prior: \", bestmodel.get_params()['fit_prior'])\n",
        "acca, prepa, recpa, f1pa, prena, recna, f1na, auca = test_model_array(bestmodel, df, 50)\n",
        "print()\n",
        "print(\"Boxplot de AUCs obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=auca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejor AUC promedio obtenido en la busqueda:  0.8725\n",
            "\n",
            "Mejores Hiperparametros obtenidos en la busqueda:\n",
            "alpha:  1\n",
            "fit_prior:  False\n",
            "\n",
            "Boxplot de AUCs obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a860417b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9wWrKHnYLFpH"
      },
      "source": [
        "####***E.7. Comparación y Síntesis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KvfUkS-U2r0o"
      },
      "source": [
        "En esta parte, se procedera a realizar la síntesis o resumen de los resultados obtenidos. Se empleara una comparación entre los mismos, con el objetivo de formular conclusiones apropiadas. La evaluación se desarrolla en base a distintas metricas. Entre ellas, cabe mencionar ***Exactitud, Precisión, Recall, F1 y Área bajo la curva ROC (AUC)***. Asimismo, tambien se usa el ***Promedio de métricas***, el cual constituye el promedio de los valores de todas las metricas mencionadas. Dicho promedio fue planteado con el objetivo de considerar la maximización de todas las metricas en la busqueda de los mejores hiperparametros. En la siguiente tabla, se presentan los ***hiperparametros*** que maximizan los valores de cada metrica. En ese sentido, ello permite identificar los mejores ***hiperparametros*** en base a que medida se desee optimizar. \n",
        "\n",
        "![alt text](https://i.ibb.co/5xFXKk9/03.png)\n",
        "\n",
        "De acuerdo a lo observado en la tabla anterior, es posible concluir que el mejor valor para el ***hiperparametro Pesos*** es ***Uniform***, ya que este logro ser el mejor para todas las métricas consideradas. Asimismo, respecto a ***Numero de vecinos***, no hay un valor mayoritario como en el caso anterior. No obstante, en este tipo de casos, es importante elegir un metrica para basarse en ella y analizar lo obtenido respecto a ***boxplots*** y otros elementos estadisticos. En este caso, se selecciona ***F1*** como metrica de mayor relevancia. El ***Boxplot*** de ***F1*** para ***Positivo***, es decir para la clase positiva, posee sus valores distribuidos en valores altos, siendo su limite inferior ***0.5***. Igualmente, el ***Boxplot*** de ***F1*** para ***Negativo***, es decir para la clase negativa, tambien posee sus valores distribuidos en valores altos. El valor promedio de ***F1*** para ***Negativo*** no es tan alto, ya que presenta ***outliers*** en ***0.0***. Considerando la información dada anteriormente, se concluye que ***F1***, en este caso, es un metrica de decisión apropiada. ***14*** logro ser el mejor valor para el ***hiperparametro Numero de vecinos***, en el caso de ***F1*** para ***Positivo*** y ***F1*** para ***Negativo***. Por ultimo, para el ***hiperparametro Algoritmo***, se logra determinar ***Brute*** como el valor optimo, ya que este funciona mejor para la mayoria de metricas consideradas. Por lo tanto, se concluye que los ***hiperparametros*** que logran maximizar las metricas de forma conjunta y funcionan mejor con los datos son:\n",
        "\n",
        "* ***alpha: 1***\n",
        "* ***fit_prior: True***\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NxLiJbgcdkZ",
        "colab_type": "text"
      },
      "source": [
        "##***2. Análisis de los mejores Clasificadores con Metricas de Desempeño***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K1rlESM23Kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "9fc0733a-8ec3-40e7-a521-f2ab1a147046"
      },
      "source": [
        "# Importar librerias:\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Realizar prueba con los mejores Hiperparametros para el algoritmo de KNN:\n",
        "bestknn = KNN(n_neighbors=14, weights='uniform', algorithm='brute')\n",
        "knn_acc, knn_prep, knn_recp, knn_f1p, knn_pren, knn_recn, knn_f1n, knn_auc = test_model(bestknn, df, 50)\n",
        "knn_acca, knn_prepa, knn_recpa, knn_f1pa, knn_prena, knn_recna, knn_f1na, knn_auca = test_model_array(bestknn, df, 50)\n",
        "\n",
        "# Realizar prueba con los mejores Hiperparametros para el algoritmo de Arbol de Decisión:\n",
        "bestdtc = DecisionTreeClassifier(max_depth=32, min_samples_split=0.6, min_samples_leaf=0.15, max_features='sqrt')\n",
        "ad_acc, ad_prep, ad_recp, ad_f1p, ad_pren, ad_recn, ad_f1n, ad_auc = test_model(bestdtc, df, 50)\n",
        "ad_acca, ad_prepa, ad_recpa, ad_f1pa, ad_prena, ad_recna, ad_f1na, ad_auca = test_model_array(bestdtc, df, 50)\n",
        "\n",
        "# Realizar prueba con los mejores Hiperparametros para el algoritmo de Random Forest:\n",
        "bestrfc = RFC(n_estimators=5, max_depth=2, max_features='log2', bootstrap=True)\n",
        "rf_acc, rf_prep, rf_recp, rf_f1p, rf_pren, rf_recn, rf_f1n, rf_auc = test_model(bestrfc, df, 50)\n",
        "rf_acca, rf_prepa, rf_recpa, rf_f1pa, rf_prena, rf_recna, rf_f1na, rf_auca = test_model_array(bestrfc, df, 50)\n",
        "\n",
        "# Realizar prueba con los mejores Hiperparametros para el algoritmo de Regresión Logistica:\n",
        "bestlr = LR(C=203, class_weight='balanced', solver='sag')\n",
        "lr_acc, lr_prep, lr_recp, lr_f1p, lr_pren, lr_recn, lr_f1n, lr_auc = test_model(bestlr, df, 50)\n",
        "lr_acca, lr_prepa, lr_recpa, lr_f1pa, lr_prena, lr_recna, lr_f1na, lr_auca = test_model_array(bestlr, df, 50)\n",
        "\n",
        "# Realizar prueba con los mejores Hiperparametros para el algoritmo de Redes Bayesianas Multinomiales:\n",
        "bestmnb = MultinomialNB(alpha=1, fit_prior=True)\n",
        "mnb_acc, mnb_prep, mnb_recp, mnb_f1p, mnb_pren, mnb_recn, mnb_f1n, mnb_auc = test_model(bestmnb, dfn, 50)\n",
        "mnb_acca, mnb_prepa, mnb_recpa, mnb_f1pa, mnb_prena, mnb_recna, mnb_f1na, mnb_auca = test_model_array(bestmnb, df, 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opVZuGYBcmvY",
        "colab_type": "text"
      },
      "source": [
        "####***A. Evaluación segun metrica de Exactitud (Accurancy)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0f5pnNbkU7C",
        "colab_type": "text"
      },
      "source": [
        "En las siguientes celdas de codigo, se indica la ***Exactitud (Accuracy)*** obtenida con la prueba anterior para todos los clasificadores. Cabe mencionar que se tuvieron en cuenta los mejores ***hiperparametros*** para el modelo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h22sS2l-9P7",
        "colab_type": "text"
      },
      "source": [
        "***En la siguiente celda de código se imprime la Exaxtitud obtenida con el mejor modelo del clasificador KNN.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xifDZ8pkgyOG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "4d24e9bf-5cf5-4e77-90b2-832e2b90f7b2"
      },
      "source": [
        "print(\"Exactitud (Accuracy) obtenida con mejor modelo de KNN:\", knn_acc)\n",
        "print()\n",
        "print(\"Boxplot de exactitudes obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=knn_acca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exactitud (Accuracy) obtenida con mejor modelo de KNN: 0.7700000000000001\n",
            "\n",
            "Boxplot de exactitudes obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af4b72828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWMk8AQI_W2D",
        "colab_type": "text"
      },
      "source": [
        "**En la siguiente celda de código se imprime la Exaxtitud obtenida con el mejor modelo del clasificador de Árbol de Decesión**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJNltwtBq2Fw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "930b77c2-636c-4c4b-a6c4-645d7d4c0e79"
      },
      "source": [
        "print(\"Exactitud (Accuracy) obtenida con mejor modelo de Árbol de Decisión:\", ad_acc)\n",
        "print()\n",
        "print(\"Boxplot de exactitudes obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=ad_acca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exactitud (Accuracy) obtenida con mejor modelo de Árbol de Decisión: 0.6366666666666666\n",
            "\n",
            "Boxplot de exactitudes obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af43ece80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aB3FUoCXR-tl"
      },
      "source": [
        "**En la siguiente celda de código se imprime la Exaxtitud obtenida con el mejor modelo del clasificador de Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1-wN7edR1cY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "9551879f-dd0f-405d-e919-a3fcb399ac5b"
      },
      "source": [
        "print(\"Exactitud (Accuracy) obtenida con mejor modelo de Random Forest:\", rf_acc)\n",
        "print()\n",
        "print(\"Boxplot de exactitudes obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=rf_acca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exactitud (Accuracy) obtenida con mejor modelo de Random Forest: 0.7883333333333334\n",
            "\n",
            "Boxplot de exactitudes obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b17445160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AhMz_OOVhOdm"
      },
      "source": [
        "**En la siguiente celda de código se imprime la Exaxtitud obtenida con el mejor modelo del clasificador de Regresiín Logidtica**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCG5zosuS4qy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "4c399678-3703-4484-969d-969bcd9174ce"
      },
      "source": [
        "print(\"Exactitud (Accuracy) obtenida con mejor modelo de Regresión Logistica (Logistic Regression):\", lr_acc)\n",
        "print()\n",
        "print(\"Boxplot de exactitudes obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=lr_acca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exactitud (Accuracy) obtenida con mejor modelo de Regresión Logistica (Logistic Regression): 0.7833333333333333\n",
            "\n",
            "Boxplot de exactitudes obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0399b358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WJww5KPdhWcF"
      },
      "source": [
        "**En la siguiente celda de código se imprime la Exaxtitud obtenida con el mejor modelo del clasificador de Redes Bayesianas Multinomiales**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3O2Me7-UrIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "20fe2586-10ca-4175-b8f7-282420de9de6"
      },
      "source": [
        "print(\"Exactitud (Accuracy) obtenida con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes):\", mnb_acc)\n",
        "print()\n",
        "print(\"Boxplot de exactitudes obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=mnb_acca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exactitud (Accuracy) obtenida con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes): 0.7516666666666668\n",
            "\n",
            "Boxplot de exactitudes obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f7251d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iHu68thjgI8S"
      },
      "source": [
        "####***B. Evaluación segun metrica de Precisión (Precision)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ut6dzl7Y3u7G"
      },
      "source": [
        "En el siguiente codigo, se indica la ***Precisión (Precision)*** obtenida con la prueba anterior. Cabe mencionar que se tuvieron en cuenta los mejores ***hiperparametros*** para cada modelo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qjq-9NXmj3e",
        "colab_type": "text"
      },
      "source": [
        "#####***B.1. Precisión para clase Positiva***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cwqqtbEphiaK"
      },
      "source": [
        "***En la siguiente celda de código se imprime la  Precisión obtenida con el mejor modelo del clasificador KNN. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqVnHowbkSEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "4a0f0e84-bc51-4d5d-ac8c-a03016eb5856"
      },
      "source": [
        "print(\"Precisión (Precision) para Valoracin Positiva (clase positiva) obtenida con mejor modelo de KNN:\", knn_prep)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=knn_prepa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión (Precision) para Valoracin Positiva (clase positiva) obtenida con mejor modelo de KNN: 0.8133333333333335\n",
            "\n",
            "Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f978f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASSklEQVR4nO3db2xbd73H8U984nJhadfaONYJ3ciajtaCgPgjENqfwtLhsjlKpNFlMmL8EUZ0iD4ARLKJxokKHZ6m8aAwpvVBt8pDQlmFQr3STKvEnVqNPpiQFs20g9ZdGbhJZi9b0zLFPfZ9sEvuzdLGx4mzk/x4v6RJSfeNzzdb9e7Rr7bTUKlUKgIAGMfn9QIAgKVB4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAzV6PUC/98bb1xUuczT8gHADZ+vQevWXXPVf7+sAl8uVwg8ANQJRzQAYCgCDwCGIvAAYKiqgU+lUrrtttu0adMmvfLKK1eccRxHg4OD2rp1q26//XYNDQ3VfVEAQG2qBr6jo0NPPfWUPvShD1115tChQzp37pyeffZZ/fa3v9XevXv12muv1XVRAEBtqgb+M5/5jGzbnnfm8OHD2r59u3w+nwKBgLZu3aojR47UbUkAQO3q8jTJfD6vlpaWmc9t29b58+fr8dDvqYcfflC53Gmv11gWLl++LMe57PUaWGYsq1GNjcvq2dWeueGGNv3oR/d7vca8ltX/qWCwydPrv/lmUf/6178k37L6z+KNSlniZ8HgXcoVRyWH3xcqX9abbxYVCq32epN51aVktm3rn//8pz7+8Y9LmntH71ahMOXpC52amtbI+sC0PvDhDs92ALD8XXr1qJqa1mhi4oKne/h8DfPeGNflaZLbtm3T0NCQyuWyisWinnvuOUWj0Xo8NABggaoG/qc//aluvfVWnT9/Xt/85jd15513SpISiYRGR0clSV1dXVq/fr2+9KUv6e6779b3vvc9XXfddUu7OQBgXg3L6Ydue31Ek0rt1t/+/jpHNADmdenVo9p43QfV27vL0z3ekyMaAMDyQ+ABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAM5SrwuVxOPT09ikaj6unp0dmzZ+fMTExMaMeOHers7NSXv/xlDQ8P13tXAEANXAU+mUwqHo9rZGRE8Xhc/f39c2Z+/vOf62Mf+5gOHTqkp556Sr/4xS+Uz+frvjAAwJ2qgS8UCspms4rFYpKkWCymbDarYrE4a+7kyZO65ZZbJEmBQECbN2/WH/7whyVYGQDgRmO1gXw+r3A4LMuyJEmWZam5uVn5fF6BQGBm7qMf/agOHz6s9vZ2vfbaa/rzn/+s9evX17RMMNhU4/r15fdbnl4fwMrh91sKhVZ7vca8qgberb6+Pu3Zs0ddXV1qaWnR5z//+Zk/FNwqFKZULlfqtVLNSiXHs2sDWFlKJUcTExc83cHna5j3xrhq4G3b1tjYmBzHkWVZchxH4+Pjsm171lwgENDDDz8883kikdDGjRsXsToAYDGqnsEHg0FFIhFlMhlJUiaTUSQSmXU8I0lvvPGGLl++LEl64YUX9Morr8yc2wMA3nuujmgGBgbU19enRx99VGvWrFEqlZL0zl36zp071d7erpdeekk/+9nP5PP5tG7dOj322GN6//vfv6TLAwCuzlXg29raNDQ0NOfX9+3bN/Pxli1btGXLlvptBgBYFF7JCgCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYChXP3Q7l8upr69Pk5OTWrt2rVKplFpbW2fNFAoF3X///crn87p8+bI+97nP6Sc/+YkaG11dAgBQZ67u4JPJpOLxuEZGRhSPx9Xf3z9n5rHHHlNbW5sOHTqk3//+93r55Zf17LPP1n1hAIA7VQNfKBSUzWYVi8UkSbFYTNlsVsVicdZcQ0ODLl68qHK5rOnpaZVKJYXD4aXZGgBQVdXA5/N5hcNhWZYlSbIsS83Nzcrn87Pm7rvvPuVyOd18880z/3z6059emq0BAFXV7YD8yJEj2rRpk5588kldvHhRiURCR44c0bZt21w/RjDYVK91FsTvtzy9PoCVw++3FAqt9nqNeVUNvG3bGhsbk+M4sixLjuNofHxctm3Pmkun09qzZ498Pp9Wr16t2267TSdOnKgp8IXClMrlSu3fRZ2USo5n1wawspRKjiYmLni6g8/XMO+NcdUjmmAwqEgkokwmI0nKZDKKRCIKBAKz5tavX6/nn39ekjQ9Pa0XXnhBN95442J2BwAsgqtn0QwMDCidTisajSqdTmtwcFCSlEgkNDo6Kkl64IEH9OKLL6qzs1Pd3d1qbW3V3XffvXSbAwDm5eoMvq2tTUNDQ3N+fd++fTMfX3/99dq/f3/9NgMALAqvZAUAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQzW6Gcrlcurr69Pk5KTWrl2rVCql1tbWWTM//vGPderUqZnPT506pV/96lfq6Oio68IAAHdcBT6ZTCoej6urq0vDw8Pq7+/XgQMHZs089NBDMx+fPHlSX//613XLLbfUd1sAgGtVj2gKhYKy2axisZgkKRaLKZvNqlgsXvVrnn76aXV2dmrVqlX12xQAUJOqgc/n8wqHw7IsS5JkWZaam5uVz+evOD89Pa1Dhw7prrvuqu+mAICauDqiqcVzzz2nlpYWRSKRmr82GGyq9zo18fstT68PYOXw+y2FQqu9XmNeVQNv27bGxsbkOI4sy5LjOBofH5dt21ecP3jw4ILv3guFKZXLlQV9bT2USo5n1wawspRKjiYmLni6g8/XMO+NcdUjmmAwqEgkokwmI0nKZDKKRCIKBAJzZs+fP68XX3xRnZ2di1gZAFAPrp4HPzAwoHQ6rWg0qnQ6rcHBQUlSIpHQ6OjozNzvfvc7ffGLX9S11167NNsCAFxzdQbf1tamoaGhOb++b9++WZ/v2LGjPlsBABaNV7ICgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKFcBT6Xy6mnp0fRaFQ9PT06e/bsFecOHz6szs5OxWIxdXZ26vXXX6/nrgCAGjS6GUomk4rH4+rq6tLw8LD6+/t14MCBWTOjo6P65S9/qSeffFKhUEgXLlzQqlWrlmRpAEB1Ve/gC4WCstmsYrGYJCkWiymbzapYLM6ae+KJJ/Stb31LoVBIkrR69Wq9733vW4KVAQBuVL2Dz+fzCofDsixLkmRZlpqbm5XP5xUIBGbmTp8+rfXr1+urX/2qLl26pNtvv107duxQQ0OD62WCwaYFfAv14/dbnl4fwMrh91sKhVZ7vca8XB3RuOE4jk6dOqX9+/drenpa3/72t9XS0qLu7m7Xj1EoTKlcrtRrpZqVSo5n1wawspRKjiYmLni6g8/XMO+NcdUjGtu2NTY2Jsd5J36O42h8fFy2bc+aa2lp0bZt27Rq1So1NTWpo6NDL7300iLXBwAsVNXAB4NBRSIRZTIZSVImk1EkEpl1PCO9czZ/7NgxVSoVlUol/elPf9LmzZuXZmsAQFWuniY5MDCgdDqtaDSqdDqtwcFBSVIikdDo6Kgk6c4771QwGNQdd9yh7u5ubdy4UV/5yleWbnMAwLwaKpWKd4fe7+L1GXwqtVt/+/vr+sCHOzzbAcDyd+nVo9p43QfV27vL0z0WfQYPAFiZCDwAGIrAA4ChCDwAGIrAA4ChCDwAGIrAA4ChCDwAGIrAA4ChCDwAGIrAA4ChCDwAGIrAA4ChCDwAGIrAA4ChCDwAGIrAA4ChCDwAGIrAA4ChCDwAGKrRzVAul1NfX58mJye1du1apVIptba2zprZu3evfvOb36i5uVmS9KlPfUrJZLLuCwMA3HEV+GQyqXg8rq6uLg0PD6u/v18HDhyYM9fd3a3e3t66LwkAqF3VI5pCoaBsNqtYLCZJisViymazKhaLS74cAGDhqt7B5/N5hcNhWZYlSbIsS83Nzcrn8woEArNmn3nmGR07dkyhUEjf//739clPfnJptl5CztuTuvTqUa/XwDJRvvy2JMnX+F8eb4LlxHl7UtIHvV6jKldHNG7cc889+u53vyu/36/jx4/rvvvu0+HDh7Vu3TrXjxEMNtVrnQXZtOlG+f2WpztgeTlz5owkacOGsMebYHkJa8OGDQqFVnu9yLyqBt62bY2NjclxHFmWJcdxND4+Ltu2Z82FQqGZj2+66SbZtq2//vWv+uxnP+t6mUJhSuVypYb166u7+x7Pro3lKZXaLUn6wQ8e8HgTLEcTExc8vb7P1zDvjXHVM/hgMKhIJKJMJiNJymQyikQic45nxsbGZj7+y1/+on/84x+64YYbFro3AGCRXB3RDAwMqK+vT48++qjWrFmjVColSUokEtq5c6fa29v1yCOP6OWXX5bP55Pf79dDDz00664eAPDeaqhUKt6dibyL10c0wLv9+4imt3eXx5sAcy36iAYAsDIReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEO5Cnwul1NPT4+i0ah6enp09uzZq86eOXNGn/jEJ5RKpeq1IwBgAVwFPplMKh6Pa2RkRPF4XP39/VeccxxHyWRSW7dureuSAIDaVQ18oVBQNptVLBaTJMViMWWzWRWLxTmzjz/+uL7whS+otbW17osCAGpTNfD5fF7hcFiWZUmSLMtSc3Oz8vn8rLmTJ0/q2LFj+sY3vrEkiwIAatNYjwcplUratWuXHnzwwZk/CBYiGGyqxzpA3fj97/x+DoVWe7wJULuqgbdtW2NjY3IcR5ZlyXEcjY+Py7btmZmJiQmdO3dO3/nOdyRJb731liqViqamprR7927XyxQKUyqXKwv4NoClUSo5kqSJiQsebwLM5fM1zHtjXDXwwWBQkUhEmUxGXV1dymQyikQiCgQCMzMtLS06ceLEzOd79+7VpUuX1Nvbu8j1AQAL5epZNAMDA0qn04pGo0qn0xocHJQkJRIJjY6OLumCAICFaahUKsvmTIQjGiw3qdQ7R4y9vbs83gSYq9oRDa9kBQBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBD8W6SuKLjx5/XsWP/7fUanjt37lVJ0vXXf9jjTZaHm2/eoptuutXrNfC/Fv0DP4D/ZNdee63XKwALxh08AKxQvB88APyHIvAAYCgCDwCGIvAAYCgCDwCGcvU0yVwup76+Pk1OTmrt2rVKpVJqbW2dNXPw4EE98cQT8vl8KpfL2r59u+69996l2BkA4IKrp0nee++9uuuuu9TV1aXh4WEdPHhQBw4cmDUzNTWla665Rg0NDZqamlJnZ6d+/etfa/Pmza6X4WmSAODeol/oVCgUlM1mtX//fklSLBbT7t27VSwWFQgEZuaamv7vIm+//bZKpZIaGhpqXhYA4E61ZlYNfD6fVzgclmVZkiTLstTc3Kx8Pj8r8JJ09OhRPfLIIzp37px++MMfatOmTTUtu27dNTXNAwCurq5/ydrR0aFnnnlGIyMjGh4e1pkzZ+r58ACAGlQNvG3bGhsbk+M4kiTHcTQ+Pi7btq/6NS0tLWpvb9cf//jHui0KAKhN1cAHg0FFIhFlMhlJUiaTUSQSmXM8c/r06ZmPi8WiTpw4oY985CN1XhcA4JarZ9GcPn1afX19euutt7RmzRqlUilt2LBBiURCO3fuVHt7u/bs2aPjx4+rsbFRlUpF27dv19e+9rX34nsAAFzBsno3SQBA/fBKVgAwFIEHAEMReAAwFIEHAEMReGAeuVxOPT09ikaj6unp0dmzZ71eCXCNwAPzSCaTisfjGhkZUTweV39/v9crAa4ReOAq/v1Ge7FYTNI7b7SXzWZVLBY93gxwh8ADVzHfG+0BKwGBBwBDEXjgKhbyRnvAckLggatw+0Z7wHLFe9EA87jaG+0BKwGBBwBDcUQDAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgqP8BVHD/N208jwQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KdOVi1l8huVq"
      },
      "source": [
        "***En la siguiente celda de código se imprime la  Precisión obtenida con el mejor modelo del clasificador Árbol de Decisión. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMQEiT3frZtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "ca87c906-dc51-45a3-d19e-5c026b3aca99"
      },
      "source": [
        "print(\"Precisión (Precision) Valoracin Positiva (clase positiva) obtenida con mejor modelo de Árbol de Decisión:\", ad_prep)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=ad_prepa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión (Precision) Valoracin Positiva (clase positiva) obtenida con mejor modelo de Árbol de Decisión: 0.78\n",
            "\n",
            "Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0fa05c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OulHTEZ5h04A"
      },
      "source": [
        "***En la siguiente celda de código se imprime la  Precisión obtenida con el mejor modelo del clasificador Random Forest. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvWnmStjSF58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "97161b05-9447-4485-c462-5d5f7c3fa0af"
      },
      "source": [
        "print(\"Precisión (Precision) Valoracin Positivae (clase positiva) obtenida con mejor modelo de Random Forest:\", rf_prep)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=rf_prepa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión (Precision) Valoracin Positivae (clase positiva) obtenida con mejor modelo de Random Forest: 0.7700000000000001\n",
            "\n",
            "Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0fa24a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPi0lEQVR4nO3dX2zT9cLH8c/621B82MJZ3cZvAu6ABhsDXugJF0d8DAy7SHFolCbFGwnlQqMJyTGbRtYVTEyTc6MoMZqIkHpBdiOHhrAFLx4zo5gYExYbMAc3JuHHNtsz+R/Kr30uOCFnz6TtoONXvs/7deXky/oR59vmuy6tKRQKBQEAjOPzegAAYHYQeAAwFIEHAEMReAAwFIEHAEMReAAwFIEHAEPVej3gP/3rXxeVz/OyfAAoh89Xoz/96b9u+utVFfh8vkDgAaBCuKIBAEMReAAwFIEHAEOVDHwikdDq1au1bNky/fzzz394xnVdxeNxtbe3a+3aterr66v4UADAzJQM/Jo1a/TFF1/ogQceuOmZgwcPanR0VAMDA9q/f7927dql06dPV3QoAGBmSgb+iSeekG3bRc8cOnRIL730knw+nxobG9Xe3q7Dhw9XbCQAYOYq8jJJx3HU2tp642PbtnX27NlKfOo76u9/f0/Dwye9nlEVrl27Jte95vUMVBnLqlVtbVW9utozf/7zUv3tb295PaOoqvo35ffP8/Txf/89q8uXL0u+qvpj8UYhL/FeMPg/8gVXOZevC+Wv6fffs2pqqvd6SVEVKZlt2zpz5oxWrFghafoz+nJlMhc8/UGnefMaZN13Vfc9uMazDQCq36VTX2nevAZNTJz3dIfPV1P0iXFFXibZ0dGhvr4+5fN5ZbNZHTlyRMFgsBKfGgBwi0oG/t1339VTTz2ls2fP6pVXXtG6deskSdFoVENDQ5Kkzs5OLVy4UM8884w2btyo1157TYsWLZrd5QCAomqq6U23vb6iSSR26p+//sYVDYCiLp36Sg8tul9dXds93XFHrmgAANWHwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiKwAOAoQg8ABiqtpxDw8PD6u7u1uTkpObPn69EIqG2trYpZzKZjN566y05jqNr165p5cqVeuedd1RbW9ZDAAAqrKxn8LFYTJFIRP39/YpEIurp6Zl25uOPP9bSpUt18OBB/eMf/9BPP/2kgYGBig8GAJSnZOAzmYzS6bRCoZAkKRQKKZ1OK5vNTjlXU1OjixcvKp/P6+rVq8rlcmppaZmd1QCAkkrenziOo5aWFlmWJUmyLEvNzc1yHEeNjY03zr366qt6/fXX9eSTT+ry5cvatGmTHn/88RmN8fvnzXB+ZdXVWZ4+PoC7R12dpaameq9nFFWxC/LDhw9r2bJl2rt3ry5evKhoNKrDhw+ro6Oj7M+RyVxQPl+o1KQZy+Vczx4bwN0ll3M1MXHe0w0+X03RJ8Ylr2hs29bY2Jhc93r8XNfV+Pi4bNueci6ZTOq5556Tz+dTfX29Vq9eraNHj97mfADArSoZeL/fr0AgoFQqJUlKpVIKBAJTrmckaeHChfr6668lSVevXtW3336rhx9+eBYmAwDKUdaraHp7e5VMJhUMBpVMJhWPxyVJ0WhUQ0NDkqS3335bP/zwg9avX68NGzaora1NGzdunL3lAICiyrqDX7p0qfr6+qb9/U8//fTGXy9evFh79uyp3DIAwG3hJ1kBwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMVVbgh4eHFQ6HFQwGFQ6HNTIy8ofnDh06pPXr1ysUCmn9+vX67bffKrkVADADteUcisViikQi6uzs1IEDB9TT06N9+/ZNOTM0NKQPP/xQe/fuVVNTk86fP685c+bMymgAQGkln8FnMhml02mFQiFJUigUUjqdVjabnXLu888/1+bNm9XU1CRJqq+v1z333DMLkwEA5SgZeMdx1NLSIsuyJEmWZam5uVmO40w5d/LkSf3666/atGmTnn/+ee3evVuFQmF2VgMASirriqYcruvqxIkT2rNnj65evaotW7aotbVVGzZsKPtz+P3zKjXnltTVWZ4+PoC7R12dpaameq9nFFUy8LZta2xsTK7ryrIsua6r8fFx2bY95Vxra6s6Ojo0Z84czZkzR2vWrNGxY8dmFPhM5oLyee+e9edyrmePDeDuksu5mpg47+kGn6+m6BPjklc0fr9fgUBAqVRKkpRKpRQIBNTY2DjlXCgU0uDgoAqFgnK5nL777js98sgjtzkfAHCrynqZZG9vr5LJpILBoJLJpOLxuCQpGo1qaGhIkrRu3Tr5/X49++yz2rBhgx566CG9+OKLs7ccAFBUTaGKvhPq9RVNIrFT//z1N9334BrPNgCofpdOfaWHFt2vrq7tnu647SsaAMDdicADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEq9pZ9pnCvTOrSqa+8noEqkb92RZLkq73X4yWoJu6VSUn3ez2jJAL/HxYtetDrCagyo6OnJEmLF1X/f8y4k+6/K3rBG34ARSQSOyXJ8zd2AP4Ib/gBAP9PEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMFRZgR8eHlY4HFYwGFQ4HNbIyMhNz/7yyy967LHHlEgkKrURAHALygp8LBZTJBJRf3+/IpGIenp6/vCc67qKxWJqb2+v6EgAwMyVDHwmk1E6nVYoFJIkhUIhpdNpZbPZaWc/+eQTPf3002pra6v4UADAzJR8yz7HcdTS0iLLsiRJlmWpublZjuOosbHxxrnjx49rcHBQ+/bt0+7du29pTLF3JgG8UFd3/eu+qane4yXAzFXkPVlzuZy2b9+u995778b/CG4Fb9mHapPLuZKkiYnzHi8Bpiv1ln0lA2/btsbGxuS6rizLkuu6Gh8fl23bN85MTExodHRUW7dulSSdO3dOhUJBFy5c0M6dOyvwjwEAmKmSgff7/QoEAkqlUurs7FQqlVIgEJhyPdPa2qqjR4/e+HjXrl26dOmSurq6Zmc1AKCksl5F09vbq2QyqWAwqGQyqXg8LkmKRqMaGhqa1YEAgFtTUygUqubSmzt4VJtE4voVY1fXdo+XANOVuoPnJ1kBwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMVVvOoeHhYXV3d2tyclLz589XIpFQW1vblDMfffSRDh06JJ/Pp7q6Om3btk2rVq2ajc0AgDKUFfhYLKZIJKLOzk4dOHBAPT092rdv35QzK1as0ObNmzV37lwdP35cL7/8sgYHB3XvvffOynAAQHElr2gymYzS6bRCoZAkKRQKKZ1OK5vNTjm3atUqzZ07V5K0bNkyFQoFTU5OzsJkAEA5SgbecRy1tLTIsixJkmVZam5uluM4N/09X375pRYvXqwFCxZUbikAYEbKuqKZie+//17vv/++Pvvssxn/Xr9/XqXnALelru76E5umpnqPlwAzVzLwtm1rbGxMruvKsiy5rqvx8XHZtj3t7I8//qg333xTu3fv1pIlS2Y8JpO5oHy+MOPfB8yWXM6VJE1MnPd4CTCdz1dT9IlxySsav9+vQCCgVColSUqlUgoEAmpsbJxy7tixY9q2bZs++OADPfroo7c5GwBwu8p6HXxvb6+SyaSCwaCSyaTi8bgkKRqNamhoSJIUj8d15coV9fT0qLOzU52dnTpx4sTsLQcAFFVTKBSq5k6EKxpUm0RipySpq2u7x0uA6W77igYAcHci8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYqK/DDw8MKh8MKBoMKh8MaGRmZdsZ1XcXjcbW3t2vt2rXq6+ur9FYAwAyUFfhYLKZIJKL+/n5FIhH19PRMO3Pw4EGNjo5qYGBA+/fv165du3T69OmKDwYAlKemUCgUih3IZDIKBoM6evSoLMuS67pauXKlBgYG1NjYeOPc1q1b9cILL6ijo0OStGPHDrW2tmrLli1lj8lkLiifLzoHd8g333ytwcH/8XqG50ZHT0mSFi9+0OMl1eHJJ/9bf/3rU17PwL/5fDXy++fd9NdrS30Cx3HU0tIiy7IkSZZlqbm5WY7jTAm84zhqbW298bFt2zp79uyMxhYbijuroWGu6uosr2d4zu+//jXOn8V1DQ1z1dRU7/UMlKlk4O8knsFXj+XL/6Lly//i9QxUoYmJ815PwL+VegZf8g7etm2NjY3JdV1J17+ZOj4+Ltu2p507c+bMjY8dx9GCBQtudTcA4DaVDLzf71cgEFAqlZIkpVIpBQKBKdczktTR0aG+vj7l83lls1kdOXJEwWBwdlYDAEoq+U1WSTp58qS6u7t17tw5NTQ0KJFIaMmSJYpGo3rjjTe0fPlyua6rHTt26JtvvpEkRaNRhcPhGY3higYAylfqiqaswN8pBB4Aynfbd/AAgLsTgQcAQxF4ADBUVb0O3uer8XoCANw1SjWzqr7JCgCoHK5oAMBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4oYnh4WOFwWMFgUOFwWCMjI15PAspG4IEiYrGYIpGI+vv7FYlE1NPT4/UkoGwEHriJTCajdDqtUCgkSQqFQkqn08pmsx4vA8pD4IGbcBxHLS0tsixLkmRZlpqbm+U4jsfLgPIQeAAwFIEHbsK2bY2Njcl1XUmS67oaHx+XbdseLwPKQ+CBm/D7/QoEAkqlUpKkVCqlQCCgxsZGj5cB5eENP4AiTp48qe7ubp07d04NDQ1KJBJasmSJ17OAshB4ADAUVzQAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCG+l9CfxQp/7D8sAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uE1UCTJsh459"
      },
      "source": [
        "***En la siguiente celda de código se imprime la  Precisión obtenida con el mejor modelo del clasificador Regresión Logistica. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUWA_Z2TTP2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "6ae3ddfb-661f-452f-ea7d-ab97eba8865c"
      },
      "source": [
        "print(\"Precisión (Precision) Valoracin Positiva (clase positiva) obtenida con mejor modelo de Regresión Logistica (Logistic Regression):\", lr_prep)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=lr_prepa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión (Precision) Valoracin Positiva (clase positiva) obtenida con mejor modelo de Regresión Logistica (Logistic Regression): 0.7866666666666668\n",
            "\n",
            "Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0faa99b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Eheirc2Rh9xE"
      },
      "source": [
        "***En la siguiente celda de código se imprime la  Precisión obtenida con el mejor modelo del clasificador Redes Bayesianas Multinomiales. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHfhqmeKU43_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "e786105e-3127-4142-f779-c25615971a79"
      },
      "source": [
        "print(\"Precisión (Precision) para Fraude (clase positiva) obtenida con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes):\", mnb_prep)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=mnb_prepa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión (Precision) para Fraude (clase positiva) obtenida con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes): 0.77\n",
            "\n",
            "Boxplot de precisiónes (clase positiva) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f704128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "55hjhJWcmyVK"
      },
      "source": [
        "#####***B.2. Precisión para clase Negativa***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k8OjVqRViQAF"
      },
      "source": [
        "***En la siguiente celda de código se imprime la  Precisión obtenida con el mejor modelo del clasificador KNN. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mscj6K5CmHDH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "d8475ce9-5ae9-44db-a8db-025e1a6c68a6"
      },
      "source": [
        "print(\"Precisión (Precision) para Valoracin Negativa (clase negativa) obtenida con mejor modelo de KNN:\", knn_pren)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=knn_prena)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión (Precision) para Valoracin Negativa (clase negativa) obtenida con mejor modelo de KNN: 0.7933333333333333\n",
            "\n",
            "Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0fae9748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XO8F6SeSiSYG"
      },
      "source": [
        "***En la siguiente celda de código se imprime la  Precisión obtenida con el mejor modelo del clasificador Árbol de Decisión. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB1J6Vdardj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "19dd118f-a1dc-4d77-a98d-837406ddb33a"
      },
      "source": [
        "print(\"Precisión (Precision) para Valoracin Negativa (clase negativa) obtenida con mejor modelo de Árbol de Decisión:\", ad_pren)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=ad_prena)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión (Precision) para Valoracin Negativa (clase negativa) obtenida con mejor modelo de Árbol de Decisión: 0.7\n",
            "\n",
            "Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0fb997f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3R2mLHk6iWIk"
      },
      "source": [
        "***En la siguiente celda de código se imprime la  Precisión obtenida con el mejor modelo del clasificador Random Forest. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV_jv7fPSIAk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "95fde06d-d07c-4c80-c704-fa8510c62b98"
      },
      "source": [
        "print(\"Precisión (Precision) para Valoracin Negativa (clase negativa) obtenida con mejor modelo de Random Forest:\", rf_pren)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=rf_prena)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión (Precision) para Valoracin Negativa (clase negativa) obtenida con mejor modelo de Random Forest: 0.77\n",
            "\n",
            "Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0b6c4b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jbEvlTNZiaj3"
      },
      "source": [
        "***En la siguiente celda de código se imprime la  Precisión obtenida con el mejor modelo del clasificador Regresión Logistica. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fazz4fzOTTvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "1ff04616-ddbe-4bde-c1bc-af3e45cc589d"
      },
      "source": [
        "print(\"Precisión (Precision) para Valoracin Negativa (clase negativa) obtenida con mejor modelo de Regresión Logistica (Logistic Regression):\", lr_pren)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=lr_prena)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión (Precision) para Valoracin Negativa (clase negativa) obtenida con mejor modelo de Regresión Logistica (Logistic Regression): 0.7333333333333333\n",
            "\n",
            "Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0afe03ccf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RWdfWdh2ienR"
      },
      "source": [
        "***En la siguiente celda de código se imprime la  Precisión obtenida con el mejor modelo del clasificador Redes Bayesianas Multinomiales. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioGL9HATU8Vz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "597d8704-adb6-499d-88dc-bf30dacafab6"
      },
      "source": [
        "print(\"Precisión (Precision) para No fraude (clase negativa) obtenida con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes):\", mnb_pren)\n",
        "print()\n",
        "print(\"Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\")\n",
        "sns.boxplot(data=mnb_prena)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión (Precision) para No fraude (clase negativa) obtenida con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes): 0.75\n",
            "\n",
            "Boxplot de precisiónes (clase negativa) obtenidas en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f66ec18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ekTZjj6NgKUR"
      },
      "source": [
        "####***C. Evaluación segun metrica de Recall***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKG0v-qQphly",
        "colab_type": "text"
      },
      "source": [
        "En el siguiente codigo, se indica el ***Recall*** obtenido con la prueba anterior. Cabe mencionar que se tuvieron en cuenta los mejores ***hiperparametros*** para cada modelo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t7vXGJHenX_Q"
      },
      "source": [
        "#####***C.1. Recall para clase Positiva***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mITFnYKPim6z"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Recall obtenido con el mejor modelo del clasificador KNN. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5567LEHnUj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "e6a274b0-1351-4067-ea61-7116a9a4eea6"
      },
      "source": [
        "print(\"Recall para Fraude (clase positiva) obtenido con mejor modelo de KNN:\", knn_recp)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=knn_recpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall para Fraude (clase positiva) obtenido con mejor modelo de KNN: 0.88\n",
            "\n",
            "Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af45b9780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mEZ3z6iyjDLq"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Recall obtenido con el mejor modelo del clasificador Árbol de Decisión. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqmw52HGr5tO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "db5212e6-c6cd-47f9-ce8f-ff0e1c70ef35"
      },
      "source": [
        "print(\"Recall para Fraude (clase positiva) obtenido con mejor modelo de Árbol de Decisión:\", ad_recp)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=ad_recpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall para Fraude (clase positiva) obtenido con mejor modelo de Árbol de Decisión: 0.65\n",
            "\n",
            "Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af423e588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkVOLoG4jG7D",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mKrw9lzcjHKC"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Recall obtenido con el mejor modelo del clasificador Random Forest. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYK87WHLSVDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "eb821bf4-80c0-46ca-c28c-42a03af75e29"
      },
      "source": [
        "print(\"Recall para Fraude (clase positiva) obtenido con mejor modelo de Random Forest:\", rf_recp)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=rf_recpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall para Fraude (clase positiva) obtenido con mejor modelo de Random Forest: 0.9\n",
            "\n",
            "Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af81ad978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3bEUH7yjK6z",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6xABsZFFjLLt"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Recall obtenido con el mejor modelo del clasificador Regresión Logistica. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdHrvD5lT2sh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "16fb39c8-0c20-4ea8-8776-2c7eb849625d"
      },
      "source": [
        "print(\"Recall para Fraude (clase positiva) obtenido con mejor modelo de Regresión Logistica (Logistic Regression):\", lr_recp)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=lr_recpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall para Fraude (clase positiva) obtenido con mejor modelo de Regresión Logistica (Logistic Regression): 0.9\n",
            "\n",
            "Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0fa2bb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPEklEQVR4nO3dYWxUdbrH8d/MwSq50sWZ0OFUNKTG1ImpvpANJoLXheI08WD1Epzs4JKrcUxWY2/YxDBGbUVN3PGdshLjC5WKuyENu2InTcuS7L1YIvjGBOIE3dQ2FTm0MGO3guYWzsx9ca/NbbCdM3Taaf/7/byb9OnMAwlfTv897QSKxWJRAADjBKu9AABgbhB4ADAUgQcAQxF4ADAUgQcAQxF4ADAUgQcAQy2p9gL/33ffXVShwG35AOBHMBjQDTf8y7QfX1CBLxSKBB4AKoQjGgAwFIEHAEMReAAwVMnAp9NpbdiwQY2Njfrqq69+dsbzPO3atUvNzc3atGmTurq6Kr4oAKA8JQO/ceNGffjhh7rxxhunnenu7tbw8LAOHTqk/fv3a/fu3Tp9+nRFFwUAlKdk4NesWSPbtmec6enp0datWxUMBhUKhdTc3Kze3t6KLQkAKF9FbpN0XVf19fWTj23b1tmzZyvx1PPq6NEj+uMfO6u9xoIwMfHf8jyv2mtggbEsSzU111Z7jQUhkdiue+65t9przGhB3QcfDl9f1devrV2qQKCqKywYAf4i8DMCgQD/Rv5Pbe1SrVixrNprzKgigbdtW2fOnNEdd9wh6corer9yuQtV/UGnpqZf6g9/+GXVXh/A4nLu3PdVff1gMDDjhXFFbpNsaWlRV1eXCoWC8vm8Dh8+rFgsVomnBgBcpZKBf/XVV3Xvvffq7Nmzeuyxx/TAAw9IkpLJpE6ePClJam1t1apVq3T//ffrkUce0dNPP62bbrppbjcHAMwosJDedLvaRzQAsJjMyxENAGDhIfAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGWuJnaHBwUKlUSmNjY1q+fLnS6bRWr149ZSaXy+m5556T67q6fPmy1q5dqxdeeEFLlvh6CQBAhfm6gu/o6FAikVBfX58SiYTa29uvmHn77bd1yy23qLu7Wx9//LG++OILHTp0qOILAwD8KRn4XC6nbDYrx3EkSY7jKJvNKp/PT5kLBAK6ePGiCoWCJiYmdOnSJUUikbnZGgBQUsnzE9d1FYlEZFmWJMmyLNXV1cl1XYVCocm5p556Ss8884zWrVunH3/8Udu2bdNdd91V1jLh8PVlrg8AmE7FDsh7e3vV2NiovXv36uLFi0omk+rt7VVLS4vv58jlLqhQKFZqJQAwWjAYmPHCuOQRjW3bGhkZked5kiTP8zQ6OirbtqfM7du3Tw8++KCCwaCWLVumDRs26Pjx47NcHwBwtUoGPhwOKxqNKpPJSJIymYyi0eiU4xlJWrVqlY4cOSJJmpiY0Keffqpbb711DlYGAPgRKBaLJc9EBgYGlEqlND4+rtraWqXTaTU0NCiZTKqtrU1NTU0aHh5WR0eHzp8/L8/ztHbtWj3//PNl3SbJEQ0A+FfqiMZX4OcLgQcA/2Z9Bg8AWJwIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYylfgBwcHFY/HFYvFFI/HNTQ09LNzPT092rx5sxzH0ebNm3X+/PlK7goAKEOgWCwWSw1t375dW7ZsUWtrqw4ePKgDBw6os7NzyszJkye1c+dO7d27VytWrND333+vmpoaXXvttb6XyeUuqFAouQ4AQFIwGFA4fP30Hy/1BLlcTtlsVo7jSJIcx1E2m1U+n58y9/777+vxxx/XihUrJEnLli0rK+4AgMoqGXjXdRWJRGRZliTJsizV1dXJdd0pcwMDA/rmm2+0bds2Pfzww9qzZ498fHEAAJgjSyr1RJ7n6csvv9R7772niYkJPfHEE6qvr9dDDz3k+zlm+lIDAFCekoG3bVsjIyPyPE+WZcnzPI2Ojsq27Slz9fX1amlpUU1NjWpqarRx40adOHGirMBzBg8A/s36DD4cDisajSqTyUiSMpmMotGoQqHQlDnHcdTf369isahLly7p2LFjuu2222a5PgDgavm6i2ZgYECpVErj4+Oqra1VOp1WQ0ODksmk2tra1NTUpEKhoHQ6rSNHjigYDGrdunXauXOngkH/t9pzBQ8A/pW6gvcV+PlC4AHAv1kf0QAAFicCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCD8zggw/e1+OPJ/SnP3WWHgYWGAIPzOBvfzskSfrrX3urvAlQPgIPTOODD96f8pireCw2BB6Yxk9X7z/hKh6LDYEHAEMReAAwFIEHpvGrX90/5fGmTS1V2gS4OgQemMZvfvPvUx7/+tfbq7MIcJUIPDCDn67iuXrHYsSbbgPAIsWbbgPAPykCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCG8hX4wcFBxeNxxWIxxeNxDQ0NTTv79ddf684771Q6na7UjgCAq+Ar8B0dHUokEurr61MikVB7e/vPznmep46ODjU3N1d0SQBA+UoGPpfLKZvNynEcSZLjOMpms8rn81fMvvPOO7rvvvu0evXqii8KACjPklIDrusqEonIsixJkmVZqqurk+u6CoVCk3OnTp1Sf3+/Ojs7tWfPnqtaZqbfigYAKE/JwPtx6dIlvfjii3rttdcm/yO4Gvy6YADwr9SvCy4ZeNu2NTIyIs/zZFmWPM/T6OiobNuenDl37pyGh4f15JNPSpLGx8dVLBZ14cIFvfLKKxX4YwAAylUy8OFwWNFoVJlMRq2trcpkMopGo1OOZ+rr63X8+PHJx7t379YPP/ygnTt3zs3WAICSfN1F89JLL2nfvn2KxWLat2+fdu3aJUlKJpM6efLknC4IALg6vGUfACxSvGUfAPyTIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYKglfoYGBweVSqU0Njam5cuXK51Oa/Xq1VNm3nrrLfX09CgYDOqaa67Rjh07tH79+rnYGQDgQ6BYLBZLDW3fvl1btmxRa2urDh48qAMHDqizs3PKzCeffKI1a9Zo6dKlOnXqlB599FH19/fruuuu871MLndBhULJdQAAkoLBgMLh66f/eKknyOVyymazchxHkuQ4jrLZrPL5/JS59evXa+nSpZKkxsZGFYtFjY2NzWZ3AMAslAy867qKRCKyLEuSZFmW6urq5LrutJ/z0Ucf6eabb9bKlSsrtykAoCy+zuDL8dlnn+mNN97Qu+++W/bnzvSlBgCgPCUDb9u2RkZG5HmeLMuS53kaHR2VbdtXzH7++ed69tlntWfPHjU0NJS9DGfwAODfrM/gw+GwotGoMpmMJCmTySgajSoUCk2ZO3HihHbs2KE333xTt99++yzXBgDMlq+7aAYGBpRKpTQ+Pq7a2lql02k1NDQomUyqra1NTU1N2rJli7799ltFIpHJz3v99dfV2Njoexmu4AHAv1JX8L4CP18IPAD4N+sjGgDA4kTgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB6YwdjYd/r971/WP/4xVu1VgLL5Cvzg4KDi8bhisZji8biGhoaumPE8T7t27VJzc7M2bdqkrq6uSu8KzLvu7r/o73//Uh9//OdqrwKUzVfgOzo6lEgk1NfXp0Qiofb29itmuru7NTw8rEOHDmn//v3avXu3Tp8+XfGFgfkyNvad+vv/S8ViUf39R7iKx6JTMvC5XE7ZbFaO40iSHMdRNptVPp+fMtfT06OtW7cqGAwqFAqpublZvb29c7M1MA+6u/+iQqEoSSoUClzFY9FZUmrAdV1FIhFZliVJsixLdXV1cl1XoVBoylx9ff3kY9u2dfbs2bKWCYevL2semEvHjh2V512WJHneZR07dlS/+91/VHkrwL+SgZ9PudyFySsmoNruvvseHTnyn/K8y7KsJbr77nt07tz31V4LmBQMBma8MC55RGPbtkZGRuR5nqT//Wbq6OiobNu+Yu7MmTOTj13X1cqVK692b6DqNm9+WMFgQJIUDAb14IP/VuWNgPKUDHw4HFY0GlUmk5EkZTIZRaPRKcczktTS0qKuri4VCgXl83kdPnxYsVhsbrYG5sHy5Tdo3bp/VSAQ0Lp19+oXv1he7ZWAsgSKxWLJM5GBgQGlUimNj4+rtrZW6XRaDQ0NSiaTamtrU1NTkzzP08svv6yjR49KkpLJpOLxeFnLcESDhWZs7Du9/fZu/fa3bQQeC06pIxpfgZ8vBB4A/Jv1GTwAYHEi8ABgKAIPAIZaUPfB/3RLGgCgtFLNXFDfZAUAVA5HNABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPzGBwcFDxeFyxWEzxeFxDQ0PVXgnwjcADM+jo6FAikVBfX58SiYTa29urvRLgG4EHppHL5ZTNZuU4jiTJcRxls1nl8/kqbwb4Q+CBabiuq0gkIsuyJEmWZamurk6u61Z5M8AfAg8AhiLwwDRs29bIyIg8z5MkeZ6n0dFR2bZd5c0Afwg8MI1wOKxoNKpMJiNJymQyikajCoVCVd4M8Ic3/ABmMDAwoFQqpfHxcdXW1iqdTquhoaHaawG+EHgAMBRHNABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIb6HzNIN26TzaY/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4LpcPivjjQ5D"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Recall obtenido con el mejor modelo del clasificador Redes Bayesianas Multinomiale. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiN4SvB3VMuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "51585b73-8b51-4ee5-9d91-c1873604d884"
      },
      "source": [
        "print(\"Recall para Fraude (clase positiva) obtenido con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes):\", mnb_recp)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=mnb_recpa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall para Fraude (clase positiva) obtenido con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes): 0.77\n",
            "\n",
            "Boxplot de recalls (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f621eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kV5EPJ4enbdL"
      },
      "source": [
        "#####***C.2. Recall para clase Negativa*** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EnP5qBy6jVuk"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Recall obtenido con el mejor modelo del clasificador KNN. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vA-LA0fnecq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "7aa8489e-dd42-47c0-eed3-62eb991e8379"
      },
      "source": [
        "print(\"Recall para No fraude (clase negativa) obtenido con mejor modelo de KNN:\", knn_recn)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=knn_recna)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall para No fraude (clase negativa) obtenido con mejor modelo de KNN: 0.67\n",
            "\n",
            "Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af45904a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Du7vZMzRjaqt"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Recall obtenido con el mejor modelo del clasificador Árbol de Decisión. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAPOoiB4r8cq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "36f6e36e-43a6-4fdb-ff4f-3f1d7cb39211"
      },
      "source": [
        "print(\"Recall para No fraude (clase negativa) obtenido con mejor modelo de Árbol de Decisión:\", ad_recn)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=ad_recna)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall para No fraude (clase negativa) obtenido con mejor modelo de Árbol de Decisión: 0.72\n",
            "\n",
            "Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af420ac88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kWOnpr05jeWX"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Recall obtenido con el mejor modelo del clasificador Random Forest. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQE7nc-GSW8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "d60ab0b8-24d5-4664-b3ed-fc02438aec0e"
      },
      "source": [
        "print(\"Recall para No fraude (clase negativa) obtenido con mejor modelo de Random Forest:\", rf_recn)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=rf_recna)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall para No fraude (clase negativa) obtenido con mejor modelo de Random Forest: 0.69\n",
            "\n",
            "Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af81adf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v6pIKlNrjm58"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Recall obtenido con el mejor modelo del clasificador Regresión Logistica. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyYTCEXTT4X1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "a6cdb626-1984-4ba6-8175-6cc5bfdbb9af"
      },
      "source": [
        "print(\"Recall para No fraude (clase negativa) obtenido con mejor modelo de Regresión Logistica (Logistic Regression):\", lr_recn)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=lr_recna)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall para No fraude (clase negativa) obtenido con mejor modelo de Regresión Logistica (Logistic Regression): 0.68\n",
            "\n",
            "Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f8b6898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EBXfa6Ftjsay"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Recall obtenido con el mejor modelo del clasificador Redes Bayesianas Multinomiales. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGKhJAqzVPRn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "af202dac-654d-48a8-aae7-f2b48b216052"
      },
      "source": [
        "print(\"Recall para No fraude (clase negativa) obtenido con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes):\", mnb_recn)\n",
        "print()\n",
        "print(\"Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=mnb_recna)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall para No fraude (clase negativa) obtenido con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes): 0.85\n",
            "\n",
            "Boxplot de recalls (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f6196d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pcvl7d4ogJGG"
      },
      "source": [
        "####***D. Evaluación segun metrica de F1***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k963hev-3ySG"
      },
      "source": [
        "En el siguiente codigo, se indica el ***F1*** obtenido con la prueba anterior. Cabe mencionar que se tuvieron en cuenta los mejores ***hiperparametros*** para cada modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OpCDOulBoTyp"
      },
      "source": [
        "#####***D.1. F1 para clase Positiva***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MebUPaCyj0_j"
      },
      "source": [
        "***En la siguiente celda de código se imprime el F1 obtenido con el mejor modelo del clasificador KNN. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEMWiEIpoQqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "ef2a8c11-5a21-4852-b3e1-324a8ef5067f"
      },
      "source": [
        "print(\"F1 para Fraude (clase positiva) obtenido con mejor modelo de KNN:\", knn_f1p)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=knn_f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 para Fraude (clase positiva) obtenido con mejor modelo de KNN: 0.7933333333333334\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af4072a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2H3FFktdj58f"
      },
      "source": [
        "***En la siguiente celda de código se imprime el F1 obtenido con el mejor modelo del clasificador Árbol de Decisión. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRtTBLdksKOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "efb764af-e030-44c2-b93c-963b2ace0449"
      },
      "source": [
        "print(\"F1 para Fraude (clase positiva) obtenido con mejor modelo de Árbol de Decisión:\", ad_f1p)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=ad_f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 para Fraude (clase positiva) obtenido con mejor modelo de Árbol de Decisión: 0.5606666666666668\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af41bbb70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b_rCfm8Tj_uc"
      },
      "source": [
        "***En la siguiente celda de código se imprime el F1 obtenido con el mejor modelo del clasificador Random Forest. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0KYkDwcSlRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "32674fb4-b87f-4904-ef44-66939892ace2"
      },
      "source": [
        "print(\"F1 para Fraude (clase positiva) obtenido con mejor modelo de Random Forest:\", rf_f1p)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=rf_f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 para Fraude (clase positiva) obtenido con mejor modelo de Random Forest: 0.8033333333333332\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b02b531d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NF0OPJb5kGGp"
      },
      "source": [
        "***En la siguiente celda de código se imprime el F1 obtenido con el mejor modelo del clasificador Regresión Logistica. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFYZtn5dUNEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "5a22cd55-0fee-462a-adb2-4bbc2ed45e61"
      },
      "source": [
        "print(\"F1 para Fraude (clase positiva) obtenido con mejor modelo de Regresión Logistica (Logistic Regression):\", lr_f1p)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=lr_f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 para Fraude (clase positiva) obtenido con mejor modelo de Regresión Logistica (Logistic Regression): 0.81\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f81e7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MRcu-2KXkM1w"
      },
      "source": [
        "***En la siguiente celda de código se imprime el F1 obtenido con el mejor modelo del clasificador Redes Bayesianas Multinomiales. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVYlKLSMVdS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "04f0faf1-d373-435b-d592-275b333caef6"
      },
      "source": [
        "print(\"F1 para Fraude (clase positiva) obtenido con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes):\", mnb_f1p)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=mnb_f1pa)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 para Fraude (clase positiva) obtenido con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes): 0.7233333333333334\n",
            "\n",
            "Boxplot de f1s (clase positiva) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f57c160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a4UgR9p-oaP6"
      },
      "source": [
        "#####***D.2. F1 para clase Negativa*** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CJ6W9taij3cV"
      },
      "source": [
        "***En la siguiente celda de código se imprime el F1 obtenido con el mejor modelo del clasificador KNN. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBLGJj_coc23",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "e627eeb8-9da6-46cf-d4e2-145bb2a3e953"
      },
      "source": [
        "print(\"F1 para No fraude (clase negativa) obtenido con mejor modelo de KNN:\", knn_f1n)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=knn_f1na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 para No fraude (clase negativa) obtenido con mejor modelo de KNN: 0.6693333333333336\n",
            "\n",
            "Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af44b25c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jwL3MyRKj95r"
      },
      "source": [
        "***En la siguiente celda de código se imprime el F1 obtenido con el mejor modelo del clasificador Árbol de Decisión. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "142ghWJ_sLoU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "8e5be6f0-8317-4706-9578-0579ebaf1ee7"
      },
      "source": [
        "print(\"F1 para No fraude (clase negativa) obtenido con mejor modelo de Árbol de Decisión:\", ad_f1n)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=ad_f1na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 para No fraude (clase negativa) obtenido con mejor modelo de Árbol de Decisión: 0.5946666666666668\n",
            "\n",
            "Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af419b2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t7gqMasjkD73"
      },
      "source": [
        "***En la siguiente celda de código se imprime el F1 obtenido con el mejor modelo del clasificador Random Forest. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR2XN0PuSm0W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "eb94ac7d-7af2-4fef-ba50-c7054eb34830"
      },
      "source": [
        "print(\"F1 para No fraude (clase negativa) obtenido con mejor modelo de Random Forest:\", rf_f1n)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=rf_f1na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 para No fraude (clase negativa) obtenido con mejor modelo de Random Forest: 0.7066666666666669\n",
            "\n",
            "Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0aff934ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uj6wHqockKR_"
      },
      "source": [
        "***En la siguiente celda de código se imprime el F1 obtenido con el mejor modelo del clasificador Regresión Logistica. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA3rbpDAUO1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "1d79bc50-43c8-4c68-d8a1-28b57f5e690b"
      },
      "source": [
        "print(\"F1 para No fraude (clase negativa) obtenido con mejor modelo de Regresión Logistica (Logistic Regression):\", lr_f1n)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=lr_f1na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 para No fraude (clase negativa) obtenido con mejor modelo de Regresión Logistica (Logistic Regression): 0.6860000000000003\n",
            "\n",
            "Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0fad2b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPo0lEQVR4nO3dbWxUdaLH8V/nUIR7hbIztsOpFBvQ1IlREyXxxYrXQGEaGSwGYZLBmGisL2Q1y801VKN9iCamZnOjosRoIkLGTUhjIjJpWoIvVrtRzFUTGifoXWwpyOmDM1vKg4RyZu4Lr802SGfaTnuGv9/PK0f+lJ+JfjkepmdKstlsVgAA4/i8HgAAmB0EHgAMReABwFAEHgAMReABwFAEHgAMReABwFDzvB7wr/75z/PKZHhbPgDkw+cr0R/+8O9X/fGiCnwmkyXwAFAg3KIBAEMReAAwFIEHAEPlDHxbW5vWrFmjmpoaff/99795xnVdtba2qra2VuvWrVN7e3vBhwIApiZn4NeuXasPPvhAN95441XPHDx4UP39/Tp06JD279+vXbt26dSpUwUdCgCYmpyBX7VqlWzbnvRMR0eHtmzZIp/PJ7/fr9raWnV2dhZsJABg6gryNknHcVRZWTn+2rZtDQwMFOJLz6m//nWfTp484fWMonDmzIjOnDnj9QwUmbKyMpWVLfF6RlGoqrpJsdijXs+YVFG9Dz4QuN7TX39g4JS++99/yFrAv8CZyxeVvTzm9QwUmYvpcxoevez1DM+5F0dUWmqpvHyR11MmVZDA27at06dP64477pB05RV9vlKpc55+o9PYmCtrwRL9201rPdsAoPhdOPGJxsZcDQ+f9XSHz1cy6YVxQd4mWVdXp/b2dmUyGaXTaR0+fFjhcLgQXxoAME05A//yyy/rvvvu08DAgB577DFt2LBBktTQ0KCenh5JUn19vZYtW6b169dr69at2r59u6qqqmZ3OQBgUiXF9KHbXt+iaWt7Sf84+RO3aABM6sKJT3Rz1Q3aufNFT3fMyS0aAEDxIfAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYKii+sg+r505MyL34ogunPjE6ykAiph7cURnzhR/PrmCBwBDFf9vQXOorGyJhkcv84EfACZ14cQnKitb4vWMnLiCBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMBSBBwBDEXgAMFRejwvu7e1VY2OjRkZGtGTJErW1tam6unrCmVQqpeeee06O4+jy5cu655579MILL2jePJ5IDABeyOsKvrm5WbFYTF1dXYrFYmpqarrizNtvv62VK1fq4MGD+vjjj/Xtt9/q0KFDBR8MAMhPzsCnUiklk0lFIhFJUiQSUTKZVDqdnnCupKRE58+fVyaT0aVLlzQ2NqZgMDg7qwEAOeW8f+I4joLBoCzLkiRZlqWKigo5jiO/3z9+7qmnntLTTz+te++9Vz///LO2bdumu+++e0pjAoHrpzi/sEpLLU9/fQDXjtJSS+Xli7yeMamC3SDv7OxUTU2N9u7dq/Pnz6uhoUGdnZ2qq6vL+2ukUueUyWQLNWnKxsZcz35tANeWsTFXw8NnPd3g85VMemGc8xaNbdsaHByU6/4SP9d1NTQ0JNu2J5yLx+N68MEH5fP5tGjRIq1Zs0ZHjhyZ4XwAwHTlDHwgEFAoFFIikZAkJRIJhUKhCbdnJGnZsmX69NNPJUmXLl3S559/rltuuWUWJgMA8pHXu2haWloUj8cVDocVj8fV2toqSWpoaFBPT48k6fnnn9dXX32ljRs3atOmTaqurtbWrVtnbzkAYFJ53YNfuXKl2tvbr/j777777vhfL1++XHv27CncMgDAjPCdrABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIYi8ABgKAIPAIbK60O3f0/ciyO6cOITr2egSGQuX5Qk+eYt8HgJiol7cUTSDV7PyInA/4uqqpu8noAi099/QpK0vKr4/2PGXLrhmuhFSTabzXo94lep1DllMkUzB1Bb20uSpJ07X/R4CXAln69EgcD1V//xOdwCAJhDBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQeQW+t7dX0WhU4XBY0WhUfX19v3muo6NDGzduVCQS0caNG/XTTz8VcisAYAry+k7W5uZmxWIx1dfX68CBA2pqatK+ffsmnOnp6dGbb76pvXv3qry8XGfPntX8+fNnZTQAILecV/CpVErJZFKRSESSFIlElEwmlU6nJ5x7//339fjjj6u8vFyStGjRIl133XWzMBkAkI+cgXccR8FgUJZlSZIsy1JFRYUcx5lw7vjx4zp58qS2bdumhx56SLt371YRPQUBAH53CvawMdd19d1332nPnj26dOmSnnjiCVVWVmrTpk15f43JnqkAeKG09JcLm/LyRR4vAaYuZ+Bt29bg4KBc15VlWXJdV0NDQ7Jte8K5yspK1dXVaf78+Zo/f77Wrl2ro0ePTinwPGwMxWZszJUkDQ+f9XgJcKUZP2wsEAgoFAopkUhIkhKJhEKhkPx+/4RzkUhE3d3dymazGhsb0xdffKFbb711hvMBANOV19skW1paFI/HFQ6HFY/H1draKklqaGhQT0+PJGnDhg0KBAJ64IEHtGnTJt188816+OGHZ285AGBSPA8emATPg0cx43nwAPA7ReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFAEHgAMReABwFA8Lhi/6e9//1Td3X/zeobn+vtPSJKWL7/J4yXF4d57/0N//ON9Xs/A/8v1uOCCfSYrYKKysjKvJwDTxhU8AFyj+MAPAPidIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYKi8At/b26toNKpwOKxoNKq+vr6rnv3hhx905513qq2trVAbAQDTkFfgm5ubFYvF1NXVpVgspqampt8857qumpubVVtbW9CRAICpyxn4VCqlZDKpSCQiSYpEIkomk0qn01ecfeedd3T//ferurq64EMBAFOT8yP7HMdRMBiUZVmSJMuyVFFRIcdx5Pf7x88dO3ZM3d3d2rdvn3bv3j2tMZN9MgkAYGoK8pmsY2NjevHFF/XKK6+M/0YwHXxkHwDkb8Yfum3btgYHB+W6rizLkuu6Ghoakm3b42eGh4fV39+vJ598UpI0OjqqbDarc+fO6aWXXirAPwYAYKpyBj4QCCgUCimRSKi+vl6JREKhUGjC7ZnKykodOXJk/PWuXbt04cIF7dy5c3ZWAwByyutdNC0tLYrH4wqHw4rH42ptbZUkNTQ0qKenZ1YHAgCmpySbzRbNTW/uwQNA/nLdg+c7WQHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAxF4AHAUAQeAAw1L59Dvb29amxs1MjIiJYsWaK2tjZVV1dPOPPWW2+po6NDPp9PpaWl2rFjh1avXj0bmwEAeSjJZrPZXIceffRRbd68WfX19Tpw4IA+/PBD7du3b8KZzz77TKtWrdLChQt17NgxPfLII+ru7taCBQvyHpNKnVMmk3MOAECSz1eiQOD6q/94ri+QSqWUTCYViUQkSZFIRMlkUul0esK51atXa+HChZKkmpoaZbNZjYyMzGQ7AGAGcgbecRwFg0FZliVJsixLFRUVchznqj/no48+0vLly7V06dLCLQUATEle9+Cn4ssvv9Trr7+u9957b8o/d7L/1QAATE3OwNu2rcHBQbmuK8uy5LquhoaGZNv2FWe/+eYbPfvss9q9e7dWrFgx5THcgweA/M34HnwgEFAoFFIikZAkJRIJhUIh+f3+CeeOHj2qHTt26I033tBtt902w9kAgJnK6100x48fV2Njo0ZHR7V48WK1tbVpxYoVamho0DPPPKPbb79dmzdv1o8//qhgMDj+81599VXV1NTkPYYreADIX64r+LwCP1cIPADkb8a3aAAA1yYCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvAAYCgCDwCGIvDAJF577S96/PGY3nzzv72eAkxZXoHv7e1VNBpVOBxWNBpVX1/fFWdc11Vra6tqa2u1bt06tbe3F3orMOeOHv1akvT11//j8RJg6vIKfHNzs2KxmLq6uhSLxdTU1HTFmYMHD6q/v1+HDh3S/v37tWvXLp06dargg4G58tprf5nwmqt4XGtyBj6VSimZTCoSiUiSIpGIksmk0un0hHMdHR3asmWLfD6f/H6/amtr1dnZOTurgTnw69X7r7iKx7VmXq4DjuMoGAzKsixJkmVZqqiokOM48vv9E85VVlaOv7ZtWwMDA1MaEwhcP6XzwFwrL1/k9QQgbzkDP5dSqXPKZLJezwCuanj4rNcTgHE+X8mkF8Y5b9HYtq3BwUG5rivplz9MHRoakm3bV5w7ffr0+GvHcbR06dLp7gY8d8cdd014fdddqzxaAkxPzsAHAgGFQiElEglJUiKRUCgUmnB7RpLq6urU3t6uTCajdDqtw4cPKxwOz85qYA78+c//NeH1n/70nx4tAaYnr3fRtLS0KB6PKxwOKx6Pq7W1VZLU0NCgnp4eSVJ9fb2WLVum9evXa+vWrdq+fbuqqqpmbzkwB369iufqHdeikmw2WzQ3vbkHDwD5m/E9eADAtYnAA4ChCDwAGKqo3gfv85V4PQEArhm5mllUf8gKACgcbtEAgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPAAYisADgKEIPDCJ3t5eRaNRhcNhRaNR9fX1eT0JyBuBBybR3NysWCymrq4uxWIxNTU1eT0JyBuBB64ilUopmUwqEolIkiKRiJLJpNLptMfLgPwQeOAqHMdRMBiUZVmSJMuyVFFRIcdxPF4G5IfAA4ChCDxwFbZta3BwUK7rSpJc19XQ0JBs2/Z4GZAfAg9cRSAQUCgUUiKRkCQlEgmFQiH5/X6PlwH54QM/gEkcP35cjY2NGh0d1eLFi9XW1qYVK1Z4PQvIC4EHAENxiwYADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQBB4ADEXgAcBQ/wdjgDLlCldHtwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "re_PFBnSkQ-N"
      },
      "source": [
        "***En la siguiente celda de código se imprime el F1 obtenido con el mejor modelo del clasificador Redes Bayesianas Multinomiales. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqVQlvKSVfUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "6a2683fe-7dfd-49cb-ebd2-0c6c562a922c"
      },
      "source": [
        "print(\"F1 para No fraude (clase negativa) obtenido con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes):\", mnb_f1n)\n",
        "print()\n",
        "print(\"Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=mnb_f1na)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 para No fraude (clase negativa) obtenido con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes): 0.7493333333333334\n",
            "\n",
            "Boxplot de f1s (clase negativa) obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f53c940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YaM0sK3ZgJnc"
      },
      "source": [
        "####***E. Evaluación segun metrica de Área bajo la curva ROC (AUC)***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VkkaLLnZ3y6a"
      },
      "source": [
        "En el siguiente codigo, se indica el ***Área bajo la Curva ROC (AUC)*** obtenida con la prueba anterior. Cabe mencionar que se tuvieron en cuenta los mejores ***hiperparametros*** para cada modelo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6YXrL1zTkVlm"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Área bajo la Curva ROC (AUC) obtenido con el mejor modelo del clasificador KNN. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twGqGJPso0M6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "be6fbbe6-5e26-4823-ae8e-80aa26cf913a"
      },
      "source": [
        "print(\"Área bajo la Curva ROC (AUC) obtenido con mejor modelo de KNN:\", knn_auc)\n",
        "print()\n",
        "print(\"Boxplot de AUCs obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=knn_auca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Área bajo la Curva ROC (AUC) obtenido con mejor modelo de KNN: 0.79\n",
            "\n",
            "Boxplot de AUCs obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af4540940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RTF4f8BQlBvL"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Área bajo la Curva ROC (AUC) obtenido con el mejor modelo del clasificador Árbol de Decisión. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK-i-ggosXSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "24cfd3dc-a388-4e45-e69a-0a6b39e47531"
      },
      "source": [
        "print(\"Área bajo la Curva ROC (AUC) obtenido con mejor modelo de Árbol de Decisión:\", ad_auc)\n",
        "print()\n",
        "print(\"Boxplot de AUCs obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=ad_auca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Área bajo la Curva ROC (AUC) obtenido con mejor modelo de Árbol de Decisión: 0.66\n",
            "\n",
            "Boxplot de AUCs obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0af410a048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yuSxFAYelGOm"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Área bajo la Curva ROC (AUC) obtenido con el mejor modelo del clasificador Random Forest. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avXpxoxHSxFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "22e62521-52ed-4924-a82e-167a7cd489db"
      },
      "source": [
        "print(\"Área bajo la Curva ROC (AUC) obtenido con mejor modelo de Random Forest:\", rf_auc)\n",
        "print()\n",
        "print(\"Boxplot de AUCs obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=rf_auca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Área bajo la Curva ROC (AUC) obtenido con mejor modelo de Random Forest: 0.8625\n",
            "\n",
            "Boxplot de AUCs obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0afe0386a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gsv6eXz1lM72"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Área bajo la Curva ROC (AUC) obtenido con el mejor modelo del clasificador Regresión Logistica. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "439E7WN0UaYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "8c807cf4-1873-40e4-cf9e-268378fe8c54"
      },
      "source": [
        "print(\"Área bajo la Curva ROC (AUC) obtenido con mejor modelo de Regresión Logistica (Logistic Regression):\", lr_auc)\n",
        "print()\n",
        "print(\"Boxplot de AUCs obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=lr_auca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Área bajo la Curva ROC (AUC) obtenido con mejor modelo de Regresión Logistica (Logistic Regression): 0.8725\n",
            "\n",
            "Boxplot de AUCs obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f7d0978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8YVEvJazlUeA"
      },
      "source": [
        "***En la siguiente celda de código se imprime el Área bajo la Curva ROC (AUC) obtenido con el mejor modelo del clasificador Redes Bayesianas Multinomiales. Asi mismo, se muestra el diagrama de caja obtenido con dicho algoritmo***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vRzRtx0VtmF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "6511d884-f69b-4bce-c5cb-32808b604ac2"
      },
      "source": [
        "print(\"Área bajo la Curva ROC (AUC) obtenido con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes):\", mnb_auc)\n",
        "print()\n",
        "print(\"Boxplot de AUCs obtenidos en el cross-validation:\")\n",
        "sns.boxplot(data=mnb_auca)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Área bajo la Curva ROC (AUC) obtenido con mejor modelo de Redes Bayesianas Multinomiales (Multinomial Naive Bayes): 0.8825\n",
            "\n",
            "Boxplot de AUCs obtenidos en el cross-validation:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b0f4b9240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW-_T2OXlgE-",
        "colab_type": "text"
      },
      "source": [
        "####***F. Comparación y Síntesis***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiKjYt_9FRr-",
        "colab_type": "text"
      },
      "source": [
        "En esta sección, se procede con la construcción de la síntesis o resumen de los resultados obtenidos para cada modelo. Se empleara una comparación entre los mismos, con el objetivo de plantear conclusiones apropiadas. La comparativa se desarrolla en base a una serie de metricas. Entre ellas, cabe mencionar ***Exactitud, Precisión, Recall, F1*** y ***Área bajo la curva ROC (AUC)***. Siguiendo en este razonamiento, se procede a mostrar una tabla, la cual indica los valores de las ***metricas de evaluación*** obtenidos por el ***mejor modelo*** de cada algoritmo de aprendizaje supervisado analizado. Esta tabla es formulada con el objetivo de resaltar las limitaciones y ventajas de cada modelo de forma comparativa. Es importante resaltar que un ***mejor modelo*** de un clasificador, es aquel que cuenta con los mejores ***hiperparametros*** encontrados para el mismo. \n",
        "\n",
        "![Tabla comparativa de modelos](https://i.ibb.co/jWRD7MC/01.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra_wvg53crwu",
        "colab_type": "text"
      },
      "source": [
        "De acuerdo a lo observado en la tabla anterior, es factible reconocer que el ***mejor modelo*** de ***Random Forest*** logra obtener mejor ***performance*** que el resto de modelos en base a ***2 metricas***, las cuales son ***Exactitud y Recall para valoración negativa***. Por otra parte, se logra observar que el ***mejor modelo*** de ***Multinomial Naive Bayes*** alcanza un mejor valor de ***AUC*** que el resto de modelos evaluados. Teniendo ello en cuenta, se procedera a listar cada ***metrica de evaluación***, realizando la comparativa entre modelos respectiva:\n",
        "\n",
        "* ***Random Forest (mejor modelo)*** logra obtener una mejor ***Exactitud***, con un valor de ***78.83%***, en comparación a los ***77.00%***, ***63.66%***, ***78.33%*** y ***75.16%*** obtenidos por ***KNN (mejor modelo)***, ***Árbol de Decisión (mejor modelo)***, ***Logistic Regression (mejor modelo)*** y ***Multinomial Naive Bayes (mejor modelo)*** respectivamente.\n",
        "\n",
        "* ***KNN (mejor modelo)*** logra obtener una mejor ***Precisión valoración Positiva***, con un valor de ***81.33%***, en comparación a los ***78.00%***, ***77.00%***, ***78.66%*** y ***77.00%*** obtenidos por ***Árbol de Decisión (mejor modelo)***, ***Random Forest (mejor modelo)***, ***Logistic Regression (mejor modelo)*** y ***Multinomial Naive Bayes (mejor modelo)*** respectivamente.\n",
        "\n",
        "* ***KNN (mejor modelo)*** logra obtener una mejor ***Precisión para valoración Negativa***, con un valor de ***79.33%***, en comparación a los ***70.00%***, ***77.00%***, ***73.33%*** y ***75.00%*** obtenidos por ***Árbol de Decisión (mejor modelo)***, ***Random Forest (mejor modelo)***, ***Logistic Regression (mejor modelo)*** y ***Multinomial Naive Bayes (mejor modelo)*** respectivamente.\n",
        "\n",
        "* ***Random Forest (mejor modelo)*** y  ***Logistic Regression (mejor modelo)*** lograron obtener un mejor ***Recall para valoración Positiva***, con un valor de ***90.00%***, en comparación a los ***88.00%***, ***65.00%*** y ***77.00%***, obtenidos por ***KNN (mejor modelo)***, ***Árbol de Decisión (mejor modelo)***, y ***Multinomial Naive Bayes (mejor modelo)*** respectivamente.\n",
        "\n",
        "* ***Multinomial Naive Bayes (mejor modelo)*** logra obtener un mejor ***Recall para Valoracion Negativa***, con un valor de ***85.00%***, en comparación a los ***67.00%***, ***72.00%***, ***69.00%*** y ***68.00%*** obtenidos por ***KNN (mejor modelo)***, ***Árbol de Decisión (mejor modelo)***, ***Random Forest (mejor modelo)*** y ***Logistic Regression (mejor modelo)*** y respectivamente.\n",
        "\n",
        "* ***Logistic Regression (mejor modelo)*** logra obtener un mejor ***F1 para valoración Positiva***, con un valor de ***81.00%***, en comparación a los ***79.33%***, ***56.06%***, ***80.33%*** y ***72.33%*** obtenidos por ***KNN (mejor modelo)***, ***Árbol de Decisión (mejor modelo)***, ***Random Forest (mejor modelo)*** y ***Multinomial Naive Bayes (mejor modelo)*** y respectivamente.\n",
        "\n",
        "* ***Multinomial Naive Bayes (mejor modelo)*** logra obtener un mejor ****F1 para valoración Negativa***, con un valor de ***74.93%***, en comparación a los ***66.93%***, ***59.46%***, ***70.66%*** y ***68.60%*** obtenidos por ***KNN (mejor modelo)***, ***Árbol de Decisión (mejor modelo)***, ***Random Forest (mejor modelo)*** y ***Logistic Regression (mejor modelo)*** y respectivamente.\n",
        "\n",
        "* ***Random Forest (mejor modelo)*** logra obtener una mejor ***Área bajo la curva ROC***, con un valor de ***99.61%***, en comparación a los ***99.48%***, ***98.79%***, ***99.23%***, ***95.67%*** y ***86.12%*** obtenidos por ***KNN (mejor modelo)***, ***Árbol de Decisión (mejor modelo)***, ***SVM (mejor modelo)***, ***Logistic Regression (mejor modelo)*** y ***Multinomial Naive Bayes (mejor modelo)*** respectivamente.\n",
        "\n",
        "* ***Multinomial Naive Bayes (mejor modelo)*** logra obtener un mejor ***Área bajo la curva ROC***, con un valor de ***88.25%***, en comparación a los ***79.00%***, ***66.00%***, ***86.00%*** y ***87.25%*** obtenidos por ***KNN (mejor modelo)***, ***Árbol de Decisión (mejor modelo)***, ***Random Forest (mejor modelo)*** y ***Logistic Regression (mejor modelo)*** y respectivamente.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi_th1OCQljS",
        "colab_type": "text"
      },
      "source": [
        "Como se puede observar, para la mayoria de metricas, ***Multinomial Naive Bayes (mejor modelo)*** logra obtener los mejores resultados en muchas de las metricas. Sin embargo, ***Logistic Regression (mejor modelo)*** y ***Random Forest (mejor modelo)*** consiguieron ser los mejores modelos en las otras metricas. Para ***AUC***, la diferencia de desempeño entre los clasificadores mencionados es ligeramente superior a ***2.0%***. Sin embargo, la diferencia de desempeño entre ***Multinomial Naive Bayes (mejor modelo)*** y ***Logistic Regression (mejor modelo)*** es poco significativa como para afirmar contundentemente la superioridad de uno de estos. \n",
        "\n",
        "Por otro lado, tambien es importante argumentar respecto a ***1 metrica*** en especifico para identificar el mejor clasificador. En ese sentido, dicha metrica sera ***F1***. ***Random Forest (mejor modelo)***  y ***Logistic Regression (mejor modelo)*** consiguen los mejores  resultados para esta metrica. Tanto para ***F1 para valoraciónes Positivas*** como para ***F1 para valoraciónes Negativas***. ***Random Forest (mejor modelo)*** consigue un desempeño de ***80.33%*** y ***70.60%*** en F1. Mientras que, ***Logistic Regression (mejor modelo)*** consigue un desempeño de ***81.00%*** y ***68.60%*** en F1. Teniendo en cuenta las variaziones que se encuentran entre los resultados de los 2 modelos, y los resultados presentes en las otras metricas de desempeño se concluye que el mejor algoritmo de clasificación es ***Random Forest (mejor modelo)***. En ese sentido, se reporta lo siguiente:\n",
        "\n",
        "* ***Los mejor modelos encontrados para el conjunto de datos estan basados en Random Forest***.\n",
        "\n",
        "Asimismo, los siguientes ajustes de ***hiperparametros*** son los más apropiados para los modelos planteados:\n",
        "\n",
        "* ***Para Random Forest:***\n",
        "  * ***Numero de estimadores (n_estimators):  5***\n",
        "  * ***Profundidad maxima (max_depth):  2***\n",
        "  * ***max_features: Logartmo (log2)***\n",
        "  * ***bootstrap:  True***\n",
        "\n",
        "***Conclusión: En base a los resultados planteados, se puede afirmar la superioridad de uno del clasificador Random Forest para abordar este problema y este dataset.***"
      ]
    }
  ]
}